{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Author: Matthew Portman**\n",
    "\n",
    "**Date (Github date will likely be more accurate): 10/22/20**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MINI README\n",
    "\n",
    "Please place this script into the directory which contains the folders for your input, temporary, and output files for SpArcFiRe typically denoted: sparcfire-in, sparcfire-tmp, and sparcfire-out. GALFIT will also be run from that same directory if you choose to use the control script included in the repo. I recommend running this alone *once* before running the big script to ensure everything is in its right place. After you confirm that this works without any errors the first time around, feel free to run the control script from then on. \n",
    "\n",
    "Running from the overarching directory is a temporary measure which will be remedied upon completion of the entire control script and full integration with SpArcFiRe. \n",
    "\n",
    "TO RUN: `python sparc_to_galfit_feedme_gen.py`\n",
    "\n",
    "To run the control script: `bash control_script.sh`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import log\n",
    "import glob\n",
    "import csv\n",
    "import subprocess\n",
    "import random\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To convert autocrop image to fits\n",
    "import subprocess\n",
    "\n",
    "try: \n",
    "    autocrop_img_filename = glob.glob('*_autoCrop.png')[0]\n",
    "    #convert_command = [\"convert \", autocrop_img_filename,\"input.fits\"]\n",
    "    convert_command = \"convert \" + autocrop_img_filename + \" input.fits\"\n",
    "\n",
    "except:\n",
    "    print(\"Cannot find \", autocrop_img_filename, \" to convert to fits.\")\n",
    "    print(\"Check Sparcfire output or directories. Cannot proceed. Quitting.\")\n",
    "    raise SystemExit(\"Quitting.\")\n",
    "    \n",
    "else:\n",
    "    try: \n",
    "        subprocess.run(convert_command, shell=True)\n",
    "    \n",
    "    except:\n",
    "        print(\"Cannot convert to FITS:\", autocrop_img_filename)\n",
    "        print(\"Check Sparcfire output or directories. Cannot proceed.\")\n",
    "        raise SystemExit(\"Quitting.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grabbing the file names\n",
    "def get_galaxy_names_list():\n",
    "\n",
    "    try:\n",
    "        filenames_read = glob.glob(\"sparcfire-in/*.fits\") # Hardcoding is a temporary measure.\n",
    "    \n",
    "    #except:\n",
    "        # Feel free to hardcode this \n",
    "        #print(\"Please input the full path to the input directory for the SpArcFiRe run and include the trailing /\")\n",
    "        #print(\"e.g. /home/usr/sparcfire-in/\")\n",
    "        #path_to_sparc_in = input()\n",
    "    \n",
    "        #try:\n",
    "            #filenames_in = glob.glob(path_to_sparc_in + \"*.fits\")\n",
    "\n",
    "        #except:\n",
    "            #print(\"See instructions above or check your directory path. Could not glob.\")\n",
    "            #raise SystemExit(\"Exitting.\")\n",
    "    \n",
    "    except:\n",
    "        print(\"Please copy me into the directory which contains the folders for your\")\n",
    "        print(\"input, temporary, and output files for SpArcFiRe typically denoted:\")\n",
    "        print(\"sparcfire-in, sparcfire-tmp, and sparcfire-out.\")\n",
    "        raise SystemExit(\"Exitting.\")\n",
    "        \n",
    "    else:\n",
    "        filenames_out = [s.split(\".\")[0] for s in filenames_read]\n",
    "        galaxy_names_out = [s.split(\"/\")[1] for s in filenames_out]\n",
    "        filenames_out = [s.replace(\"in\", \"out\") for s in filenames_out]\n",
    "        \n",
    "    return filenames_read, galaxy_names_out, filenames_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def glob_name(path='', name='', desired_file=''):\n",
    "    \n",
    "    file_path = \"./\" + path + '/' + name + desired_file\n",
    "    #print(file_path)\n",
    "    file_name = glob.glob(file_path)[0]\n",
    "    \n",
    "    return file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autocrop_grab(galaxy_name, galaxy_path):\n",
    "    # for autocrop coordinates\n",
    "    \n",
    "    try: \n",
    "        cropcoord_filename = glob_name(galaxy_path, galaxy_name, '_crop_coord.txt') #glob.glob('*coord.txt')[0]\n",
    "        cropcoord_file = open(cropcoord_filename,'r')\n",
    "\n",
    "    except:\n",
    "        print(\"Can't open to read: \", cropcoord_filename)\n",
    "        print(\"Check Sparcfire output or directories. Proceeding without crop (good luck).\")\n",
    "\n",
    "        crop_x1 = 0\n",
    "        crop_x2 = 256\n",
    "        crop_y1 = 0\n",
    "        crop_y2 = 256\n",
    "\n",
    "    else:\n",
    "        cropcoord_in = cropcoord_file.read()\n",
    "        cropcoord_file.close()\n",
    "\n",
    "        cropcoord_in = cropcoord_in.split('\\n')\n",
    "\n",
    "        crop_x1 = cropcoord_in[0]\n",
    "        crop_x2 = cropcoord_in[1]\n",
    "        crop_y1 = cropcoord_in[2]\n",
    "        crop_y2 = cropcoord_in[3]\n",
    "        \n",
    "    return crop_x1, crop_x2, crop_y1, crop_y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_to_string(x, scale = 1):\n",
    "    # Scales and chops\n",
    "    return str(float(x)*scale)[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tsv_information(galaxy_name, galaxy_path, scale_fact):\n",
    "   \n",
    "    try:\n",
    "        #tsv_filename = glob.glob(\"./\" + galaxy_path + '/' + galaxy_name + '.tsv')[0]\n",
    "        tsv_filename = glob_name(galaxy_path, galaxy_name, '.tsv')\n",
    "        tsv_file = open(tsv_filename, 'r')\n",
    "        \n",
    "    except:\n",
    "        print(\"Can't open to read: \", tsv_filename)\n",
    "        print(\"Check Sparcfire output or directories. Proceeding with default values.\")\n",
    "\n",
    "        bulge_rad_out = '2'\n",
    "        bulge_axis_ratio_out = '0.5'\n",
    "        bulge_rot_angle_out = '1'\n",
    "\n",
    "        center_pos_x_out = '30'\n",
    "        center_pos_y_out = '30'\n",
    "        disk_maj_axs_len_out = \"30\"\n",
    "        pos_angle_sersic_out = \"1\"\n",
    "        pos_angle_power_out = '30'\n",
    "        axis_ratio_out = \"0.5\"\n",
    "        max_arc_length_out = '30'\n",
    "        chirality = 0\n",
    "        chirality_2 = 0\n",
    "        # spin_parity handled by if \n",
    "        est_arcs_out = 2\n",
    "        inclination = '30'\n",
    "        bar_cand = 'FALSE'\n",
    "\n",
    "    else:\n",
    "        reader = csv.DictReader(tsv_file, dialect='excel-tab')\n",
    "        tsv_in = list(reader)\n",
    "        for row in tsv_in:\n",
    "            bulge_rad_out = scale_to_string(row['bulgeMajAxsLen'], scale_fact)\n",
    "            bulge_axis_ratio_out = row['bulgeAxisRatio']         \n",
    "\n",
    "            # Already accounted for, no need to scale\n",
    "            center_pos_x_out = row['inputCenterR']\n",
    "            center_pos_y_out = row['inputCenterC']\n",
    "            \n",
    "            # Scaled down, may scale down a bit further to better reflect the *half* radius\n",
    "            disk_maj_axs_len_out = scale_to_string(row['diskMajAxsLen'], scale_fact) \n",
    "            \n",
    "            # Angles don't need to scale\n",
    "            bulge_angle = np.degrees(float(row['bulgeMajAxsAngle']))\n",
    "            disk_angle = np.degrees(float(row['diskMajAxsAngleRadians']))\n",
    "            \n",
    "            a_ratio = float(row['diskAxisRatio']) # I use a_ratio later hence why it's not immediately converted\n",
    "            axis_ratio_out = scale_to_string(a_ratio)\n",
    "            \n",
    "            if disk_angle < 0: \n",
    "                inclination = np.degrees(np.arccos(a_ratio))\n",
    "                bulge_rot_angle_out = scale_to_string(90 + bulge_angle) #because sparcfire gets confused sometimes\n",
    "                \n",
    "                pos_angle_power_out = -disk_angle\n",
    "                pos_angle_sersic_out = 90 + disk_angle # Because sparcfire is checking negative direction too, \n",
    "                                                                          # assuming symmetry this should align us better\n",
    "            else:\n",
    "                inclination = -np.degrees(np.arccos(a_ratio)) \n",
    "                bulge_rot_angle_out = scale_to_string(90 - bulge_angle)            \n",
    "                \n",
    "                pos_angle_power_out = 180 - disk_angle\n",
    "                pos_angle_sersic_out = 90 - disk_angle \n",
    "                \n",
    "            if a_ratio >= 0.5:\n",
    "                pos_angle_power_out = pos_angle_power_out + bulge_angle # Big change, should this also apply to bulge?\n",
    "            \n",
    "            pos_angle_power_out = scale_to_string(pos_angle_power_out)\n",
    "            pos_angle_sersic_out = scale_to_string(pos_angle_sersic_out)\n",
    "            inclination = scale_to_string(inclination)\n",
    "\n",
    "            # GRABBING ARC STATISTICS\n",
    "            avg_arc_length_out = scale_to_string(row['avgArcLength'], scale_fact)\n",
    "            #med_arc_length = row['medianArcLength'][:6]\n",
    "            max_arc_length_out = scale_to_string(row['maxArcLength'], scale_fact)\n",
    "            \n",
    "            # Grabbing chirality\n",
    "            chirality = row['chirality_maj']\n",
    "            chirality_2 = row['chirality_alenWtd']\n",
    "            \n",
    "            # For estimating number of real arcs to influence fourier modes\n",
    "            est_arcs_out = row['chirality_votes_maj']\n",
    "            est_arcs_out = min(int(est_arcs_out[1]),int(est_arcs_out[-2]))\n",
    "            \n",
    "            # bar candidate: r_in = 0 according to Chien\n",
    "            bar_cand = row['bar_candidate_available']\n",
    "            \n",
    "            # Grabbing PA absolute average from dominant chirality\n",
    "            pitch_angle = abs(float(row['pa_alenWtd_avg_domChiralityOnly']))\n",
    "            #print(pitch_angle)\n",
    "            \n",
    "            # Based on linear regression from test set: galaxy, alpha, pitch angle\n",
    "            #6698 - 0.9319, 16.8303045\n",
    "            #1248 - 2.0704, 28.10656079\n",
    "            #9688 - 0.544, 12.11462932\n",
    "            #9241 - 0.7194, 19.01479688\n",
    "            #1827 - 1.2037, 21.55850102\n",
    "            #4222 - 0.5625, 8.145239069\n",
    "            #0761 - 1.1330, 19.53474969\n",
    "            alpha_out = scale_to_string(0.07*pitch_angle - 0.3)\n",
    "            \n",
    "        tsv_file.close()\n",
    " \n",
    "    if chirality == 'Zwise':\n",
    "        spin_parity = '-'\n",
    "    elif chirality == 'Swise':\n",
    "        spin_parity = ''\n",
    "    else:\n",
    "        if chirality_2 == 'Zwise':\n",
    "            spin_parity = '-'\n",
    "        elif chirality_2 == 'Swise':\n",
    "            spin_parity = ''\n",
    "        else:\n",
    "            print(\"Something went wrong in choosing a chirality! Coin flip...\")\n",
    "            spin_parity = random.choice(['','-'])\n",
    "        \n",
    "    return (\n",
    "        bulge_rad_out,\n",
    "        bulge_axis_ratio_out,\n",
    "        bulge_rot_angle_out,\n",
    "        center_pos_x_out,\n",
    "        center_pos_y_out,\n",
    "        disk_maj_axs_len_out,\n",
    "        pos_angle_sersic_out,\n",
    "        pos_angle_power_out,\n",
    "        axis_ratio_out,\n",
    "        max_arc_length_out,\n",
    "        spin_parity,\n",
    "        est_arcs_out,\n",
    "        inclination,\n",
    "        bar_cand,\n",
    "        alpha_out\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_information(galaxy_name, galaxy_path, scale_fact):\n",
    "\n",
    "    try:\n",
    "        #arcs_filename = glob.glob(galaxy_path + '/' + '*_arcs.csv')\n",
    "        arcs_filename = glob_name(galaxy_path, galaxy_name, '_arcs.csv')\n",
    "        arcs_file = open(arcs_filename, 'r')\n",
    "    except:\n",
    "        print(\"Can't open to read: \", arcs_filename)\n",
    "        print(\"Check Sparcfire output or directories. Proceeding with default values.\")\n",
    "        \n",
    "        inner_rad = '0'\n",
    "        outer_rad = '20'\n",
    "        cumul_rot_out = '60'\n",
    "\n",
    "    else:\n",
    "        reader = csv.DictReader(arcs_file)\n",
    "        arcs_in = list(reader)\n",
    "        arm_1_dict = arcs_in[0]\n",
    "        \n",
    "        try:\n",
    "            arm_2_dict = arcs_in[1]\n",
    "        \n",
    "        except:\n",
    "            print(\"Only found one arm. Proceeding.\")\n",
    "            arm_2_dict = arm_1_dict\n",
    "        \n",
    "        arc_init_theta = np.degrees(float(arm_1_dict['math_initial_theta'])) % 360\n",
    "        arc_init_theta_2 = np.degrees(float(arm_2_dict['math_initial_theta'])) % 360\n",
    "        \n",
    "        arc_end_theta = np.degrees(float(arm_1_dict['relative_theta_end'])) % 360\n",
    "        arc_end_theta_2 = np.degrees(float(arm_2_dict['relative_theta_end'])) % 360\n",
    "        \n",
    "        # How far the arm rotates in theta which approximates the point where sparcfire no longer traces the arm\n",
    "        # and hence where the cumulative rotation out point is. Note, this already takes into account the relative\n",
    "        # starting point of the arms which is the hard part... \n",
    "        # JK sparc is measuring as from its auto-crop and face-on transform. I can't use that!\n",
    "        \n",
    "        cumul_rot_out = 0.5*abs((arc_end_theta + arc_end_theta_2) - (arc_init_theta + arc_init_theta_2)) # NOT A STRING\n",
    "        \n",
    "        inner_rad = 0.5*(float(arm_1_dict['r_start']) + float(arm_2_dict['r_start'])) # Averaging the inner distance to both arcs            \n",
    "        outer_rad = 0.5*(float(arm_1_dict['r_end']) + float(arm_2_dict['r_start'])) # Averaging outer distance\n",
    "        \n",
    "        #pitch_angle = 0.5*abs(float(arm_1_dict['pitch_angle']) + float(arm_2_dict['pitch_angle']))\n",
    "        #print(pitch_angle)\n",
    "        \n",
    "        #alpha_out = scale_to_string(0.06*pitch_angle - 0.12)\n",
    "        \n",
    "    \n",
    "        try:\n",
    "            cumul_rot_out = abs((arc_init_theta % 360)/(log(inner_rad)/log(outer_rad)))\n",
    "        except:\n",
    "            print(\"Couldn't calculate theoretical theta_out. Proceeding.\")\n",
    "        \n",
    "        arcs_file.close()\n",
    "                              \n",
    "        inner_rad = scale_to_string(inner_rad, scale_fact)\n",
    "        outer_rad = scale_to_string(outer_rad, scale_fact)\n",
    "\n",
    "    return inner_rad, outer_rad, cumul_rot_out #, alpha_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_sdss_info(galaxy_name): # to grab petromag and also psf parameter things\n",
    "    \n",
    "    try:\n",
    "        #star_dl_filename = glob_name('star_dl','star_dl','.csv')\n",
    "        star_dl_filename = glob_name('star_dl','star_dl','.csv')\n",
    "        star_dl_file = open(star_dl_filename, 'r')\n",
    "        \n",
    "    except:\n",
    "        print(\"Can't open to read csv with star information used for Galaxy \", galaxy_name)\n",
    "        print(\"Check Sparcfire output or directories. Proceeding with default values.\")\n",
    "\n",
    "        # Defaults go here\n",
    "        run_out = '0'\n",
    "        rerun_out = '0'\n",
    "        camcol_out = '0'\n",
    "        field_out = '0'\n",
    "        rowc_out = '0'\n",
    "        colc_out = '0'\n",
    "        petromag_out = '16'\n",
    "\n",
    "    else:\n",
    "        star_df = pd.read_csv(star_dl_file, index_col=0)\n",
    "        #csv_gal_name = star_df.columns[0]\n",
    "        try:\n",
    "            temp = star_df.at[galaxy_name, 'run']\n",
    "            \n",
    "        except:\n",
    "            #print(star_df.loc[:, 'name'])\n",
    "            print(\"Can't find the galaxy: \", galaxy_name, \" in our repository.\")\n",
    "            print(\"Proceeding with default values and no PSF.\")\n",
    "            run_out = '0'\n",
    "            rerun_out = '0'\n",
    "            camcol_out = '0'\n",
    "            field_out = '0'\n",
    "            rowc_out = '0'\n",
    "            colc_out = '0'\n",
    "            petromag_out = '16'\n",
    "            \n",
    "        else:\n",
    "            galaxy_band = galaxy_name[-1]\n",
    "            \n",
    "            run_out = ' run: ' + scale_to_string(star_df.at[galaxy_name, 'run'])\n",
    "            rerun_out = ' rerun: ' + scale_to_string(star_df.at[galaxy_name, 'rerun'])\n",
    "            camcol_out = ' camcol: ' + scale_to_string(star_df.at[galaxy_name, 'camcol'])\n",
    "            field_out = ' field: ' + scale_to_string(star_df.at[galaxy_name, 'field'])\n",
    "            rowc_out = ' row: ' + scale_to_string(star_df.at[galaxy_name, 'rowC'])\n",
    "            colc_out = ' col: ' + scale_to_string(star_df.at[galaxy_name, 'colC'])\n",
    "            petromag_out = scale_to_string(star_df.at[galaxy_name, 'petroMag_' + galaxy_band])\n",
    "        \n",
    "        #csv_in = list(reader)\n",
    "        #if galaxy_name in csv_in:\n",
    "        #    gal_index = csv_in.index(galaxy_name)\n",
    "        \n",
    "        #    for row in csv_in:\n",
    "        #        if galaxy_name in row:\n",
    "        #            run_out = row['run']\n",
    "        #            rerun_out = row['rerun']\n",
    "        #            camcol_out = ['camcol']\n",
    "        #            field_out = ['field']\n",
    "        #            petromag = row['PetroMag_r']\n",
    "        \n",
    "    return run_out, rerun_out, camcol_out, field_out, rowc_out, colc_out, petromag_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_feedme(path, list_in):\n",
    "    \n",
    "    file_path = \"/\".join([\".\", path, \"\"]) + 'autogen_feedme_galfit.in'\n",
    "    galfit_in = open(file_path, 'w')\n",
    "\n",
    "    for value in feedme_list:\n",
    "        galfit_in.write(value + '\\n')\n",
    "\n",
    "    galfit_in.close()\n",
    "    return file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    count = 0\n",
    "    paths_to_feedme = []\n",
    "    \n",
    "    filenames_in, galaxy_names, filenames_out = get_galaxy_names_list()\n",
    "    \n",
    "    for galaxy in filenames_out:\n",
    "    \n",
    "        gname = galaxy_names[count]\n",
    "        #print(gname)\n",
    "        \n",
    "        x1crop, x2crop, y1crop, y2crop = autocrop_grab(gname, galaxy)\n",
    "    \n",
    "        scale = (float(x2crop)-float(x1crop))/256\n",
    "    \n",
    "        bulge_rad, bulge_axis_ratio, pos_angle_bulge, \\\n",
    "            center_pos_x, center_pos_y, \\\n",
    "            disk_maj_axs_len, pos_angle_disk, pos_angle_power, \\\n",
    "            axis_ratio, max_arc, spin_dir, \\\n",
    "            est_arcs, inclination, bar_candidate, \\\n",
    "            alpha = tsv_information(gname, galaxy, scale)\n",
    "    \n",
    "        in_rad, out_rad, cumul_rot = csv_information(gname, galaxy, scale)\n",
    "    \n",
    "        run, rerun, camcol, field, psf_row, psf_col, petromag = csv_sdss_info(gname) \n",
    "    \n",
    "        cumul_rot = scale_to_string((cumul_rot + float(pos_angle_disk)) % 360) #+ float(pos_angle_power) \n",
    "    \n",
    "        if bar_candidate.upper() == \"FALSE\": # According to Chien, if no bar, then r_in = 0 since r_in is more a mathematical construct relating to the bar\n",
    "            in_rad = \"0\" #unsure if I'll keep this...\n",
    "            #pass\n",
    "        elif bar_candidate.upper() == \"TRUE\":\n",
    "            pass\n",
    "        else:\n",
    "            print(bar_candidate)\n",
    "            print(\"bar_candidate is neither TRUE nor FALSE in the TSV. Check sparcfire output.\")\n",
    "            print(\"Defaulting the average inner distance to the arms.\")\n",
    "    \n",
    "    \n",
    "        # Initializing Feedme\n",
    "        feedme_list = []\n",
    "    \n",
    "        #To reconstruct the z PSF (i.e., the 5th HDU) at the position (row, col) = (500, 600) from run 1336, column 2, field 51 you’d say:\n",
    "        #read_PSF psField-001336-2-0051.fit 5 500.0 600.0 foo.fit\n",
    "\n",
    "        feedme_list.append(\"#\" + run + camcol + field + \"; HDU: z\" + psf_row + psf_col)\n",
    "        feedme_list.append(\"\")\n",
    "        # Image and Galfit Control Param\n",
    "        feedme_list.append(\"A) ./\" + filenames_in[count]) \n",
    "        feedme_list.append(\"B) ./sparcfire-tmp/galfits/\" + gname + \"_out.fits\")\n",
    "        feedme_list.append(\"C) none\")\n",
    "        feedme_list.append(\"D) none\")\n",
    "        feedme_list.append(\"E) 1\")\n",
    "        feedme_list.append(\"F) ./sparcfire-tmp/galfit_masks/\" + gname + \"_star-rm.fits\") #I hate to make this verbose but I have no other choice in this case...\n",
    "        feedme_list.append(\"G) ./constraints.txt\")\n",
    "        feedme_list.append(\"H) \" + x1crop + \" \" + x2crop + \" \" + y1crop + \" \" + y2crop)\n",
    "        feedme_list.append(\"K) 10  10\") \n",
    "        feedme_list.append(\"J) 24.8\") # SDSS\n",
    "        feedme_list.append(\"K) 0.396  0.396\") # SDSS\n",
    "        feedme_list.append(\"O) regular\")\n",
    "        feedme_list.append(\"P) 0\")\n",
    "        feedme_list.append(\"\")\n",
    "    \n",
    "        # Sersic 1\n",
    "        # Fixing as much as I can here... it's not exactly a priority.\n",
    "        feedme_list.append(\"# Component number: 1\")\n",
    "        feedme_list.append(\"0) sersic\")\n",
    "        feedme_list.append(\"1) \" + center_pos_x + \" \" + center_pos_y + \"   0  0\")\n",
    "        feedme_list.append(\"3) \" + str(float(petromag) + 3.0) + \" 1\") # Initial guess goes here\n",
    "        feedme_list.append(\"4) \" + bulge_rad + \"0\") \n",
    "        feedme_list.append(\"5) 4  1\") # According to other paper GALFIT usually doesn't have a problem with the index\n",
    "        feedme_list.append(\"6) 0  0\")    \n",
    "        feedme_list.append(\"7) 0  0\")    \n",
    "        feedme_list.append(\"8) 0  0\")    \n",
    "        # According to other papers, bulge (esp. in spiral galaxies) averages to about 2 so this is a good starting place\n",
    "        # see https://ned.ipac.caltech.edu/level5/Sept11/Buta/Buta9.html\n",
    "        feedme_list.append(\"9) \" + axis_ratio + \" 0\")  \n",
    "        feedme_list.append(\"10) \" + pos_angle_bulge + \" 0\") \n",
    "        feedme_list.append(\"\")\n",
    "    \n",
    "        # Sersic 2\n",
    "        feedme_list.append(\"# Component number: 2\")\n",
    "        feedme_list.append(\"0) sersic\")\n",
    "        feedme_list.append(\"1) \" + center_pos_x + \" \" + center_pos_y + \"   0  0\")\n",
    "        feedme_list.append(\"3) \" + petromag + \"  1\") # Initial guess goes here\n",
    "        feedme_list.append(\"4) \" + disk_maj_axs_len + \" 1\") # Use this for effective radius? Also 0 this one out? Will have to see how well it works in practice\n",
    "        feedme_list.append(\"5) 1  1\") # Classical disk follows Sersic n = 1 so good place to start (per Readme Exponential profile)\n",
    "        feedme_list.append(\"6) 0  0\")    \n",
    "        feedme_list.append(\"7) 0  0\")    \n",
    "        feedme_list.append(\"8) 0  0\")    \n",
    "        feedme_list.append(\"9) \" + axis_ratio + \" 1\") # Exactly what we're looking for... may have to adjust due to spiral arm degeneracy concerns (m=2)\n",
    "        feedme_list.append(\"10) \" + pos_angle_disk + \" 1\") #90  1\") # fixing this to 'normal' 0 so that we can JUST rotate power function\n",
    "        feedme_list.append(\"\")\n",
    "    \n",
    "        # Power\n",
    "        feedme_list.append(\"R0) power\")\n",
    "        feedme_list.append(\"R1) \" + in_rad + \"  0\") # Chosen based on where *detection* of arms usually start\n",
    "        feedme_list.append(\"R2) \" + out_rad + \"  0\")\n",
    "        feedme_list.append(\"R3) \" + spin_dir + cumul_rot + \"  1\") # See calc above\n",
    "        feedme_list.append(\"R4) \" + alpha + \"  1\") # Another good thing to automate via Sparcfire \n",
    "        feedme_list.append(\"R9) \" + inclination + \" 1\") # see if can't 0 this one out... \n",
    "        feedme_list.append(\"R10) 0  1\")#+ pos_angle_power + \" 1\") # Always more to discover, looks like all the images are mirrored across the y axis.\n",
    "\n",
    "        f1 = 0.05\n",
    "        f3 = 0.02\n",
    "        f4 = 0.005\n",
    "        f5 = 0.001\n",
    "        if est_arcs <= 2:\n",
    "            f3 -= 0.015\n",
    "            f5 = 0\n",
    "            f4 = 0\n",
    "        elif est_arcs == 3:\n",
    "            f3 += 0.03\n",
    "            f4 += 0.005\n",
    "            f5 = 0\n",
    "        elif est_arcs >= 4:\n",
    "            f3 += 0.03\n",
    "            f4 += 0.015\n",
    "            f5 += 0.014\n",
    "        else:\n",
    "            print(\"Something went wrong with the estimation of arcs! Check chirality_votes_maj in csv. Proceeding\")\n",
    "        # ---- Fourier modes. May need to add more at some point (?)\n",
    "        feedme_list.append(\"F1) \" + str(f1) + \" 45  1  1\") # Need to experiment with amplitude and phase angle for better understanding of this\n",
    "        feedme_list.append(\"F3) \" + str(f3) + \" 25  1  1\")\n",
    "        feedme_list.append(\"#F4) \" + str(f4) + \" 4  1  1\")\n",
    "        feedme_list.append(\"#F5) \" + str(f5) + \" 6  1  1\")  \n",
    "        feedme_list.append(\"\")\n",
    "    \n",
    "        # Sky -- Necessary?\n",
    "        feedme_list.append(\"# Component number: 3\")\n",
    "        feedme_list.append(\"0) sky\")\n",
    "        feedme_list.append(\"1) 1000  1\")\n",
    "        feedme_list.append(\"2) 0  1\")\n",
    "        feedme_list.append(\"3) 0  1\")\n",
    "                       \n",
    "        count += 1\n",
    "    \n",
    "        paths_to_feedme.append(write_to_feedme(galaxy, feedme_list))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
