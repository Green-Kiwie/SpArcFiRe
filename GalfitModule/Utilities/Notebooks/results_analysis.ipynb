{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4247750-5fc9-4be0-8102-06041cdb7c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install --user astropy\n",
    "#!pip3 install --user kaleido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58b85295-242d-405b-ba3a-260bf8f72535",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import astropy as ap\n",
    "import pandas as pd\n",
    "from astropy.io import fits\n",
    "import scipy.linalg as slg\n",
    "from scipy.stats import norm\n",
    "import scipy.stats\n",
    "from math import ceil\n",
    "import csv\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from plotly.offline import iplot\n",
    "import kaleido\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.colors as colors\n",
    "# from matplotlib.colors import LinearSegmentedColormap\n",
    "import glob\n",
    "import os\n",
    "# These are in Functions\n",
    "from os.path import join as pj\n",
    "# from os.path import abspath as absp\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.display import display\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import PIL\n",
    "import pickle\n",
    "\n",
    "import sys\n",
    "from collections import namedtuple as nt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a7e0271-d54c-42e1-a9e5-9527b166c8d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ[\"SPARCFIRE_HOME\"] = \"/home/portmanm/sparcfire_matt/\"\n",
    "\n",
    "_HOME_DIR = os.path.expanduser(\"~\")\n",
    "try:\n",
    "    _SPARCFIRE_DIR = os.environ[\"SPARCFIRE_HOME\"]\n",
    "    _MODULE_DIR = pj(_SPARCFIRE_DIR, \"GalfitModule\")\n",
    "except KeyError:\n",
    "    if __name__ == \"__main__\":\n",
    "        print(\"SPARCFIRE_HOME is not set. Please run 'setup.bash' inside SpArcFiRe directory if not done so already.\")\n",
    "        print(\"Checking the current directory for GalfitModule, otherwise quitting.\")\n",
    "            \n",
    "        _MODULE_DIR = pj(os.getcwd(), \"GalfitModule\")\n",
    "        \n",
    "        if not exists(_MODULE_DIR):\n",
    "            raise Exception(\"Could not find GalfitModule!\")\n",
    "    \n",
    "sys.path.append(_MODULE_DIR)\n",
    "from Classes.Components import *\n",
    "from Classes.Containers import *\n",
    "from Classes.FitsHandlers import *\n",
    "from Functions.helper_functions import *\n",
    "\n",
    "all_results = nt(\"all_results\", [\"full_df\", \"success_df\", \"not_success_df\", \"by_eye_success_df\", \"by_eye_not_success_df\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de93171e-4ad6-4e16-acd3-8c302cb5d8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Defunct\n",
    "# def check_galfit_chi(gal_name, base_path):\n",
    "#     # An example line\n",
    "#     # # Chi^2/nu = 4.661,  Chi^2 = 12025.575,  Ndof = 2580\n",
    "    \n",
    "#     #galfit_txt_out = \"galfit.01\" # in the future galfit.01 may change\n",
    "#     filename = os.path.join(base_path, gal_name, galfit_txt_out)\n",
    "#     with open(filename, \"r\") as f:\n",
    "#         for line in f:\n",
    "#             if \"Chi\" in line:\n",
    "#                 chi_line = line.strip(\"# \")\n",
    "    \n",
    "#     # This also works but it's quite devious...\n",
    "#     # chi_line.replace(\"^\", \"\").replace(\"/\", \"_\").replace(\",  \", \"\\n\").lower()\n",
    "#     # exec(chi_line)\n",
    "    \n",
    "#     out_vals = chi_line.split(\",\")\n",
    "#     chi2_nu = float(out_vals[0].strip().split(\"=\")[-1])\n",
    "#     chi2 = float(out_vals[1].strip().split(\"=\")[-1])\n",
    "#     ndof = int(out_vals[2].strip().split(\"=\")[-1])\n",
    "    \n",
    "#     return chi2_nu, chi2, ndof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47be9c91-a9a6-4971-b9d2-3be76d4b9d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_total_galaxies(in_dir = \"sparcfire-in\", out_dir = \"sparcfire-out\"):   \n",
    "    all_gnames_in  = find_files(in_dir, \"123*\", \"f\")\n",
    "    all_gnames_out = find_files(out_dir, \"123*\", \"d\")\n",
    "    total_galaxies = min(len(all_gnames_in), len(all_gnames_out))\n",
    "    if not total_galaxies:\n",
    "        total_galaxies  = max(len(all_gnames_in), len(all_gnames_out))\n",
    "        \n",
    "    return total_galaxies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee884139-38d5-41a0-8415-78651519848c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_residual_df(\n",
    "    out_dir, \n",
    "    basename, \n",
    "    method = \"nmr_x_1-p\", \n",
    "    verbose = True\n",
    "):\n",
    "    \n",
    "    pickle_filename = pj(out_dir, basename, sorted(find_files(pj(out_dir, basename), f'{basename}_output_results*.pkl', \"f\"))[-1])\n",
    "    \n",
    "    residual_df  = pd.read_pickle(pickle_filename)\n",
    "    # temp_df = deepcopy(residual_df)\n",
    "    # Setting residual columns\n",
    "    #residual_df[\"KS_P\"] = 1 - residual_df[\"KS_P\"]\n",
    "    if method == \"nmr_x_1-p\":\n",
    "        result_of_method = (1 - residual_df[\"KS_P\"])*residual_df[\"NMR\"]\n",
    "    elif method == \"nmr_neg_log\":\n",
    "        result_of_method = residual_df[\"NMR\"]/-np.log(residual_df[\"KS_P\"] + 1e-10)\n",
    "    elif method == \"W_quality\":\n",
    "        result_of_method = residual_df[\"KS_P\"]/residual_df[\"W_NMR\"]\n",
    "    else:\n",
    "        raise Exception(f\"Method given: {method} is not a valid method (yet).\")\n",
    "    \n",
    "    residual_df[method] = result_of_method\n",
    "    \n",
    "    # Valid meaning NMR was successfully calculated\n",
    "    #cols_to_drop = [col for col in residual_df.columns if col.endswith(\"_sky_2\")]\n",
    "    #valid_spiral_df = residual_df.drop(columns = cols_to_drop).dropna()\n",
    "\n",
    "    # rename sky_2 to sky_3 for non-spirals to be inline with everything else\n",
    "    # this would be for potential comparison down the line\n",
    "    cols_to_merge = [col for col in residual_df.columns if col.endswith(\"_sky_3\") or col.endswith(\"_sky_4\")]\n",
    "    #_ = [residual_df[col].fillna(residual_df[f\"{col[:-1]}2\"], inplace = True) for col in cols_to_merge]\n",
    "    cols_to_drop  = [col for col in residual_df.columns if col.endswith(\"_sky_2\") or col.endswith(\"_sky_3\")]#  + [\"KS_STAT\"]\n",
    "    residual_df.drop(columns = cols_to_drop, inplace = True)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"{len(residual_df)} galaxy models generated.\")\n",
    "        cutoff_val = 0.007\n",
    "        residual_cutoff = residual_df[method] <= cutoff_val\n",
    "        print(f\"{sum(residual_cutoff)} models pass score cutoff.\")\n",
    "        \n",
    "    \n",
    "    return residual_df.sort_values(by = method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f5cd1a4-3cf8-4c58-9178-ce87b4cd9278",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_galaxy_csv(out_dir, basename, pre_post):\n",
    "    \n",
    "    field = \" pa_alenWtd_avg_domChiralityOnly\"\n",
    "    # {basename}_ uneccessary because different *galfit* runs \n",
    "    # should have same sparcfire output\n",
    "    fname = pj(out_dir, basename, f\"{basename}_{pre_post}_galfit_galaxy.csv\")\n",
    "    sparc_output_csv = pd.read_csv(fname, #pj(out_dir, f\"pre_galfit_galaxy.csv\"),\n",
    "                                       index_col = \"name\",\n",
    "                                       on_bad_lines = \"warn\",\n",
    "                                       usecols   = [\"name\", field], # , \" iptSz\"],\n",
    "                                       #na_values = \"NaN\",\n",
    "                                       #dtype     = {field : float} #, \" iptSz\" : str}#, \"name\" : str}\n",
    "                                      )#.loc[:, field]\n",
    "    #sparc_output_csv.index.name = None\n",
    "    sparc_output_csv[field] = sparc_output_csv[field].astype(float)\n",
    "    sparc_output_csv.index  = sparc_output_csv.index.map(str)\n",
    "    #sparc_output_csv[\" iptSz\"] = sparc_output_csv[\" iptSz\"].str.extract(r\"([0-9]+)\").astype(float)\n",
    "\n",
    "    #sparc_output_csv[\"pre_sign\"] = np.sign(sparc_output_csv[field])\n",
    "    sparc_output_csv.rename(columns = {field : f\"galaxy_{pre_post}_pa\"}, inplace = True)\n",
    "    \n",
    "    return sparc_output_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a5e2491-9d83-4573-8826-ba9d91f5b8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_galaxy_arcs_csv(out_dir, basename, pre_post, **kwargs):\n",
    "    \n",
    "    field_pa   = kwargs.get(\"field_pa\"  , \"pitch_angle\")\n",
    "    field_alen = kwargs.get(\"field_alen\", \"arc_length\")\n",
    "    name_col   = kwargs.get(\"name_col\"  , \"gxyName\")\n",
    "\n",
    "    fname = pj(out_dir, basename, f\"{basename}_{pre_post}_galfit_galaxy_arcs.csv\")\n",
    "    sparc_output_arcs_csv = pd.read_csv(fname, \n",
    "                                       index_col = name_col,\n",
    "                                       usecols   = [name_col, field_pa, field_alen],\n",
    "                                       dtype     = {field_pa : float, field_alen : float} #, name_col : str}\n",
    "                                      )#.loc[:, field]\n",
    "    #sparc_output_csv.index.name = None\n",
    "    sparc_output_arcs_csv.index = sparc_output_arcs_csv.index.map(str)\n",
    "\n",
    "    # Filtering for pure circles and near circles\n",
    "    sparc_output_arcs_csv = sparc_output_arcs_csv[abs(sparc_output_arcs_csv[field_pa ]) > 1]\n",
    "\n",
    "    #sparc_output_arcs_csv = pd.concat([sparc_output_arcs_csv, pre_sparc_output_csv], axis = 1)\n",
    "    #sparc_output_arcs_csv[\"sign\"] = np.sign(sparc_output_arcs_csv[field])\n",
    "\n",
    "    # Keeps only arms which align with dom chirality only\n",
    "    # sparc_output_arcs_csv[\"check\"] = [\n",
    "    #     row[\"sign\"] + pre_sparc_output_csv.loc[i, \"pre_sign\"] \n",
    "    #     if i in pre_sparc_output_csv.index \n",
    "    #     else None \n",
    "    #     for i, row in sparc_output_arcs_csv.iterrows()\n",
    "    # ]\n",
    "\n",
    "    #sparc_output_arcs_csv = sparc_output_arcs_csv[abs(sparc_output_arcs_csv.loc[:, \"check\"]) == 2].drop(columns = [\"sign\", \"check\"])\n",
    "    sparc_output_arcs_top3 = sparc_output_arcs_csv.groupby(name_col).head(3).reset_index()\n",
    "    sparc_output_arcs_top3[f\"{pre_post}_sign\"] = np.sign(sparc_output_arcs_top3.pitch_angle)\n",
    "\n",
    "    dom_sign = np.sign(sparc_output_arcs_top3.groupby(name_col).sum()[f\"{pre_post}_sign\"])\n",
    "    sparc_output_arcs_top3 = sparc_output_arcs_top3.join(dom_sign, rsuffix = \"_dom\", on = name_col)\n",
    "\n",
    "    cond = sparc_output_arcs_top3[f\"{pre_post}_sign_dom\"] == sparc_output_arcs_top3[f\"{pre_post}_sign\"]\n",
    "    sparc_output_arcs_top2 = sparc_output_arcs_top3[cond].groupby(name_col).head(2).reset_index().drop(columns = [f\"{pre_post}_sign_dom\", \"index\"])\n",
    "\n",
    "    #pre_sparc_output_top2.rename(columns = {field : \"pre_pa\"}, inplace = True)\n",
    "    #pre_sparc_output_csv.dropna(inplace=True)\n",
    "    return sparc_output_arcs_top2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc9d4a2f-ad1d-465a-9de9-dab0ffec7ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_arcs_output(sparc_output_arcs_top2, pre_post, **kwargs):\n",
    "    \n",
    "    field_pa   = kwargs.get(\"field_pa\"  , \"pitch_angle\")\n",
    "    field_alen = kwargs.get(\"field_alen\", \"arc_length\")\n",
    "    name_col   = kwargs.get(\"name_col\"  , \"gxyName\")\n",
    "    \n",
    "    single_arm = sparc_output_arcs_top2[~sparc_output_arcs_top2.duplicated(name_col, keep = False)]\n",
    "    single_arm.loc[:, field_pa] = 0\n",
    "    #single_arm.loc[:, \"arc_length\"]  = 0\n",
    "\n",
    "    filled_in = pd.concat([sparc_output_arcs_top2, single_arm], ignore_index = True)\n",
    "    str_fill = [f\"{pre_post}_pa1\", f\"{pre_post}_pa2\"] * (len(filled_in) // 2)\n",
    "    filled_in[\"temp1\"] = str_fill\n",
    "\n",
    "    str_fill = [f\"{pre_post}_alen1\", f\"{pre_post}_alen2\"] * (len(filled_in) // 2)\n",
    "    filled_in[\"temp2\"] = str_fill\n",
    "\n",
    "    #filled_in = filled_in.reset_index().drop(columns = [\"index\"])\n",
    "    sp_out = filled_in.pivot_table(index = name_col, columns = [\"temp1\", \"temp2\"], values = [field_pa, field_alen])\n",
    "\n",
    "    sp_out = sp_out.droplevel(0, axis = 1).droplevel(0, axis = 1)\n",
    "    sp_out.columns = [f'{pre_post}_alen1', f'{pre_post}_alen2', f'{pre_post}_pa1', f'{pre_post}_pa2']\n",
    "    \n",
    "    return sp_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07dbb8f0-f2fd-4c0e-a3cd-76597837bd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def before_after_galfit_comparison(all_sparc_out, pre_sparc_output_csv, post_sparc_output_csv):\n",
    "    \n",
    "    before_after_galfit_df = deepcopy(all_sparc_out)#.dropna() #full_df.dropna(subset = [\"post_pa\"])\n",
    "    #before_after_galfit_df = before_after_galfit_df[np.sign(before_after_galfit_df.loc[:, \"pre_pa\"]) != np.sign(before_after_galfit_df.loc[:, \"post_pa\"])]\n",
    "\n",
    "    before_after_galfit_df[\"chiral_agreement\"] = np.sign(before_after_galfit_df[\"pre_pa1\"]) == np.sign(before_after_galfit_df[\"post_pa1\"])\n",
    "\n",
    "    before_after_galfit_df[\"pre_pa1\"]  = abs(before_after_galfit_df[\"pre_pa1\"])\n",
    "    before_after_galfit_df[\"pre_pa2\"]  = abs(before_after_galfit_df[\"pre_pa2\"])\n",
    "    before_after_galfit_df[\"post_pa1\"] = abs(before_after_galfit_df[\"post_pa1\"])\n",
    "    before_after_galfit_df[\"post_pa2\"] = abs(before_after_galfit_df[\"post_pa2\"])\n",
    "\n",
    "\n",
    "    before_after_galfit_df[\"1-1\"] = abs(before_after_galfit_df[\"pre_pa1\"] - before_after_galfit_df[\"post_pa1\"])\n",
    "    before_after_galfit_df[\"2-2\"] = abs(before_after_galfit_df[\"pre_pa2\"] - before_after_galfit_df[\"post_pa2\"])\n",
    "    before_after_galfit_df[\"1-2\"] = abs(before_after_galfit_df[\"pre_pa1\"] - before_after_galfit_df[\"post_pa2\"])\n",
    "    before_after_galfit_df[\"2-1\"] = abs(before_after_galfit_df[\"pre_pa2\"] - before_after_galfit_df[\"post_pa1\"])\n",
    "\n",
    "    before_after_galfit_df[\"mean-1122\"]  = before_after_galfit_df[[\"1-1\",\"2-2\"]].mean(axis = \"columns\")\n",
    "    before_after_galfit_df[\"mean-1221\"]  = before_after_galfit_df[[\"1-2\",\"2-1\"]].mean(axis = \"columns\")\n",
    "\n",
    "    before_after_galfit_df[\"min_diff\"]   = before_after_galfit_df[[\"mean-1122\", \"mean-1221\"]].min(axis = 1)\n",
    "\n",
    "    before_after_galfit_df[\"best_diffs\"] = [\n",
    "        (row[\"1-1\"], row[\"2-2\"]) if np.mean((row[\"1-1\"], row[\"2-2\"])) == row[\"min_diff\"] \n",
    "        else (row[\"1-2\"], row[\"2-1\"]) \n",
    "        for _, row in before_after_galfit_df.iterrows()\n",
    "    ]\n",
    "\n",
    "    before_after_galfit_df[\"pa_diff1\"], before_after_galfit_df[\"pa_diff2\"] = zip(*before_after_galfit_df[\"best_diffs\"])\n",
    "    #before_after_galfit_df[\"best_diff2\"] = [row[\"2-2\"] if np.mean((row[\"1-1\"], row[\"2-2\"])) == row[\"min_diff\"] else row[\"2-1\"] for _, row in before_after_galfit_df.iterrows()]\n",
    "    before_after_galfit_df[\"pa_diff_galaxy\"] = abs(abs(post_sparc_output_csv[\"galaxy_post_pa\"]) - abs(pre_sparc_output_csv[\"galaxy_pre_pa\"]))# < 15\n",
    "\n",
    "    # min(2_arm_length)/max(2_arm_length) > 0.7, verify that this is valid by eye\n",
    "    #before_after_galfit_df[\"alen_ratio\"] = post_sparc_output_csv[\" iptSz\"]*before_after_galfit_df[[\"pre_alen1\", \"pre_alen2\"]].min(axis = 1)/(pre_sparc_output_csv[\" iptSz\"]*before_after_galfit_df[[\"post_alen1\", \"post_alen2\"]].max(axis = 1))\n",
    "    before_after_galfit_df[\"alen_ratio\"] = before_after_galfit_df[[\"post_alen1\", \"post_alen2\"]].min(axis = 1)/before_after_galfit_df[[\"post_alen1\", \"post_alen2\"]].max(axis = 1)\n",
    "    #before_after_galfit_df.drop(columns = [\"pre_sign\", \"post_sign\"], inplace = True)\n",
    "\n",
    "    # before_after_galfit_df.loc[:, \"within_15_degrees_pre\"]  = before_after_galfit_df.loc[:, \"diff_pre\"] < 15\n",
    "    # before_after_galfit_df.loc[:, \"within_15_degrees_post\"] = before_after_galfit_df.loc[:, \"diff_post\"] < 15\n",
    "    #before_after_galfit_df.sort_values(by = [\"post_pa\"])\n",
    "    before_after_galfit_df = before_after_galfit_df.drop(columns = before_after_galfit_df.columns[9:-4])\n",
    "    \n",
    "    return before_after_galfit_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16e8bd45-f542-48a8-8923-1e07f5cbb9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_everything(residual_df, before_after_galfit_df):\n",
    "    full_df = residual_df.join(before_after_galfit_df)\n",
    "    full_df = full_df[full_df.index.notnull()].sort_values(by = method)\n",
    "\n",
    "    #full_df.dropna(subset = [\"pa_diff1\", \"pa_diff2\", \"pa_diff_galaxy\"], how = \"all\", inplace = True)\n",
    "    #full_df.fillna(subset = [\"pa_diff1\", \"pa_diff2\", \"pa_diff_galaxy\"], how = \"all\", inplace = True)\n",
    "    full_df[\"min_pa_diff\"] = full_df[[\"pa_diff1\", \"pa_diff2\", \"pa_diff_galaxy\"]].min(axis = 1)\n",
    "    \n",
    "    return full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "850f1b7e-eb54-45d1-b759-dbfffc197ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_success(\n",
    "    full_df, \n",
    "    in_dir = \"sparcfire-in\", \n",
    "    out_dir = \"sparcfire-out\",\n",
    "    sparcfire_processed   = None,\n",
    "    flip_chiral_agreement = False,\n",
    "    verbose = True\n",
    "):\n",
    "    cutoff_val = 0.007\n",
    "    residual_cutoff = full_df[\"nmr_x_1-p\"] <= cutoff_val\n",
    "    #pa_cutoff = (full_df[\"pa_diff1\"] < 10) | (full_df[\"pa_diff2\"] < 10)\n",
    "    pa_cutoff   = full_df[\"min_pa_diff\"] < 10\n",
    "    alen_cutoff = full_df[\"alen_ratio\"] > 0.5 #[True]\n",
    "    sign_cutoff = full_df[\"chiral_agreement\"].astype(bool)\n",
    "    if flip_chiral_agreement:\n",
    "        sign_cutoff = ~sign_cutoff\n",
    "\n",
    "    success_df     = full_df[residual_cutoff & pa_cutoff & alen_cutoff & sign_cutoff]\n",
    "    not_success_df = full_df[~(residual_cutoff & pa_cutoff & alen_cutoff & sign_cutoff)]\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"{len(full_df)} processed by sparcfire\")\n",
    "        print(f\"{sum(residual_cutoff)} pass score cutoff\")\n",
    "        print(f\"{sum(pa_cutoff)} pass pitch angle cutoff\")\n",
    "        print(f\"{sum(alen_cutoff)} pass arm length ratio cutoff\")\n",
    "        print(f\"{sum(sign_cutoff)} pass chiral agreement\")\n",
    "        print(f\"{len(success_df)} or {100*len(success_df)/len(full_df):.2f}% ({len(success_df)}/{len(full_df)}) succeed by SpArcFiRe+Score\")\n",
    "        if sparcfire_processed is not None:\n",
    "            sparcfire_processed = full_df.dropna(subset = [\"pa_diff1\", \"pa_diff2\", \"pa_diff_galaxy\"], how = \"all\")\n",
    "        \n",
    "        print(f\"{total_galaxies - len(sparcfire_processed)}/{total_galaxies} models failed reprocessing by SpArcFiRe\")\n",
    "        \n",
    "        #print(f\"Total success less 24% false positive -- {len(success_df)*.76:.0f}\")\n",
    "        #print(f\"Total success less 24% false positive + 24% false negative -- {len(not_success_df)*0.24+len(success_df)*.76:.0f}\")\n",
    "        #print(f\"Estimated total success % -- {100*(len(not_success_df)*0.24+len(success_df)*.76)/len(full_df):.0f}%\")\n",
    "    \n",
    "    return success_df, not_success_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28a24bed-8970-4c51-b8a9-83d51e80bdd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_by_eye_data(\n",
    "    out_dir, \n",
    "    basename, \n",
    "    residual_df, \n",
    "    full_df,\n",
    "    sparcfire_processed = None,\n",
    "    subset = None,  \n",
    "    verbose = True\n",
    "):\n",
    "    \n",
    "    with open(f\"{pj(out_dir, basename, basename)}_by-eye_success.txt\", \"r\") as f:\n",
    "        raw_by_eye_success_galaxies = [i.split(\"_\")[0].strip() for i in f.readlines()]\n",
    "\n",
    "    with open(f\"{pj(out_dir, basename, basename)}_by-eye_not_success.txt\", \"r\") as f:\n",
    "        raw_by_eye_not_success_galaxies = [i.split(\"_\")[0].strip() for i in f.readlines()]\n",
    "        \n",
    "    by_eye_success_galaxies = [i for i in raw_by_eye_success_galaxies if i in full_df.index]\n",
    "    by_eye_not_success_galaxies = [i for i in raw_by_eye_not_success_galaxies if i in full_df.index]\n",
    "    if sparcfire_processed is not None:\n",
    "        sparcfire_processed = full_df.dropna(subset = [\"pa_diff1\", \"pa_diff2\", \"pa_diff_galaxy\"], how = \"all\")\n",
    "    \n",
    "    if verbose:\n",
    "        \n",
    "        total = len(residual_df)\n",
    "        if subset:\n",
    "            total = subset\n",
    "            print(f\"Working on a subset of {total} galaxies\")\n",
    "            \n",
    "        align = len(f\"{len(by_eye_success_galaxies)}/{len(raw_by_eye_success_galaxies)}\")\n",
    "        print(f\"Number of *total* by eye successful galaxies\")\n",
    "        print(f\"{len(raw_by_eye_success_galaxies):<{align}} => {len(raw_by_eye_success_galaxies)/total*100:.2f}%\")\n",
    "        print(f\"Number of by eye successful galaxies that SpArcFiRe *could* process\")\n",
    "        by_eye_processed = [i for i in sparcfire_processed.index if i in raw_by_eye_success_galaxies]\n",
    "        print(f\"{len(by_eye_processed)}/{len(raw_by_eye_success_galaxies)} => {len(by_eye_processed)/len(raw_by_eye_success_galaxies)*100:.2f}%\")\n",
    "        \n",
    "        print()\n",
    "        \n",
    "        align = len(f\"{len(by_eye_not_success_galaxies)}/{len(raw_by_eye_not_success_galaxies)}\")\n",
    "        print(f\"Number of *total* by eye not successful galaxies\")\n",
    "        \n",
    "        print(f\"{len(raw_by_eye_not_success_galaxies):<{align}} => {len(raw_by_eye_not_success_galaxies)/total*100:.2f}%\")\n",
    "        print(f\"Number of by eye not successful galaxies that SpArcFiRe *could* process\")\n",
    "        by_eye_processed = [i for i in sparcfire_processed.index if i in raw_by_eye_success_galaxies]\n",
    "        print(f\"{len(by_eye_processed)}/{len(raw_by_eye_not_success_galaxies)} => {len(by_eye_processed)/len(raw_by_eye_not_success_galaxies)*100:.2f}%\")\n",
    "    \n",
    "    return by_eye_success_galaxies, by_eye_not_success_galaxies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f49f540e-82da-4e7b-8c61-6779c16075a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_false_positive_negative(\n",
    "    by_eye_success_galaxies, \n",
    "    by_eye_not_success_galaxies, \n",
    "    success_df, \n",
    "    not_success_df, \n",
    "    full_df,\n",
    "    verbose = True\n",
    "):\n",
    "    \n",
    "    false_positive = set(by_eye_not_success_galaxies).intersection(set(success_df.index))\n",
    "    false_negative = set(by_eye_success_galaxies).intersection(set(not_success_df.index))\n",
    "\n",
    "    by_eye_success_df     = full_df.loc[by_eye_success_galaxies].sort_values(by = method)\n",
    "    by_eye_not_success_df = full_df.loc[by_eye_not_success_galaxies].sort_values(by = method)\n",
    "\n",
    "    FP_rate = f\"{len(false_positive)}/({len(false_positive)} + {len(by_eye_not_success_df)})\"\n",
    "    FN_rate = f\"{len(false_negative)}/({len(false_negative)} + {len(by_eye_success_df)})\"\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"False positive rate (by eye) -- {FP_rate} = {100*eval(FP_rate):.2f}%\")\n",
    "        print(f\"False negative rate (by eye) -- {FN_rate} = {100*eval(FN_rate):.2f}%\")\n",
    "\n",
    "    #print(f\"Total # of galaxies sorted by eye -- {len(raw_by_eye_success_galaxies) + len(raw_by_eye_not_success_galaxies)}\")\n",
    "    return by_eye_success_df, by_eye_not_success_df, FP_rate, FN_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a481b27c-a6ff-4fc8-86ed-0ae1e24c014c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def vprint(verbosity, *args, **kwargs):\n",
    "    if verbosity:\n",
    "        print(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec6fcd6b-d3b1-4e8a-a675-1d196bbe4d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_analysis(\n",
    "    in_dir = \"sparcfire-in\", \n",
    "    out_dir = \"sparcfire-out\", \n",
    "    basename = \"\", \n",
    "    method = \"nmr_x_1-p\", \n",
    "    flip_chiral_agreement = False,\n",
    "    incl_by_eye = True,\n",
    "    by_eye_subset = None,\n",
    "    verbose = False\n",
    "):\n",
    "    \n",
    "    vprint(verbose, \"Load residual.\")\n",
    "    residual_df = load_residual_df(out_dir, basename, method = method)\n",
    "    \n",
    "    # field_pa   = \"pitch_angle\"\n",
    "    # field_alen = \"arc_length\"\n",
    "    # name_col   = \"gxyName\"\n",
    "\n",
    "    vprint(verbose, \"Load pre galaxy csv.\")\n",
    "    pre_sparc_output_csv        = load_galaxy_csv(out_dir,      basename, pre_post = \"pre\")\n",
    "        \n",
    "    vprint(verbose, \"Load pre galaxy arcs csv.\")\n",
    "    pre_sparc_output_arcs_top2  = load_galaxy_arcs_csv(out_dir, basename, pre_post = \"pre\")\n",
    "\n",
    "    vprint(verbose, \"Load post galaxy csv.\")\n",
    "    post_sparc_output_csv       = load_galaxy_csv(out_dir,      basename, pre_post = \"post\")\n",
    "    \n",
    "    vprint(verbose, \"Load post galaxy arcs csv.\")\n",
    "    post_sparc_output_arcs_top2 = load_galaxy_arcs_csv(out_dir, basename, pre_post = \"post\")\n",
    "\n",
    "# ====================================================================================================================\n",
    "\n",
    "    vprint(verbose, \"Prep pre galaxy arcs df\")\n",
    "    pre_sp_out    = prepare_arcs_output(pre_sparc_output_arcs_top2,  pre_post = \"pre\")\n",
    "    vprint(verbose, \"Prep post galaxy arcs df\")\n",
    "    post_sp_out   = prepare_arcs_output(post_sparc_output_arcs_top2, pre_post = \"post\")\n",
    "\n",
    "    vprint(verbose, \"And combine\")\n",
    "    all_sparc_out = pd.concat([pre_sp_out, post_sp_out], axis = 1)\n",
    "    \n",
    "# ====================================================================================================================\n",
    "\n",
    "    vprint(verbose, \"Compare SpArcFiRe analysis before and after\")\n",
    "    before_after_galfit_df     = before_after_galfit_comparison(\n",
    "        all_sparc_out, \n",
    "        pre_sparc_output_csv, \n",
    "        post_sparc_output_csv\n",
    "    )\n",
    "    \n",
    "    vprint(verbose, \"Bring everything together\")\n",
    "    full_df                    = gather_everything(residual_df, before_after_galfit_df)\n",
    "    \n",
    "    sparcfire_processed        = full_df.dropna(subset = ['pa_diff1', 'pa_diff2', 'pa_diff_galaxy'], how = 'all')\n",
    "    \n",
    "    vprint(verbose, \"Determine success\")\n",
    "    success_df, not_success_df = determine_success(\n",
    "        full_df, \n",
    "        in_dir = \n",
    "        in_dir, \n",
    "        out_dir = out_dir, \n",
    "        flip_chiral_agreement = flip_chiral_agreement,\n",
    "        sparcfire_processed   = sparcfire_processed\n",
    "    )\n",
    "    \n",
    "    full_df[\"success\"] = full_df.index.isin(success_df.index)\n",
    "    print()\n",
    "    \n",
    "# ====================================================================================================================\n",
    "    \n",
    "    by_eye_success_df     = None\n",
    "    by_eye_not_success_df = None\n",
    "    \n",
    "    if incl_by_eye:\n",
    "        vprint(verbose, \"Extract by-eye evaluation\")\n",
    "        by_eye_success_galaxies, by_eye_not_success_galaxies = extract_by_eye_data(\n",
    "            out_dir, \n",
    "            basename, \n",
    "            residual_df, \n",
    "            full_df, \n",
    "            subset = by_eye_subset,\n",
    "            sparcfire_processed = sparcfire_processed\n",
    "        )\n",
    "        print()\n",
    "\n",
    "        # To resolve an occasional processing error...\n",
    "        by_eye_success_limited     = list(set(by_eye_success_galaxies).intersection(full_df.index))\n",
    "        by_eye_not_success_limited = list(set(by_eye_not_success_galaxies).intersection(full_df.index))\n",
    "\n",
    "        vprint(verbose, \"Calculate by-eye statistics\")\n",
    "        by_eye_success_df, by_eye_not_success_df, FP_rate, FN_rate = calculate_false_positive_negative(\n",
    "            by_eye_success_limited, \n",
    "            by_eye_not_success_limited, \n",
    "            success_df, \n",
    "            not_success_df, \n",
    "            full_df\n",
    "        )\n",
    "\n",
    "        full_df[\"by_eye_success\"] = full_df.index.isin(by_eye_success_df.index)\n",
    "    \n",
    "    return all_results(full_df, success_df, not_success_df, by_eye_success_df, by_eye_not_success_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e86d3aa8-f9c3-4490-9092-cc594f47de05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_multi_run_results(\n",
    "    method, \n",
    "    *args, \n",
    "    df_names = [],\n",
    "    incl_by_eye = True,\n",
    "    verbose = True\n",
    "):\n",
    "    \n",
    "    print(f\"Joining {len(args)} attempts...\")\n",
    "    primary_full_df = deepcopy(args[0].full_df)\n",
    "    \n",
    "    num_dfs = len(args)\n",
    "    #alt_full_df     = deepcopy(args[1].full_df)\n",
    "    #alt_full_df.rename(columns = {method : f\"1_{method}\"}, inplace = True)\n",
    "\n",
    "    all_full_dfs = [primary_full_df]\n",
    "    all_methods  = [method]\n",
    "    \n",
    "    for i, arg in enumerate(args[1:]):\n",
    "        alt_method = f\"{i}_{method}\"\n",
    "        all_methods.append(alt_method)\n",
    "        all_full_dfs.append(arg.full_df.rename(columns = {method : alt_method}))\n",
    "\n",
    "    # BY RESIDUAL\n",
    "    #temp_bool_df = pd.concat([primary_full_df[method], alt_full_df[f\"1_{method}\"]], axis = 1)\n",
    "    combined_bool_df = pd.concat([df[method] for df, method in zip(all_full_dfs, all_methods)], axis = 1)\n",
    "\n",
    "    #combined_bool_df.drop(index = list(set(primary_full_df.index).difference(set(alt_full_df.index))), inplace = True)\n",
    "    #temp_bool_df[\"minima\"] = temp_bool_df.idxmin(axis = 1)\n",
    "    combined_bool_df[\"minima\"] = combined_bool_df.idxmin(axis = 1)\n",
    "    \n",
    "    #og_minima  = temp_bool_df.minima == method\n",
    "    #alt_minima = temp_bool_df.minima == f\"1_{method}\"\n",
    "    minima_conditions = [combined_bool_df.minima == method for method in all_methods]\n",
    "    \n",
    "    #og_success = temp_bool_df.index.isin(args[0].by_eye_success_df.index)\n",
    "    #alt_success = temp_bool_df.index.isin(args[1].by_eye_success_df.index)\n",
    "    #print(sum((og_minima & og_success) | (alt_minima & alt_success)))\n",
    "        \n",
    "    # By everything\n",
    "    eval_str = \" | \".join([f\"all_full_dfs[{i}].success\" for i in range(num_dfs)])\n",
    "    combined_bool_df[\"by_sparcfire_success\"] = eval(eval_str) #primary_full_df.success | alt_full_df.success # | combined_bool_df.residual_minima_success\n",
    "    \n",
    "    if incl_by_eye:\n",
    "        by_eye_success_conditions = [combined_bool_df.index.isin(df.by_eye_success_df.index) for df in args]\n",
    "\n",
    "        all_conditions = zip(minima_conditions, by_eye_success_conditions)\n",
    "        list_o_conditions = [cond_set[0] & cond_set[1] for cond_set in all_conditions]\n",
    "        eval_str = \" | \".join([f\"list_o_conditions[{i}]\" for i in range(num_dfs)])\n",
    "\n",
    "        combined_bool_df[\"residual_minima_success\"] = eval(eval_str) \n",
    "        # print(sum((minima_conditions[0] & by_eye_success_conditions[0]) | (minima_conditions[1] & by_eye_success_conditions[1])))\n",
    "        # print(sum(list_o_conditions[0] | list_o_conditions[1]))\n",
    "\n",
    "        #eval_str = \" | \".join([df.success for df in all_df])\n",
    "        combined_bool_df[\"by_minima_and_sparcfire_success\"] = combined_bool_df.by_sparcfire_success | combined_bool_df.residual_minima_success\n",
    "    \n",
    "        # TODO: Show % in both\n",
    "        # by eye success for all labeled by df\n",
    "        best_fit_str_dict = {m : f\"df_{i}\" for i, m in enumerate(all_methods)}\n",
    "        combined_bool_df[\"best_fit\"] = None\n",
    "\n",
    "        for gname, row in combined_bool_df.iterrows():\n",
    "            best_method = [\n",
    "                (m, full_df.loc[gname, \"by_eye_success\"]) \n",
    "                for m, full_df in zip(all_methods, all_full_dfs)\n",
    "                if gname in full_df.index and full_df.loc[gname, \"by_eye_success\"]\n",
    "            ]\n",
    "\n",
    "            if len(best_method) > 1:\n",
    "                best_method = [(row.minima, None)]\n",
    "\n",
    "            elif not best_method:\n",
    "                best_method = [(None, None)]\n",
    "\n",
    "            if not combined_bool_df.loc[gname, \"best_fit\"]:\n",
    "                combined_bool_df.loc[gname, \"best_fit\"] = best_fit_str_dict.get(best_method[0][0], None)\n",
    "\n",
    "        #eval_str = \" | \".join([f\"all_full_dfs[{i}].by_eye_success\" for i, _ in enumerate(all_full_dfs)])\n",
    "        #combined_bool_df[\"by_eye_success\"] = eval(eval_str) #primary_full_df.by_eye_success | alt_full_df.by_eye_success\n",
    "        combined_bool_df[\"by_eye_success\"] = False | combined_bool_df.best_fit.str.contains(\"df\")\n",
    "\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Total success by combining SpArcFiRe + score: {sum(combined_bool_df.by_sparcfire_success)}/{total_galaxies}\")\n",
    "        \n",
    "        if incl_by_eye:\n",
    "            if df_names:\n",
    "                if len(df_names) != num_dfs: \n",
    "                    print(\"Length of dataframe names supplied should be equal to the number of dataframes supplied.\")\n",
    "                    print(\"Leaving current convention in the dataframe (df_0, df_1, ..., df_n)\")\n",
    "                else:\n",
    "                    combined_bool_df[\"best_fit\"]   = combined_bool_df.best_fit.replace({f\"df_{i}\" : name for i, name in enumerate(df_names)})\n",
    "                    \n",
    "            print(f\"Total success by best score: {sum(combined_bool_df.residual_minima_success)}/{total_galaxies}\")\n",
    "            print(f\"Total success by SpArcFiRe and best score between the two runs: {sum(combined_bool_df.by_minima_and_sparcfire_success)}/{total_galaxies}\")\n",
    "            print(f\"Total success by eye: {sum(combined_bool_df.by_eye_success)}/{total_galaxies}\")\n",
    "            print()\n",
    "\n",
    "            bss  = set(combined_bool_df[combined_bool_df[\"by_sparcfire_success\"]].index)\n",
    "            TP   = set(combined_bool_df[combined_bool_df[\"by_eye_success\"]].index)\n",
    "            bsns = set(combined_bool_df[~combined_bool_df[\"by_sparcfire_success\"]].index)\n",
    "            TN   = set(combined_bool_df[~combined_bool_df[\"by_eye_success\"]].index)\n",
    "\n",
    "            FP   = bss.intersection(TN)\n",
    "            FN   = bsns.intersection(TP)\n",
    "\n",
    "            sparc_positive = bss.intersection(TP)\n",
    "            sparc_negative = bsns.intersection(TN)\n",
    "            fraction = len(sparc_positive)/sum(combined_bool_df.by_eye_success)\n",
    "            neg_fraction = len(sparc_negative)/sum(~combined_bool_df.by_eye_success)\n",
    "            # FPR = FP/(FP + TN)\n",
    "            # FNR = FN/(FN + TP)\n",
    "            print(f\"By eye success found by SpArcFiRe+score:  {len(sparc_positive)}/{sum(combined_bool_df.by_eye_success)} = {100*fraction:.2f}%\")\n",
    "            print(f\"By eye not success found by SpArcFiRe+score:  {len(sparc_negative)}/{sum(~combined_bool_df.by_eye_success)} = {100*neg_fraction:.2f}%\")\n",
    "            FP_rate = f\"{len(FP)} / ({len(FP)} + {len(TN)})\"\n",
    "            FN_rate = f\"{len(FN)} / ({len(FN)} + {len(TP)})\"\n",
    "\n",
    "            print()\n",
    "            print(f\"False positive rate (by eye) -- {FP_rate} = {100*eval(FP_rate):.2f}%\")\n",
    "            print(f\"False negative rate (by eye) -- {FN_rate} = {100*eval(FN_rate):.2f}%\")\n",
    "            \n",
    "            # TODO: GENERATE CONFUSION MATRIX\n",
    "            #print()\n",
    "            #print(f\"Confusion matrix\")\n",
    "            #print()\n",
    "            #print()\n",
    "    \n",
    "    #combined_success_df = pd.concat\n",
    "    \n",
    "    return combined_bool_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "693a33b8-825d-40d2-88ec-906322df9ec7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_ecdf(x, runname, df, dict_o_kwargs):\n",
    "    \n",
    "    # for key, default in exec_kwargs().items():\n",
    "    #     exec(f\"{key} = kwargs.get({key}, {default})\")\n",
    "    # Yeesh https://stackoverflow.com/a/67367191\n",
    "    # Use frame(3) since these functions are nested\n",
    "    sys._getframe(4).f_locals.update(dict_o_kwargs)\n",
    "\n",
    "    fig = px.ecdf(df,\n",
    "                  x = x,\n",
    "                  markers = True, \n",
    "                  lines = False, \n",
    "                  marginal = \"histogram\",\n",
    "                  ecdfnorm = None,\n",
    "                  log_x    = log_x,\n",
    "                  log_y    = log_y\n",
    "                 ) \n",
    "\n",
    "    if add_vline:\n",
    "        fig.add_vline(x = cutoff_val, \n",
    "                      row = 1,\n",
    "                      line_color = \"cyan\",\n",
    "                      annotation_text= f\"{cutoff_val}\", \n",
    "                      annotation_position=\"bottom\")\n",
    "\n",
    "    if add_hline:\n",
    "        yval = sum(df.loc[:, x] < cutoff_val)\n",
    "        fig.add_hline(y = yval, \n",
    "                      row = 1,\n",
    "                      col = 1,\n",
    "                      line_color = \"magenta\",\n",
    "                      annotation_text=f\"{yval}\",\n",
    "                      annotation_position=\"bottom left\"\n",
    "                     )\n",
    "        \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d8fe7455-01b0-477f-beb7-0d72b1af46db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_scatter(x, runname, df, dict_o_kwargs):\n",
    "    \n",
    "    sys._getframe(4).f_locals.update(dict_o_kwargs)\n",
    "        \n",
    "    fig = px.scatter(df, \n",
    "               x = x, \n",
    "               y = y, \n",
    "               color = color,\n",
    "               color_continuous_scale = \"Agsunset\",\n",
    "                    )\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fbe217be-635a-4f9a-85d1-bf40d0bb4fcb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_histogram(x, runname, df, dict_o_kwargs, multi):\n",
    "    \n",
    "    sys._getframe(4).f_locals.update(dict_o_kwargs)\n",
    "    \n",
    "    fig = px.histogram(\n",
    "        df,\n",
    "        x         = x,\n",
    "        color     = color,\n",
    "        histnorm  = histnorm,\n",
    "        facet_col = facet_col,\n",
    "        facet_row = facet_row,\n",
    "        nbins     = nbins,\n",
    "        #hover_data = {'Galaxy ID': (\":c\", full_df.index)},\n",
    "        log_x     = log_x,\n",
    "        log_y     = log_y,\n",
    "    )\n",
    "    \n",
    "    if facet_col or facet_row:\n",
    "        fig.for_each_annotation(lambda a: a.update(text=a.text.split(\"=\")[-1]))\n",
    "\n",
    "    if multi:\n",
    "        fig.update_layout(barmode = \"overlay\")\n",
    "        fig.update_traces(opacity = 0.75)\n",
    "        \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8c26146b-9f20-456d-aa64-f0e0b56a6225",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_plot(x, runname, plot_type, df, output_image_dir = \"for_paper_images\", **kwargs):\n",
    "        \n",
    "    dict_o_kwargs = {\n",
    "        \"y\"               : None,\n",
    "        \"color\"           : None,\n",
    "        \n",
    "        \"xaxis_title\"     : \"\",\n",
    "        \"yaxis_title\"     : \"\",\n",
    "        \n",
    "        \"xaxis_range\"     : None,\n",
    "        \"yaxis_range\"     : None,\n",
    "        \n",
    "        \"log_x\"           : False,\n",
    "        \"log_y\"           : False,\n",
    "        \n",
    "        \"histnorm\"        : \"\",\n",
    "        \"facet_col\"       : None,\n",
    "        \"facet_row\"       : None,\n",
    "        \n",
    "        \"nbins\"           : 0,\n",
    "        \n",
    "        \"cutoff_val\"      : 0.007,\n",
    "        \"add_vline\"       : True,\n",
    "        \"add_hline\"       : True,\n",
    "        \n",
    "        \"title\"           : \"\",\n",
    "        \"title_x\"         : 0.9,\n",
    "        \"title_y\"         : 0.5,\n",
    "\n",
    "        \"paper_image_dir\" : paper_image_dir,\n",
    "        \"filetype\"        : \"png\",\n",
    "        \"show\"            : True,\n",
    "        \"write\"           : True\n",
    "    }\n",
    "    \n",
    "    # Updating with kwargs\n",
    "    dict_o_kwargs = {key : kwargs.get(key, default) for key, default in dict_o_kwargs.items()}\n",
    "    \n",
    "    plt.clf()\n",
    "    if plot_type == \"ecdf\":\n",
    "        fig = create_ecdf(x, runname, df, dict_o_kwargs)\n",
    "    elif plot_type == \"scatter\":\n",
    "        fig = create_scatter(x, runname, df, dict_o_kwargs)\n",
    "    elif plot_type == \"histogram\":\n",
    "        multi = kwargs.get(\"multi\", True)\n",
    "        fig = create_histogram(x, runname, df, dict_o_kwargs, multi)\n",
    "    else:\n",
    "        return\n",
    "    \n",
    "    sys._getframe(3).f_locals.update(dict_o_kwargs)\n",
    "    \n",
    "    if title:\n",
    "        fig.update_layout(\n",
    "            title_text = title, \n",
    "            title_x    = title_x, \n",
    "            title_y    = title_y\n",
    "        )\n",
    "        \n",
    "    if xaxis_title:\n",
    "        fig.update_layout(xaxis_title = xaxis_title)\n",
    "    if yaxis_title:\n",
    "        fig.update_layout(yaxis_title = yaxis_title)\n",
    "        \n",
    "    if xaxis_range:\n",
    "        fig.update_layout(xaxis_range = xaxis_range)\n",
    "    if yaxis_range:\n",
    "        fig.update_layout(yaxis_range = yaxis_range)\n",
    "    \n",
    "    if show:\n",
    "        fig.show()\n",
    "        \n",
    "    if write:\n",
    "        fig.write_image(f\"{output_image_dir}/{plot_type}_{runname}_{x}.{filetype}\", width = 1200)\n",
    "        \n",
    "    fig.data   = []\n",
    "    fig.layout = {}\n",
    "    \n",
    "    #return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "524b8133-afce-4840-9a24-9d145858b41f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_all_plots(\n",
    "    df_container, \n",
    "    method, \n",
    "    basename, \n",
    "    output_image_dir, \n",
    "    show = True, \n",
    "    write = True, \n",
    "    **kwargs\n",
    "):\n",
    "        \n",
    "    plot_df = df_container.full_df[df_container.full_df.loc[:, method] < kwargs.get(\"score_ecdf_cutoff\", 0.015)]\n",
    "\n",
    "    _ = create_plot(\n",
    "        x                = method,\n",
    "        runname          = basename,\n",
    "        plot_type        = \"ecdf\",\n",
    "        df               = plot_df,\n",
    "        output_image_dir = output_image_dir,\n",
    "        xaxis_title      = \"KStest+NMR\",\n",
    "        # title       = f\"1000 galaxies: ECDF for KStest+NMR on all models\",\n",
    "        # title_y     = 0.92\n",
    "        show             = show,\n",
    "        write            = write\n",
    "    )\n",
    "    \n",
    "# ============================================================================================================================================================\n",
    "# SERSIC INDEX HISTOGRAMS\n",
    "# ============================================================================================================================================================\n",
    "\n",
    "    x1   = \"sersic_index_sersic_1\"\n",
    "    x2   = \"sersic_index_sersic_2\"\n",
    "    x    = \"n\"\n",
    "    fcol = \"domain\"\n",
    "\n",
    "    # By eye success\n",
    "    plot_df = df_container.by_eye_success_df[[x1,x2]].rename(columns = {x1 : \"bulge\", x2 : \"disk\"})\n",
    "    plot_df = pd.melt(plot_df).rename(columns   = {\"value\" : x, \"variable\" : \"component\"})\n",
    "    plot_df[fcol] = \"by-eye success\"\n",
    "\n",
    "    plot_df1 = df_container.success_df[[x1,x2]].rename(columns = {x1 : \"bulge\", x2 : \"disk\"})\n",
    "    plot_df1 = pd.melt(plot_df1).rename(columns = {\"value\" : x, \"variable\" : \"component\"})\n",
    "    plot_df1[fcol] = \"success\"\n",
    "\n",
    "    plot_df2 = df_container.full_df[[x1,x2]].rename(columns = {x1 : \"bulge\", x2 : \"disk\"})\n",
    "    plot_df2 = pd.melt(plot_df2).rename(columns = {\"value\" : x, \"variable\" : \"component\"})\n",
    "    plot_df2[fcol] = \"all models\"\n",
    "\n",
    "    plot_df = pd.concat([plot_df, plot_df1, plot_df2], axis = 0)\n",
    "\n",
    "    _ = create_plot(\n",
    "        x                = x,\n",
    "        runname          = f\"{basename}_by-eye-vs-success-vs-all\",\n",
    "        plot_type        = \"histogram\",\n",
    "        df               = plot_df,\n",
    "        output_image_dir = output_image_dir,\n",
    "        histnorm         = \"probability\",\n",
    "        color            = \"component\",\n",
    "        nbins            = 40,\n",
    "        facet_col        = fcol,\n",
    "        xaxis_range      = kwargs.get(\"xaxis_range_sersic_hist\", None), # [10, 20],\n",
    "        yaxis_range      = kwargs.get(\"xaxis_range_sersic_hist\", None), # [0, 0.15],\n",
    "        # title       = f\"{runname} galaxies: distribution of magnitudes for by-eye successful models\"\n",
    "        # title_y     = 0.85\n",
    "        show             = show,\n",
    "        write            = write\n",
    "    )\n",
    "\n",
    "    # _ = create_plot(\n",
    "    #     x           = x,\n",
    "    #     runname     = \"1000_by-eye\",\n",
    "    #     plot_type   = \"histogram\",\n",
    "    #     df          = plot_df,\n",
    "    #     color       = \"component\",\n",
    "    #     # title       = f\"{runname} galaxies: distribution of Sérsic indices for by-eye successful models\"\n",
    "    #     # title_y     = 0.85\n",
    "    #     show        = show\n",
    "    # )\n",
    "\n",
    "    # # All results\n",
    "    # plot_df = full_df[[x1,x2]].rename(columns = {x1 : \"bulge\", x2 : \"disk\"})\n",
    "    # plot_df = pd.melt(plot_df).rename(columns = {\"value\" : x, \"variable\" : \"component\"})\n",
    "\n",
    "    # _ = create_plot(\n",
    "    #     x           = x,\n",
    "    #     runname     = \"1000\",\n",
    "    #     plot_type   = \"histogram\",\n",
    "    #     df          = plot_df,\n",
    "    #     color       = \"component\",\n",
    "    #     # title       = f\"{runname} galaxies: distribution of Sérsic indices for by-eye successful models\"\n",
    "    #     # title_y     = 0.85\n",
    "    #     show        = show\n",
    "    # )\n",
    "    \n",
    "# ============================================================================================================================================================\n",
    "# MAGNITUDE HISTOGRAMS \n",
    "# ============================================================================================================================================================\n",
    "    \n",
    "    # TODO: Combine these into one plot either using facet or go\n",
    "    # https://plotly.com/python/subplots/\n",
    "    # or https://plotly.com/python/facet-plots/\n",
    "\n",
    "    x1   = \"magnitude_sersic_1\"\n",
    "    x2   = \"magnitude_sersic_2\"\n",
    "    x    = \"m\"\n",
    "    fcol = \"domain\"\n",
    "\n",
    "    plot_df = df_container.by_eye_success_df[[x1,x2]].rename(columns = {x1 : \"bulge\", x2 : \"disk\"})\n",
    "    plot_df = pd.melt(plot_df).rename(columns   = {\"value\" : x, \"variable\" : \"component\"})\n",
    "    plot_df[fcol] = \"by-eye success\"\n",
    "\n",
    "    plot_df1 = df_container.success_df[[x1,x2]].rename(columns = {x1 : \"bulge\", x2 : \"disk\"})\n",
    "    plot_df1 = pd.melt(plot_df1).rename(columns = {\"value\" : x, \"variable\" : \"component\"})\n",
    "    plot_df1[fcol] = \"success\"\n",
    "\n",
    "    plot_df2 = df_container.full_df[[x1,x2]].rename(columns = {x1 : \"bulge\", x2 : \"disk\"})\n",
    "    plot_df2 = pd.melt(plot_df2).rename(columns = {\"value\" : x, \"variable\" : \"component\"})\n",
    "    plot_df2[fcol] = \"all models\"\n",
    "\n",
    "    plot_df = pd.concat([plot_df, plot_df1, plot_df2], axis = 0)\n",
    "\n",
    "    _ = create_plot(\n",
    "        x                = x,\n",
    "        runname          = f\"{basename}_by-eye-vs-success-vs-all\",\n",
    "        plot_type        = \"histogram\",\n",
    "        df               = plot_df,\n",
    "        output_image_dir = output_image_dir,\n",
    "        histnorm         = \"probability\",\n",
    "        color            = \"component\",\n",
    "        facet_col        = fcol,\n",
    "        xaxis_range      = kwargs.get(\"xaxis_range_mag_hist\", None), # [10, 20],\n",
    "        yaxis_range      = kwargs.get(\"yaxis_range_mag_hist\", None), # [0, 0.15],\n",
    "        # title       = f\"{runname} galaxies: distribution of magnitudes for by-eye successful models\"\n",
    "        # title_y     = 0.85\n",
    "        show             = show,\n",
    "        write            = write\n",
    "    )\n",
    "\n",
    "    # By eye\n",
    "    # figure1 = create_plot(\n",
    "    #     x           = x,\n",
    "    #     runname     = \"1000_by-eye\",\n",
    "    #     plot_type   = \"histogram\",\n",
    "    #     df          = plot_df,\n",
    "    #     color       = \"component\",\n",
    "    #     xaxis_range = [10, 17],\n",
    "    #     # title       = f\"{runname} galaxies: distribution of magnitudes for by-eye successful models\"\n",
    "    #     # title_y     = 0.85\n",
    "    #     show        = show,\n",
    "    #     write       = False\n",
    "    # )\n",
    "\n",
    "    # # All results\n",
    "    # plot_df = full_df[[x1,x2]].rename(columns = {x1 : \"bulge\", x2 : \"disk\"})\n",
    "    # plot_df = pd.melt(plot_df).rename(columns = {\"value\" : x, \"variable\" : \"component\"})\n",
    "\n",
    "    # figure2 = create_plot(\n",
    "    #     x           = x,\n",
    "    #     runname     = \"1000\",\n",
    "    #     plot_type   = \"histogram\",\n",
    "    #     df          = plot_df,\n",
    "    #     color       = \"component\",\n",
    "    #     xaxis_range = [10, 18],\n",
    "    #     # title       = f\"{runname} galaxies: distribution of magnitudes for by-eye successful models\"\n",
    "    #     # title_y     = 0.85\n",
    "    #     show        = show,\n",
    "    #     write       = False\n",
    "    # )\n",
    "    \n",
    "# ============================================================================================================================================================\n",
    "# ALEN HISTOGRAM\n",
    "# ============================================================================================================================================================\n",
    "    _ = create_plot(\n",
    "        x                = \"alen_ratio\",\n",
    "        runname          = basename,\n",
    "        plot_type        = \"histogram\",\n",
    "        df               = df_container.full_df,\n",
    "        output_image_dir = output_image_dir,\n",
    "        xaxis_title      = \"alen ratio\",\n",
    "        multi            = False,\n",
    "        # title       = f\"{runname} galaxies: distribution of alen ratios for all models\"\n",
    "        # title_y     = 0.85\n",
    "        show             = show,\n",
    "        write            = write\n",
    "    )\n",
    "    \n",
    "# ============================================================================================================================================================\n",
    "# ECDF OF BY EYE SCORE\n",
    "# ============================================================================================================================================================\n",
    "    \n",
    "    _ = create_plot(\n",
    "        x                = method,\n",
    "        runname          = f\"{basename}_by-eye\",\n",
    "        plot_type        = \"ecdf\",\n",
    "        df               = df_container.by_eye_success_df,\n",
    "        output_image_dir = output_image_dir,\n",
    "        xaxis_title      = \"KStest+NMR\",\n",
    "        add_hline        = False,\n",
    "        # title       = f\"1000 galaxies: ECDF for KStest+NMR on by-eye successful model fits\",\n",
    "        # title_y     = 0.92\n",
    "        show             = show,\n",
    "        write            = write\n",
    "    )\n",
    "    \n",
    "# ============================================================================================================================================================\n",
    "# SCATTER OF PITCH ANGLE DIFFERENCES\n",
    "# ============================================================================================================================================================\n",
    "    \n",
    "    x     = \"observation\"\n",
    "    y     = \"model\"\n",
    "    color = \"difference\"\n",
    "\n",
    "    pre_pa  = df_container.full_df[[\"pre_pa1\" , \"pre_pa2\"]].mean(axis = 1)\n",
    "    post_pa = df_container.full_df[[\"post_pa1\", \"post_pa2\"]].mean(axis = 1)\n",
    "    plot_df = pd.concat([pre_pa, post_pa], axis = 1).rename(columns = {0 : x, 1 : y})\n",
    "    plot_df[color] = abs(plot_df[x] - plot_df[y])\n",
    "\n",
    "    _ = create_plot(\n",
    "        x                = x,\n",
    "        y                = y,\n",
    "        runname          = f\"{basename}_pa_diff\",\n",
    "        plot_type        = \"scatter\",\n",
    "        df               = plot_df,\n",
    "        output_image_dir = output_image_dir,\n",
    "        color            = color,\n",
    "        # title     = \"Pitch angle difference reported by SpArcFiRe, model vs observation\"\n",
    "        # title_y   = 0.85\n",
    "        show             = show,\n",
    "        write            = write\n",
    "    )\n",
    "    \n",
    "# ============================================================================================================================================================\n",
    "# SCATTER OF PITCH ANGLE DIFFERENCES\n",
    "# ============================================================================================================================================================\n",
    "\n",
    "    _ = create_plot(\n",
    "        x                = \"pa_diff_galaxy\",\n",
    "        runname          = basename,\n",
    "        plot_type        = \"ecdf\",\n",
    "        df               = df_container.full_df,\n",
    "        output_image_dir = output_image_dir,\n",
    "        xaxis_title      = \"Pitch Angle Difference (deg)\",\n",
    "        cutoff_val       = kwargs.get(\"pa_cutoff_val\", 10),\n",
    "        # title       = f\"ECDF of pitch angle difference reported by SpArcFiRe, model vs observation\"\n",
    "        # title_y     = 0.85\n",
    "        show             = show,\n",
    "        write            = write\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3c9968be-1763-40f0-b267-cfbe467d4d31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_quantiles(out_dir, basename, df, method, print_latex = True, copy_png = False):\n",
    "    success_dir = pj(out_dir, basename, f'{basename}_galfit_png')\n",
    "    \n",
    "    quantile           = [\"0\", \"20\", \"40\", \"60\", \"80\"]\n",
    "    quantiled_galaxies = []\n",
    "    \n",
    "    print_latex_all = []\n",
    "    if print_latex:\n",
    "        print_latex_file = pj(out_dir, basename, f\"{basename}_for_latex.txt\")\n",
    "        if exists(print_latex_file):\n",
    "            print(\"Deleting old latex output file...\")\n",
    "            os.remove(print_latex_file)\n",
    "            \n",
    "        print(f\"Writing latex to file {print_latex_file}\")\n",
    "    \n",
    "    for q in quantile:\n",
    "        #vprint(print_latex, f\"{q} &\")\n",
    "        print_latex_all.append(f\"{q} &\")\n",
    "        \n",
    "        if copy_png:\n",
    "            quantile_dir = pj(success_dir, f\"{basename}_all_quantile\", f\"quantile_{q}\")\n",
    "            if exists(quantile_dir):\n",
    "                shutil.rmtree(quantile_dir)\n",
    "            os.makedirs(quantile_dir)\n",
    "        \n",
    "        # Assume runname is in basename\n",
    "        #runname = basename.split(\"_\")[0]\n",
    "        temp_str = f\"images/{basename}/{basename}_all_quantile/quantile_\"\n",
    "        initial_str = f\"    \\includegraphics[height=0.18\\\\textheight]{{{temp_str}{q}/\"\n",
    "        end_str = \"} &\"\n",
    "        \n",
    "        interp_df = df[method][df[method] >= df[method].quantile(0.01*float(q), interpolation='lower')]\n",
    "        for count, i in enumerate(interp_df.items()):\n",
    "            #if count < 5:\n",
    "            #    continue\n",
    "            if count == 8:\n",
    "                break\n",
    "\n",
    "            if count == 7 or count == len(interp_df) - 1:\n",
    "                end_str = \"} \\\\\\\\\"\n",
    "\n",
    "            gname = i[0]\n",
    "            #print(q, i)\n",
    "            #vprint(print_latex, f\"{initial_str}{gname + '_combined.png'}{end_str}\")\n",
    "            print_latex_all.append(f\"{initial_str}{gname + '_combined.png'}{end_str}\")\n",
    "                \n",
    "            if copy_png:\n",
    "                shutil.copy(pj(success_dir, f\"{gname}_combined.png\"), quantile_dir)\n",
    "                \n",
    "            quantiled_galaxies.append(gname)\n",
    "                \n",
    "            #sp(f\"cp {pj(out_dir, 'by_eye_success', gname + '_combined.png')} {pj(success_dir, 'all_quantile', 'quantile_' + q)}\")\n",
    "            \n",
    "    if print_latex:           \n",
    "        with open(print_latex_file, \"w\") as plf:\n",
    "            plf.write(\"\\n\".join(print_latex_all))\n",
    "            plf.write(\"\\n\")\n",
    "            \n",
    "    if copy_png:\n",
    "        # Tar it all up!\n",
    "        sp(f\"tar -czvf {pj(out_dir, basename, basename)}_all_quantile.tar.gz -C {success_dir} {basename}_all_quantile\")\n",
    "        \n",
    "    return quantiled_galaxies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d1214924-ee80-484d-854c-ec76922f1871",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fprint(input_str, fill_char = \"*\", fill_len = 100):\n",
    "    input_str = f\" {input_str} \"\n",
    "    print()\n",
    "    print(f\"{input_str:{fill_char}^{fill_len}}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d7b8ff1f-4954-4488-9979-c5d889d40ae8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def main(run_path, *basenames, **kwargs):\n",
    "    # Set some path variables and things\n",
    "    run_path = run_path\n",
    "    \n",
    "    if in_notebook():\n",
    "        run_path = run_path.replace(\"ics-home\", \"portmanm\")\n",
    "\n",
    "    in_dir  = kwargs.get(\"in_dir\", pj(run_path, \"sparcfire-in\"))\n",
    "    out_dir = kwargs.get(\"tmp_dir\", pj(run_path, \"sparcfire-out\"))\n",
    "    tmp_dir = kwargs.get(\"out_dir\", pj(run_path, \"sparcfire-tmp\"))\n",
    "\n",
    "    paper_image_dir = kwargs.get(\"paper_image_dir\", pj(run_path, \"for_paper_images\"))\n",
    "    if not exists(paper_image_dir):\n",
    "        os.makedirs(paper_image_dir)\n",
    "        \n",
    "    method          = kwargs.get(\"method\", \"nmr_x_1-p\")\n",
    "    nmr             = \"norm_masked_residual\"\n",
    "    \n",
    "    global total_galaxies\n",
    "    total_galaxies = get_total_galaxies(in_dir = in_dir, out_dir = out_dir)\n",
    "    \n",
    "    # FUNCTIONS OPTIONS\n",
    "    incl_by_eye   = kwargs.get(\"incl_by_eye\", False)\n",
    "    by_eye_subset = kwargs.get(\"by_eye_subset\", False)\n",
    "    show          = kwargs.get(\"show\", False)\n",
    "    print_latex   = kwargs.get(\"print_latex\", True)\n",
    "    copy_png      = kwargs.get(\"copy_png\", True)\n",
    "    \n",
    "    # Getting ready\n",
    "    all_results  = {}\n",
    "    plot_options = kwargs.get(\"plot_options\", {bname : {} for bname in basenames})\n",
    "    \n",
    "    # LOOPING THROUGH NAMES GIVEN FOR ANALYSIS\n",
    "    for basename in basenames:\n",
    "        # RESIDUAL ANALYSIS\n",
    "        fprint(f\"PERFORMING RESIDUAL ANALYSIS FOR {basename}\")\n",
    "        analysis_results = residual_analysis(\n",
    "            in_dir       = in_dir, \n",
    "            out_dir      = out_dir, \n",
    "            basename     = basename,\n",
    "            method       = method,\n",
    "            incl_by_eye  = incl_by_eye\n",
    "        )\n",
    "        \n",
    "        # Collating\n",
    "        all_results[basename] = analysis_results\n",
    "        \n",
    "        # Currently requires by eye analysis to be present\n",
    "        if incl_by_eye:\n",
    "            fprint(\"CREATING PLOTS\")\n",
    "            # OUTPUTTING PLOTS\n",
    "            create_all_plots(\n",
    "                analysis_results, \n",
    "                method, \n",
    "                basename, \n",
    "                paper_image_dir, \n",
    "                show = show,\n",
    "                **plot_options[basename]\n",
    "                #xaxis_range_mag_hist = [10, 20],\n",
    "                #yaxis_range_mag_hist = [0, 0.15]\n",
    "            )\n",
    "        \n",
    "        if print_latex or copy_png:\n",
    "            if incl_by_eye:\n",
    "                quantile_df = analysis_results.by_eye_success_df\n",
    "            else:\n",
    "                quantile_df = analysis_results.success_df\n",
    "\n",
    "            fprint(\"QUANTILING IMAGES FROM RESULTS\")\n",
    "            galaxy_set_q = create_quantiles(\n",
    "                out_dir, \n",
    "                basename, \n",
    "                quantile_df,\n",
    "                method, \n",
    "                print_latex = print_latex, \n",
    "                copy_png = copy_png\n",
    "            )\n",
    "        \n",
    "        # Unfortunately have to do this after and have the user generate the pngs from here\n",
    "        # in order to rerun create_quantiles\n",
    "        if kwargs.get(\"prep_for_quantile\", False):\n",
    "            fprint(\"JUST KIDDING, EXTRACTING QUANTILED MODELS TO BE CONVERTED TO PNG\")\n",
    "            \n",
    "            to_untar = ' '.join([f\"./{gname}_galfit_out.fits\" for gname in galaxy_set_q])\n",
    "            tar_file = f\"{pj(out_dir, basename, basename)}_galfits.tar.gz\"\n",
    "            sp(f\"tar -xzvf {tar_file} --occurrence {to_untar}\")\n",
    "\n",
    "            _ = [shutil.move(f\"{gname}_galfit_out.fits\", f\"{pj(out_dir, basename, basename)}_galfits\")\n",
    "                 for gname in galaxy_set_q\n",
    "                ]\n",
    "            \n",
    "            print(f\"Please generate the pngs corresponding with the fits in the {pj(out_dir, basename, basename)}_galfits directory.\")\n",
    "            print(\"You may then proceed to run the 'create_quantiles' function again with copy_png set to True.\")\n",
    "    \n",
    "    if len(basenames) > 1:\n",
    "        fprint(\"COMBINING RESULTS FROM ALL RUNS FED IN\")\n",
    "        combined_bool_df = combine_multi_run_results(\n",
    "            method,\n",
    "            *all_results.values(),\n",
    "            df_names = basenames,\n",
    "            incl_by_eye = incl_by_eye\n",
    "        )\n",
    "        \n",
    "    fprint(\"DONE!!!\")\n",
    "    \n",
    "    # {basename : namedtuple (fields below), \"combined_bool_df\" : combined_bool_df}\n",
    "    # full_df, success_df, not_success_df, by_eye_success_df, by_eye_not_success_df\n",
    "    all_results[\"combined_bool_df\"] = combined_bool_df\n",
    "    return all_results\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "4ca63ade-456e-41a4-baa5-4e2ae42875ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "******************************* PERFORMING RESIDUAL ANALYSIS FOR nc2 *******************************\n",
      "\n",
      "14 galaxy models generated.\n",
      "12 models pass score cutoff.\n",
      "14 processed by sparcfire\n",
      "12 pass score cutoff\n",
      "12 pass pitch angle cutoff\n",
      "10 pass arm length ratio cutoff\n",
      "11 pass chiral agreement\n",
      "7 or 50.00% (7/14) succeed by SpArcFiRe+Score\n",
      "0/14 models failed reprocessing by SpArcFiRe\n",
      "\n",
      "\n",
      "********************************** QUANTILING IMAGES FROM RESULTS **********************************\n",
      "\n",
      "Deleting old latex output file...\n",
      "Writing latex to file testing_python_control/sparcfire-out/nc2/nc2_for_latex.txt\n",
      "\n",
      "******************************* PERFORMING RESIDUAL ANALYSIS FOR nc3 *******************************\n",
      "\n",
      "14 galaxy models generated.\n",
      "13 models pass score cutoff.\n",
      "14 processed by sparcfire\n",
      "13 pass score cutoff\n",
      "11 pass pitch angle cutoff\n",
      "13 pass arm length ratio cutoff\n",
      "13 pass chiral agreement\n",
      "10 or 71.43% (10/14) succeed by SpArcFiRe+Score\n",
      "1/14 models failed reprocessing by SpArcFiRe\n",
      "\n",
      "\n",
      "********************************** QUANTILING IMAGES FROM RESULTS **********************************\n",
      "\n",
      "Deleting old latex output file...\n",
      "Writing latex to file testing_python_control/sparcfire-out/nc3/nc3_for_latex.txt\n",
      "\n",
      "****************************** COMBINING RESULTS FROM ALL RUNS FED IN ******************************\n",
      "\n",
      "Joining 2 attempts...\n",
      "Total success by combining SpArcFiRe + score: 11/14\n",
      "\n",
      "********************************************* DONE!!! **********************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    galaxy_set_14_results = main(\n",
    "        \"testing_python_control\", \n",
    "        \"nc2\", \n",
    "        \"nc3\",\n",
    "        incl_by_eye = False,\n",
    "        copy_png    = False,\n",
    "        print_latex = False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "c22055f9-0b8d-47c8-b31a-8546d00d336a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**************************** PERFORMING RESIDUAL ANALYSIS FOR 1000_NC2 *****************************\n",
      "\n",
      "1000 galaxy models generated.\n",
      "909 models pass score cutoff.\n",
      "1000 processed by sparcfire\n",
      "909 pass score cutoff\n",
      "700 pass pitch angle cutoff\n",
      "745 pass arm length ratio cutoff\n",
      "665 pass chiral agreement\n",
      "437 or 43.70% (437/1000) succeed by SpArcFiRe+Score\n",
      "68/1000 models failed reprocessing by SpArcFiRe\n",
      "\n",
      "Number of *total* by eye successful galaxies\n",
      "406     => 40.60%\n",
      "Number of by eye successful galaxies that SpArcFiRe *could* process\n",
      "406/406 => 100.00%\n",
      "\n",
      "Number of *total* by eye not successful galaxies\n",
      "594     => 59.40%\n",
      "Number of by eye not successful galaxies that SpArcFiRe *could* process\n",
      "406/594 => 68.35%\n",
      "\n",
      "False positive rate (by eye) -- 148/(148 + 594) = 19.95%\n",
      "False negative rate (by eye) -- 117/(117 + 406) = 22.37%\n",
      "\n",
      "****************************************** CREATING PLOTS ******************************************\n",
      "\n",
      "\n",
      "********************************** QUANTILING IMAGES FROM RESULTS **********************************\n",
      "\n",
      "Deleting old latex output file...\n",
      "Writing latex to file run13_for_paper/sparcfire-out/1000_NC2/1000_NC2_for_latex.txt\n",
      "\n",
      "**************************** PERFORMING RESIDUAL ANALYSIS FOR 1000_NC3 *****************************\n",
      "\n",
      "1000 galaxy models generated.\n",
      "896 models pass score cutoff.\n",
      "1000 processed by sparcfire\n",
      "896 pass score cutoff\n",
      "732 pass pitch angle cutoff\n",
      "763 pass arm length ratio cutoff\n",
      "686 pass chiral agreement\n",
      "432 or 43.20% (432/1000) succeed by SpArcFiRe+Score\n",
      "49/1000 models failed reprocessing by SpArcFiRe\n",
      "\n",
      "Number of *total* by eye successful galaxies\n",
      "422     => 42.20%\n",
      "Number of by eye successful galaxies that SpArcFiRe *could* process\n",
      "422/422 => 100.00%\n",
      "\n",
      "Number of *total* by eye not successful galaxies\n",
      "578     => 57.80%\n",
      "Number of by eye not successful galaxies that SpArcFiRe *could* process\n",
      "422/578 => 73.01%\n",
      "\n",
      "False positive rate (by eye) -- 140/(140 + 578) = 19.50%\n",
      "False negative rate (by eye) -- 130/(130 + 422) = 23.55%\n",
      "\n",
      "****************************************** CREATING PLOTS ******************************************\n",
      "\n",
      "\n",
      "********************************** QUANTILING IMAGES FROM RESULTS **********************************\n",
      "\n",
      "Deleting old latex output file...\n",
      "Writing latex to file run13_for_paper/sparcfire-out/1000_NC3/1000_NC3_for_latex.txt\n",
      "\n",
      "****************************** COMBINING RESULTS FROM ALL RUNS FED IN ******************************\n",
      "\n",
      "Joining 2 attempts...\n",
      "Total success by combining SpArcFiRe + score: 607/1000\n",
      "Total success by best score: 467/1000\n",
      "Total success by SpArcFiRe and best score between the two runs: 694/1000\n",
      "Total success by eye: 569/1000\n",
      "\n",
      "By eye success found by SpArcFiRe+score:  453/569 = 79.61%\n",
      "By eye not success found by SpArcFiRe+score:  277/431 = 64.27%\n",
      "\n",
      "False positive rate (by eye) -- 154 / (154 + 431) = 26.32%\n",
      "False negative rate (by eye) -- 116 / (116 + 569) = 16.93%\n",
      "\n",
      "********************************************* DONE!!! **********************************************\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # NC2\n",
    "    # xaxis_range_mag_hist = [10, 20],\n",
    "    # yaxis_range_mag_hist = [0, 0.15]\n",
    "    \n",
    "    # NC3\n",
    "    # xaxis_range_mag_hist = [10, 22],\n",
    "    # yaxis_range_mag_hist = [0, 0.3]\n",
    "    \n",
    "    plot_options = {\n",
    "        \"1000_NC2\" : {\n",
    "            \"xaxis_range_mag_hist\" : [10, 20], \"yaxis_range_mag_hist\" : [0, 0.15]\n",
    "        },\n",
    "        \"1000_NC3\" : {\n",
    "            \"xaxis_range_mag_hist\" : [10, 22], \"yaxis_range_mag_hist\" : [0, 0.3]\n",
    "        },\n",
    "    }\n",
    "    \n",
    "    galaxy_set_1000_results = main(\n",
    "        \"run13_for_paper\", \n",
    "        \"1000_NC2\", \n",
    "        \"1000_NC3\", \n",
    "        incl_by_eye = True,\n",
    "        plot_options = plot_options\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "63464946-41bd-4573-ac6a-279c63a14e30",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***************************** PERFORMING RESIDUAL ANALYSIS FOR 29k_NC2 *****************************\n",
      "\n",
      "28912 galaxy models generated.\n",
      "22259 models pass score cutoff.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22487/4114222190.py:7: DtypeWarning:\n",
      "\n",
      "Columns (70) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28911 processed by sparcfire\n",
      "22259 pass score cutoff\n",
      "19876 pass pitch angle cutoff\n",
      "20203 pass arm length ratio cutoff\n",
      "17012 pass chiral agreement\n",
      "9170 or 31.72% (9170/28911) succeed by SpArcFiRe+Score\n",
      "1685/28912 models failed reprocessing by SpArcFiRe\n",
      "\n",
      "\n",
      "********************************** QUANTILING IMAGES FROM RESULTS **********************************\n",
      "\n",
      "Writing latex to file 29k_galaxies/sparcfire-out/29k_NC2/29k_NC2_for_latex.txt\n",
      "\n",
      "***************************** PERFORMING RESIDUAL ANALYSIS FOR 29k_NC3 *****************************\n",
      "\n",
      "28912 galaxy models generated.\n",
      "25383 models pass score cutoff.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22487/4114222190.py:7: DtypeWarning:\n",
      "\n",
      "Columns (70) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28904 processed by sparcfire\n",
      "25383 pass score cutoff\n",
      "21572 pass pitch angle cutoff\n",
      "20577 pass arm length ratio cutoff\n",
      "18358 pass chiral agreement\n",
      "11663 or 40.35% (11663/28904) succeed by SpArcFiRe+Score\n",
      "1241/28912 models failed reprocessing by SpArcFiRe\n",
      "\n",
      "\n",
      "********************************** QUANTILING IMAGES FROM RESULTS **********************************\n",
      "\n",
      "Writing latex to file 29k_galaxies/sparcfire-out/29k_NC3/29k_NC3_for_latex.txt\n",
      "\n",
      "****************************** COMBINING RESULTS FROM ALL RUNS FED IN ******************************\n",
      "\n",
      "Joining 2 attempts...\n",
      "Total success by combining SpArcFiRe + score: 15592/28912\n",
      "\n",
      "********************************************* DONE!!! **********************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    galaxy_set_1000_results = main(\"29k_galaxies\", \"29k_NC2\", \"29k_NC3\", incl_by_eye = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98498552-b0d1-4461-b28a-6412e2cc2213",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_images_old(input_df, png_dir:str, variable_name:str, custom_range = None):\n",
    "    images_out = []\n",
    "    \n",
    "    if not custom_range:\n",
    "        custom_range = range(0, len(input_df), 50) \n",
    "        \n",
    "    count = 0\n",
    "    for index_num in custom_range:\n",
    "        g_variable = input_df.iloc[index_num]\n",
    "        gname = g_variable.name\n",
    "        variable_value = g_variable[variable_name]#.norm_masked_residual\n",
    "\n",
    "        height = 500\n",
    "        width = 500\n",
    "        size = (height, width)\n",
    "        #out_str = galaxy_info.name.replace(\"galfit_out.fits\", \"combined.png\").strip()\n",
    "        out_str = f\"{gname}_combined.png\"\n",
    "        #print(out_str)\n",
    "        \n",
    "        \n",
    "        images_out.append(Image(filename = pj(png_dir, out_str), width=width, height=height))\n",
    "            \n",
    "        print(f\"{gname}, sorted #: {index_num}\")\n",
    "        print(f\"{variable_name} = {variable_value:.6f}\")\n",
    "        #print(f\"Dim: {galaxy_info['image_size']}x{galaxy_info['image_size']}\")\n",
    "        print()\n",
    "        \n",
    "    return images_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb0dadf-10a4-4c06-bfac-5c5ca8168990",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_to_disp = generate_images_old(full_df, pj(out_dir, \"galfit_png\"), \"diff\") #, range(0,len(full_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c716159c-c1f4-4aa2-89e5-8a99a118d224",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(*images_to_disp)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "70746b6a-4331-43af-9972-17511a378117",
   "metadata": {
    "tags": []
   },
   "source": [
    "for png in glob.glob(pj(out_dir, \"scatter_plots\", \"*.png\")):\n",
    "    gname = os.path.basename(png).rstrip(\".png\")\n",
    "    if gname not in success_df.index and gname in constrained_df.index:\n",
    "        print(constrained_df.loc[gname, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd73b55-2bc5-46a9-9d47-16f472f03d31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_images(input_df, png_dir:str, cutoff_val = 0.01, variable_name = \"norm_masked_residual\", custom_range = None):\n",
    "    images_below_cutoff = []\n",
    "    images_above_cutoff = []\n",
    "    \n",
    "    if not custom_range:\n",
    "        custom_range = range(0, len(input_df), 50) \n",
    "    count = 0\n",
    "    for index_num in custom_range:\n",
    "        g_variable = input_df.iloc[index_num]\n",
    "        gname = g_variable.name\n",
    "        variable_value = g_variable[variable_name]#.norm_masked_residual\n",
    "\n",
    "        # iloc returns a series, name returns the name of the row\n",
    "\n",
    "        \n",
    "        # print(f\"chi^2/nu = {galaxy_info['chi^2_nu']:.2f}\")\n",
    "        # print(f\"chi^2 = {galaxy_info['chi^2']:.2f}\")\n",
    "        #print(f\"Norm GALFIT residual = {norm_galfit_residual:.4f}\")\n",
    "\n",
    "\n",
    "        # galfit_cmap = grayscale_cmap('RdBu')\n",
    "        # residual_plot = plt.imshow(np.flipud(masked_residual[:,:])) #, norm=colors.LogNorm())\n",
    "        # residual_plot.set_cmap('Greys')\n",
    "        # residual_plot.set_cmap(galfit_cmap)\n",
    "        # cbar = plt.colorbar()\n",
    "\n",
    "        #plt.imshow(residual_plot)\n",
    "        #imgplot = plt.imshow(arr[:, :, 0])\n",
    "        height = 500\n",
    "        width = 500\n",
    "        size = (height, width)\n",
    "        #out_str = galaxy_info.name.replace(\"galfit_out.fits\", \"combined.png\").strip()\n",
    "        out_str = f\"{gname}_combined.png\"\n",
    "        #print(out_str)\n",
    "        \n",
    "        if variable_value < cutoff_val:\n",
    "            images_below_cutoff.append(Image(filename = pj(png_dir, out_str), width=width, height=height))\n",
    "            #images_below_cutoff.append(PIL.Image.open(pj(png_dir, out_str)).resize(size))\n",
    "        else:\n",
    "            count += 1\n",
    "            if count == 1:\n",
    "                print(\"=\"*80)\n",
    "            images_above_cutoff.append(Image(filename = pj(png_dir, out_str), width=width, height=height))\n",
    "            #images_above_cutoff.append(PIL.Image.open(pj(png_dir, out_str)).resize(size))\n",
    "\n",
    "            \n",
    "        print(f\"{gname}, sorted #: {index_num}\")\n",
    "        print(f\"{variable_name} = {variable_value:.6f}\")\n",
    "        #print(f\"Dim: {galaxy_info['image_size']}x{galaxy_info['image_size']}\")\n",
    "        print()\n",
    "        \n",
    "    return images_below_cutoff, images_above_cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa61e80e-f4c1-4c8c-b07f-f9ed0a1b56e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "png_dir = os.path.join(run_path, out_dir, \"galfit_png\")\n",
    "#below, above = generate_images(residual_df, png_dir, cutoff_val = 0.013342, variable_name = analysis_var, custom_range = range(700, len(residual_df), 10) )\n",
    "below, above = generate_images(residual_df, png_dir, cutoff_val = cutoff_val, variable_name = analysis_var, custom_range = range(800, len(residual_df), 10) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d88e511-d149-424d-8a7e-6e8f4fe51dc1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display(*below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630341ca-75b3-4dc6-91b6-b9929e4f01a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(*above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9901973e-ac6f-4700-aa25-c14eab1075a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# good_fit = \"1237671262278582530\"\n",
    "# bad_fit = \"1237668366388756890\"\n",
    "\n",
    "# good_fit_obj = OutputFits(pj(out_dir, good_fit, f\"{good_fit}_galfit_out.fits\"))\n",
    "# bad_fit_obj = OutputFits(pj(out_dir, bad_fit, f\"{bad_fit}_galfit_out.fits\"))\n",
    "# good_residual = good_fit_obj.residual.data\n",
    "\n",
    "# scipy.stats.probplot(good_residual.flatten(), plot = plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ee8420-f01d-407b-a78f-7420e0244a93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# bad_residual = bad_fit_obj.residual.data\n",
    "# scipy.stats.probplot(bad_residual.flatten(), plot = plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e075be-9f7e-4901-9c7c-a364497be181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thanks to https://jakevdp.github.io/PythonDataScienceHandbook/04.07-customizing-colorbars.html\n",
    "def grayscale_cmap(cmap):\n",
    "    \"\"\"Return a grayscale version of the given colormap\"\"\"\n",
    "    cmap = plt.cm.get_cmap(cmap)\n",
    "    colors = cmap(np.arange(cmap.N))\n",
    "    \n",
    "    # convert RGBA to perceived grayscale luminance\n",
    "    # cf. http://alienryderflex.com/hsp.html\n",
    "    RGB_weight = [0.299, 0.587, 0.114]\n",
    "    luminance = np.sqrt(np.dot(colors[:, :3] ** 2, RGB_weight))\n",
    "    colors[:, :3] = luminance[:, np.newaxis]\n",
    "        \n",
    "    return LinearSegmentedColormap.from_list(cmap.name + \"_gray\", colors, cmap.N)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
