{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4247750-5fc9-4be0-8102-06041cdb7c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install --user astropy\n",
    "#!pip3 install --user kaleido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b85295-242d-405b-ba3a-260bf8f72535",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import astropy as ap\n",
    "import pandas as pd\n",
    "from astropy.io import fits\n",
    "import scipy.linalg as slg\n",
    "from scipy.stats import norm, pearsonr\n",
    "#import scipy.stats\n",
    "from math import ceil\n",
    "import csv\n",
    "\n",
    "import plotly.io as pio\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from plotly.offline import iplot\n",
    "import kaleido\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.colors as colors\n",
    "# from matplotlib.colors import LinearSegmentedColormap\n",
    "import glob\n",
    "import os\n",
    "# These are in Functions\n",
    "from os.path import join as pj\n",
    "from os.path import exists # as pj\n",
    "# from os.path import abspath as absp\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.display import display\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import PIL\n",
    "import pickle\n",
    "\n",
    "import sys\n",
    "from collections import namedtuple as nt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7e0271-d54c-42e1-a9e5-9527b166c8d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ[\"SPARCFIRE_HOME\"] = \"/home/portmanm/sparcfire_matt/\"\n",
    "\n",
    "_HOME_DIR = os.path.expanduser(\"~\")\n",
    "try:\n",
    "    _SPARCFIRE_DIR = os.environ[\"SPARCFIRE_HOME\"]\n",
    "    _MODULE_DIR = pj(_SPARCFIRE_DIR, \"GalfitModule\")\n",
    "except KeyError:\n",
    "    if __name__ == \"__main__\":\n",
    "        print(\"SPARCFIRE_HOME is not set. Please run 'setup.bash' inside SpArcFiRe directory if not done so already.\")\n",
    "        print(\"Checking the current directory for GalfitModule, otherwise quitting.\")\n",
    "            \n",
    "        _MODULE_DIR = pj(os.getcwd(), \"GalfitModule\")\n",
    "        \n",
    "        if not exists(_MODULE_DIR):\n",
    "            raise Exception(\"Could not find GalfitModule!\")\n",
    "    \n",
    "sys.path.append(_MODULE_DIR)\n",
    "from Classes.Components import *\n",
    "from Classes.Containers import *\n",
    "from Classes.FitsHandlers import *\n",
    "from Functions.helper_functions import *\n",
    "\n",
    "all_results_nt      = nt(\"all_results_nt\", [\"full_df\", \"success_df\", \"not_success_df\", \"by_eye_success_df\", \"by_eye_not_success_df\"])\n",
    "combined_results_nt = nt(\"combined_results_nt\", [\"bool_df\", \"full_df\", \"success_df\", \"by_eye_success_df\"])\n",
    "mini_sep    = \"\\n\" + 40*\"=\" + \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de93171e-4ad6-4e16-acd3-8c302cb5d8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Defunct\n",
    "# def check_galfit_chi(gal_name, base_path):\n",
    "#     # An example line\n",
    "#     # # Chi^2/nu = 4.661,  Chi^2 = 12025.575,  Ndof = 2580\n",
    "    \n",
    "#     #galfit_txt_out = \"galfit.01\" # in the future galfit.01 may change\n",
    "#     filename = os.path.join(base_path, gal_name, galfit_txt_out)\n",
    "#     with open(filename, \"r\") as f:\n",
    "#         for line in f:\n",
    "#             if \"Chi\" in line:\n",
    "#                 chi_line = line.strip(\"# \")\n",
    "    \n",
    "#     # This also works but it's quite devious...\n",
    "#     # chi_line.replace(\"^\", \"\").replace(\"/\", \"_\").replace(\",  \", \"\\n\").lower()\n",
    "#     # exec(chi_line)\n",
    "    \n",
    "#     out_vals = chi_line.split(\",\")\n",
    "#     chi2_nu = float(out_vals[0].strip().split(\"=\")[-1])\n",
    "#     chi2 = float(out_vals[1].strip().split(\"=\")[-1])\n",
    "#     ndof = int(out_vals[2].strip().split(\"=\")[-1])\n",
    "    \n",
    "#     return chi2_nu, chi2, ndof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47be9c91-a9a6-4971-b9d2-3be76d4b9d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_total_galaxies(in_dir = \"sparcfire-in\", out_dir = \"sparcfire-out\"):   \n",
    "    all_gnames_in  = find_files(in_dir, \"123*\", \"f\")\n",
    "    all_gnames_out = find_files(out_dir, \"123*\", \"d\")\n",
    "    total_galaxies = min(len(all_gnames_in), len(all_gnames_out))\n",
    "    if not total_galaxies:\n",
    "        total_galaxies  = max(len(all_gnames_in), len(all_gnames_out))\n",
    "        \n",
    "    return total_galaxies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "0bde5da9-94a6-411f-bdf6-14a0cac8eae8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def grab_header_parameters_for_flux(input_file):\n",
    "    try:\n",
    "        with fits.open(input_file) as hdul:\n",
    "            exptime = hdul[1].header.get(\"EXPTIME\", 1)\n",
    "            mag_zpt = hdul[2].header.get(\"MAGZPT\", 24.8) # Default for SDSS r band\n",
    "    except FileNotFoundError as fe:\n",
    "        print(f\"Could not fits.open {input_file}.\")\n",
    "        print(\"Using exptime and mag zpt defaults from SDSS DR7 r-band.\")\n",
    "        exptime, mag_zpt = 1, 24.8\n",
    "        \n",
    "    return exptime, mag_zpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "ee884139-38d5-41a0-8415-78651519848c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_residual_df(\n",
    "    out_dir, \n",
    "    basename,\n",
    "    **kwargs\n",
    "):\n",
    "    \n",
    "    method              = kwargs.get(\"method\", \"nmr_x_1-p\")\n",
    "    verbose             = kwargs.get(\"verbose\", True)\n",
    "    residual_cutoff_val = kwargs.get(\"residual_cutoff_val\", 0.007)\n",
    "    \n",
    "    pickle_filename = pj(out_dir, basename, sorted(find_files(pj(out_dir, basename), f'{basename}_output_results*.pkl', \"f\"))[-1])\n",
    "    \n",
    "    residual_df  = pd.read_pickle(pickle_filename)\n",
    "    # temp_df = deepcopy(residual_df)\n",
    "    # Setting residual columns\n",
    "    #residual_df[\"KS_P\"] = 1 - residual_df[\"KS_P\"]\n",
    "    if method == \"nmr_x_1-p\":\n",
    "        result_of_method = (1 - residual_df[\"KS_P\"])*residual_df[\"NMR\"]\n",
    "    elif method == \"nmr_neg_log\":\n",
    "        result_of_method = residual_df[\"NMR\"]/-np.log(residual_df[\"KS_P\"] + 1e-10)\n",
    "    elif method == \"W_quality\":\n",
    "        result_of_method = residual_df[\"KS_P\"]/residual_df[\"W_NMR\"]\n",
    "    else:\n",
    "        raise Exception(f\"Method given: {method} is not a valid method (yet).\")\n",
    "    \n",
    "    residual_df[method] = result_of_method\n",
    "    \n",
    "    # Valid meaning NMR was successfully calculated\n",
    "    #cols_to_drop = [col for col in residual_df.columns if col.endswith(\"_sky_2\")]\n",
    "    #valid_spiral_df = residual_df.drop(columns = cols_to_drop).dropna()\n",
    "\n",
    "    # rename sky_2 to sky_3 for non-spirals to be inline with everything else\n",
    "    # this would be for potential comparison down the line\n",
    "    cols_to_merge = [col for col in residual_df.columns if col.endswith(\"_sky_3\") or col.endswith(\"_sky_4\")]\n",
    "    #_ = [residual_df[col].fillna(residual_df[f\"{col[:-1]}2\"], inplace = True) for col in cols_to_merge]\n",
    "    cols_to_drop  = [col for col in residual_df.columns if col.endswith(\"_sky_2\") or col.endswith(\"_sky_3\")]#  + [\"KS_STAT\"]\n",
    "    residual_df.drop(columns = cols_to_drop, inplace = True)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"{len(residual_df)} galaxy models generated.\")\n",
    "        residual_cutoff = residual_df[method] <= residual_cutoff_val\n",
    "        print(f\"{sum(residual_cutoff)} models pass score cutoff.\")\n",
    "    \n",
    "    # This will obviously have to change if multiple spiral components are introduced\n",
    "    # but who's crazy enough to do that(???)\n",
    "    spiral_component_num = int([i for i in residual_df.columns if i.startswith(\"inner_rad_power\")][0][-1])\n",
    "    \n",
    "    input_file = \"./fake_file.fake_file\"\n",
    "    count      = 0\n",
    "    while not exists(input_file) and count < 100:\n",
    "        gname      = residual_df.index[count]\n",
    "        input_file = pj(out_dir, gname, f\"{gname}_galfit_out.fits\")\n",
    "        count += 1\n",
    "        \n",
    "    exptime, mag_zpt = grab_header_parameters_for_flux(input_file)\n",
    "        \n",
    "    # Formula from GALFIT readme...\n",
    "    # m_tot = -2.5*log_10*(F_tot/t_exp) + mag_zpt\n",
    "    # =>\n",
    "    # F_tot = t_exp*10^[-(m_tot - mag_zpt)/2.5]\n",
    "    arm_flux   = exptime*10**(\n",
    "        -(residual_df[f\"magnitude_sersic_{spiral_component_num}\"] - mag_zpt)/2.5\n",
    "    )\n",
    "    other_flux = exptime*10**(\n",
    "        -(residual_df[f\"magnitude_sersic_{spiral_component_num - 1}\"] - mag_zpt)/2.5\n",
    "    )\n",
    "\n",
    "    for i in range(spiral_component_num - 2, 0, -1):\n",
    "        other_flux += exptime*10**(\n",
    "            -(residual_df[f\"magnitude_sersic_{i}\"] - mag_zpt)/2.5\n",
    "    )\n",
    "\n",
    "    residual_df[\"arm_flux_ratio\"] = arm_flux/other_flux\n",
    "    \n",
    "    return residual_df.sort_values(by = method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5cd1a4-3cf8-4c58-9178-ce87b4cd9278",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_galaxy_csv(out_dir, basename, pre_post):\n",
    "    \n",
    "    field = \" pa_alenWtd_avg_domChiralityOnly\"\n",
    "    # {basename}_ uneccessary because different *galfit* runs \n",
    "    # should have same sparcfire output\n",
    "    fname = pj(out_dir, basename, f\"{basename}_{pre_post}_galfit_galaxy.csv\")\n",
    "    sparc_output_csv = pd.read_csv(fname, #pj(out_dir, f\"pre_galfit_galaxy.csv\"),\n",
    "                                       index_col = \"name\",\n",
    "                                       on_bad_lines = \"warn\",\n",
    "                                       usecols   = [\"name\", field], # , \" iptSz\"],\n",
    "                                       #na_values = \"NaN\",\n",
    "                                       #dtype     = {field : float} #, \" iptSz\" : str}#, \"name\" : str}\n",
    "                                      )#.loc[:, field]\n",
    "    #sparc_output_csv.index.name = None\n",
    "    sparc_output_csv[field] = sparc_output_csv[field].astype(float)\n",
    "    sparc_output_csv.index  = sparc_output_csv.index.map(str)\n",
    "    #sparc_output_csv[\" iptSz\"] = sparc_output_csv[\" iptSz\"].str.extract(r\"([0-9]+)\").astype(float)\n",
    "\n",
    "    #sparc_output_csv[\"pre_sign\"] = np.sign(sparc_output_csv[field])\n",
    "    sparc_output_csv.rename(columns = {field : f\"galaxy_{pre_post}_pa\"}, inplace = True)\n",
    "    \n",
    "    return sparc_output_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5e2491-9d83-4573-8826-ba9d91f5b8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_galaxy_arcs_csv(out_dir, basename, pre_post, **kwargs):\n",
    "    \n",
    "    field_pa   = kwargs.get(\"field_pa\"  , \"pitch_angle\")\n",
    "    field_alen = kwargs.get(\"field_alen\", \"arc_length\")\n",
    "    name_col   = kwargs.get(\"name_col\"  , \"gxyName\")\n",
    "\n",
    "    fname = pj(out_dir, basename, f\"{basename}_{pre_post}_galfit_galaxy_arcs.csv\")\n",
    "    sparc_output_arcs_csv = pd.read_csv(fname, \n",
    "                                       index_col = name_col,\n",
    "                                       usecols   = [name_col, field_pa, field_alen],\n",
    "                                       dtype     = {field_pa : float, field_alen : float} #, name_col : str}\n",
    "                                      )#.loc[:, field]\n",
    "    #sparc_output_csv.index.name = None\n",
    "    sparc_output_arcs_csv.index = sparc_output_arcs_csv.index.map(str)\n",
    "\n",
    "    # Filtering for pure circles and near circles\n",
    "    sparc_output_arcs_csv = sparc_output_arcs_csv[abs(sparc_output_arcs_csv[field_pa ]) > 1]\n",
    "\n",
    "    #sparc_output_arcs_csv = pd.concat([sparc_output_arcs_csv, pre_sparc_output_csv], axis = 1)\n",
    "    #sparc_output_arcs_csv[\"sign\"] = np.sign(sparc_output_arcs_csv[field])\n",
    "\n",
    "    # Keeps only arms which align with dom chirality only\n",
    "    # sparc_output_arcs_csv[\"check\"] = [\n",
    "    #     row[\"sign\"] + pre_sparc_output_csv.loc[i, \"pre_sign\"] \n",
    "    #     if i in pre_sparc_output_csv.index \n",
    "    #     else None \n",
    "    #     for i, row in sparc_output_arcs_csv.iterrows()\n",
    "    # ]\n",
    "\n",
    "    #sparc_output_arcs_csv = sparc_output_arcs_csv[abs(sparc_output_arcs_csv.loc[:, \"check\"]) == 2].drop(columns = [\"sign\", \"check\"])\n",
    "    sparc_output_arcs_top3 = sparc_output_arcs_csv.groupby(name_col).head(3).reset_index()\n",
    "    sparc_output_arcs_top3[f\"{pre_post}_sign\"] = np.sign(sparc_output_arcs_top3.pitch_angle)\n",
    "\n",
    "    dom_sign = np.sign(sparc_output_arcs_top3.groupby(name_col).sum()[f\"{pre_post}_sign\"])\n",
    "    sparc_output_arcs_top3 = sparc_output_arcs_top3.join(dom_sign, rsuffix = \"_dom\", on = name_col)\n",
    "\n",
    "    cond = sparc_output_arcs_top3[f\"{pre_post}_sign_dom\"] == sparc_output_arcs_top3[f\"{pre_post}_sign\"]\n",
    "    sparc_output_arcs_top2 = sparc_output_arcs_top3[cond].groupby(name_col).head(2).reset_index().drop(columns = [f\"{pre_post}_sign_dom\", \"index\"])\n",
    "\n",
    "    #pre_sparc_output_top2.rename(columns = {field : \"pre_pa\"}, inplace = True)\n",
    "    #pre_sparc_output_csv.dropna(inplace=True)\n",
    "    return sparc_output_arcs_top2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9d4a2f-ad1d-465a-9de9-dab0ffec7ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_arcs_output(sparc_output_arcs_top2, pre_post, **kwargs):\n",
    "    \n",
    "    field_pa   = kwargs.get(\"field_pa\"  , \"pitch_angle\")\n",
    "    field_alen = kwargs.get(\"field_alen\", \"arc_length\")\n",
    "    name_col   = kwargs.get(\"name_col\"  , \"gxyName\")\n",
    "    \n",
    "    single_arm = sparc_output_arcs_top2[~sparc_output_arcs_top2.duplicated(name_col, keep = False)]\n",
    "    single_arm.loc[:, field_pa] = 0\n",
    "    #single_arm.loc[:, \"arc_length\"]  = 0\n",
    "\n",
    "    filled_in = pd.concat([sparc_output_arcs_top2, single_arm], ignore_index = True)\n",
    "    str_fill = [f\"{pre_post}_pa1\", f\"{pre_post}_pa2\"] * (len(filled_in) // 2)\n",
    "    filled_in[\"temp1\"] = str_fill\n",
    "\n",
    "    str_fill = [f\"{pre_post}_alen1\", f\"{pre_post}_alen2\"] * (len(filled_in) // 2)\n",
    "    filled_in[\"temp2\"] = str_fill\n",
    "\n",
    "    #filled_in = filled_in.reset_index().drop(columns = [\"index\"])\n",
    "    sp_out = filled_in.pivot_table(index = name_col, columns = [\"temp1\", \"temp2\"], values = [field_pa, field_alen])\n",
    "\n",
    "    sp_out = sp_out.droplevel(0, axis = 1).droplevel(0, axis = 1)\n",
    "    sp_out.columns = [f'{pre_post}_alen1', f'{pre_post}_alen2', f'{pre_post}_pa1', f'{pre_post}_pa2']\n",
    "    \n",
    "    return sp_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07dbb8f0-f2fd-4c0e-a3cd-76597837bd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def before_after_galfit_comparison(all_sparc_out, pre_sparc_output_csv, post_sparc_output_csv):\n",
    "    \n",
    "    before_after_galfit_df = all_sparc_out.copy(deep = True) #.dropna() #full_df.dropna(subset = [\"post_pa\"])\n",
    "    #before_after_galfit_df = before_after_galfit_df[np.sign(before_after_galfit_df.loc[:, \"pre_pa\"]) != np.sign(before_after_galfit_df.loc[:, \"post_pa\"])]\n",
    "\n",
    "    before_after_galfit_df[\"chiral_agreement\"] = np.sign(before_after_galfit_df[\"pre_pa1\"]) == np.sign(before_after_galfit_df[\"post_pa1\"])\n",
    "\n",
    "    before_after_galfit_df[\"pre_pa1\"]  = abs(before_after_galfit_df[\"pre_pa1\"])\n",
    "    before_after_galfit_df[\"pre_pa2\"]  = abs(before_after_galfit_df[\"pre_pa2\"])\n",
    "    before_after_galfit_df[\"post_pa1\"] = abs(before_after_galfit_df[\"post_pa1\"])\n",
    "    before_after_galfit_df[\"post_pa2\"] = abs(before_after_galfit_df[\"post_pa2\"])\n",
    "    \n",
    "    #before_after_galfit_df.fillna(90, inplace = True)\n",
    "\n",
    "    before_after_galfit_df[\"1-1\"] = abs(before_after_galfit_df[\"pre_pa1\"] - before_after_galfit_df[\"post_pa1\"])\n",
    "    before_after_galfit_df[\"2-2\"] = abs(before_after_galfit_df[\"pre_pa2\"] - before_after_galfit_df[\"post_pa2\"])\n",
    "    before_after_galfit_df[\"1-2\"] = abs(before_after_galfit_df[\"pre_pa1\"] - before_after_galfit_df[\"post_pa2\"])\n",
    "    before_after_galfit_df[\"2-1\"] = abs(before_after_galfit_df[\"pre_pa2\"] - before_after_galfit_df[\"post_pa1\"])\n",
    "    \n",
    "    min_diff_pa_idx = before_after_galfit_df[[\"1-1\", \"2-2\", \"1-2\", \"2-1\"]].idxmin(axis = 1)#.reset_index(drop = True)\n",
    "    max_diff_pa_idx = before_after_galfit_df[[\"1-1\", \"2-2\", \"1-2\", \"2-1\"]].idxmax(axis = 1)#.reset_index(drop = True)\n",
    "    \n",
    "    min_pre_str  = \"pre_pa\"  + min_diff_pa_idx.str[0]\n",
    "    min_post_str = \"post_pa\" + min_diff_pa_idx.str[-1]\n",
    "    #max_pre_str  = \"pre_pa\"  + min_diff_pa_idx.str[0]\n",
    "    #max_post_str = \"post_pa\" + min_diff_pa_idx.str[-1]\n",
    "    \n",
    "    before_after_galfit_df[\"min_pre\"], before_after_galfit_df[\"min_post\"]  = zip(*[\n",
    "        (before_after_galfit_df.loc[gname, col_name_pre], before_after_galfit_df.loc[gname, col_name_post])\n",
    "        if \n",
    "            isinstance(col_name_pre, str) and isinstance(col_name_post, str)\n",
    "        else \n",
    "            (None, None)\n",
    "        for (gname, col_name_pre), (_, col_name_post) in zip(min_pre_str.items(), min_post_str.items())\n",
    "        \n",
    "    ])\n",
    "\n",
    "    #before_after_galfit_df[\"pa_diff1\"], before_after_galfit_df[\"pa_diff2\"] = zip(*before_after_galfit_df[\"best_diffs\"])\n",
    "    #before_after_galfit_df[\"max_arm_pa_diff\"]    = abs(before_after_galfit_df[\"max_post\"] - before_after_galfit_df[\"max_pre\"])\n",
    "    before_after_galfit_df[\"min_arm_pa_diff\"] = abs(before_after_galfit_df[\"min_post\"] - before_after_galfit_df[\"min_pre\"])\n",
    "    before_after_galfit_df[\"pa_diff_galaxy\"]  = abs(post_sparc_output_csv[\"galaxy_post_pa\"] - pre_sparc_output_csv[\"galaxy_pre_pa\"])\n",
    "    \n",
    "    before_after_galfit_df[\"min_pa_diff\"]     = before_after_galfit_df[[\"min_arm_pa_diff\", \"pa_diff_galaxy\"]].min(axis = 1)\n",
    "\n",
    "    #before_after_galfit_df[\"alen_ratio\"] = post_sparc_output_csv[\" iptSz\"]*before_after_galfit_df[[\"pre_alen1\", \"pre_alen2\"]].min(axis = 1)/(pre_sparc_output_csv[\" iptSz\"]*before_after_galfit_df[[\"post_alen1\", \"post_alen2\"]].max(axis = 1))\n",
    "    before_after_galfit_df[\"alen_ratio\"] = before_after_galfit_df[[\"post_alen1\", \"post_alen2\"]].min(axis = 1)/before_after_galfit_df[[\"post_alen1\", \"post_alen2\"]].max(axis = 1)\n",
    "\n",
    "    cols_to_remove = ['1-1', '2-2', '1-2', '2-1'] # 'mean-1122', 'mean-1221', 'min_diff', 'best_diffs']\n",
    "    before_after_galfit_df = before_after_galfit_df.drop(columns = cols_to_remove) #before_after_galfit_df.columns[9:-4])\n",
    "\n",
    "    return before_after_galfit_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e8bd45-f542-48a8-8923-1e07f5cbb9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_everything(residual_df, before_after_galfit_df, method):\n",
    "    full_df = residual_df.join(before_after_galfit_df)\n",
    "    full_df = full_df[full_df.index.notnull()].sort_values(by = method)\n",
    "\n",
    "    #full_df.dropna(subset = [\"pa_diff1\", \"pa_diff2\", \"pa_diff_galaxy\"], how = \"all\", inplace = True)\n",
    "    #full_df.fillna(subset = [\"pa_diff1\", \"pa_diff2\", \"pa_diff_galaxy\"], how = \"all\", inplace = True)\n",
    "    #full_df[\"min_pa_diff\"] = full_df[[\"min_arm_pa_diff\", \"pa_diff_galaxy\"]].min(axis = 1)\n",
    "    \n",
    "    return full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850f1b7e-eb54-45d1-b759-dbfffc197ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_success(\n",
    "    full_df, \n",
    "    **kwargs\n",
    "):\n",
    "    \n",
    "    in_dir                = kwargs.get(\"in_dir\", \"sparcfire-in\") \n",
    "    out_dir               = kwargs.get(\"out_dir\",\"sparcfire-out\")\n",
    "    sparcfire_processed   = kwargs.get(\"sparcfire_processed\", None)\n",
    "    flip_chiral_agreement = kwargs.get(\"flip_chiral_agreement\", False)\n",
    "    residual_cutoff_val   = kwargs.get(\"residual_cutoff_val\", 0.007)\n",
    "    pa_cutoff_val         = kwargs.get(\"pa_cutoff_val\", 10)\n",
    "    alen_cutoff_val       = kwargs.get(\"alen_cutoff_val\", 0.5)\n",
    "    verbose               = kwargs.get(\"verbose\", True)\n",
    "    \n",
    "    residual_cutoff = full_df[\"nmr_x_1-p\"] <= residual_cutoff_val\n",
    "    #pa_cutoff = (full_df[\"pa_diff1\"] < 10) | (full_df[\"pa_diff2\"] < 10)\n",
    "    pa_cutoff   = full_df[\"min_pa_diff\"] < pa_cutoff_val\n",
    "    alen_cutoff = full_df[\"alen_ratio\"] > alen_cutoff_val #[True]\n",
    "    sign_cutoff = full_df[\"chiral_agreement\"].astype(bool)\n",
    "    if flip_chiral_agreement:\n",
    "        sign_cutoff = ~sign_cutoff\n",
    "\n",
    "    success_df     = full_df[residual_cutoff & pa_cutoff & alen_cutoff & sign_cutoff].copy()\n",
    "    not_success_df = full_df[~(residual_cutoff & pa_cutoff & alen_cutoff & sign_cutoff)].copy()\n",
    "    \n",
    "    if verbose:\n",
    "        # print(f\"{len(full_df)} processed by sparcfire\")\n",
    "        # print(f\"{sum(residual_cutoff)} pass score cutoff\")\n",
    "        print(f\"{sum(pa_cutoff)} pass pitch angle cutoff\")\n",
    "        print(f\"{sum(alen_cutoff)} pass arm length ratio cutoff\")\n",
    "        print(f\"{sum(sign_cutoff)} pass chiral agreement\")\n",
    "        print(f\"{len(success_df)} or {100*len(success_df)/len(full_df):.2f}% ({len(success_df)}/{len(full_df)}) succeed by SpArcFiRe+Score\")\n",
    "        if sparcfire_processed is not None:\n",
    "            sparcfire_processed = full_df.dropna(subset = [\"min_arm_pa_diff\", \"pa_diff_galaxy\"], how = \"all\")\n",
    "        \n",
    "        print(f\"{total_galaxies - len(sparcfire_processed)}/{total_galaxies} models failed reprocessing by SpArcFiRe\")\n",
    "        \n",
    "        #print(f\"Total success less 24% false positive -- {len(success_df)*.76:.0f}\")\n",
    "        #print(f\"Total success less 24% false positive + 24% false negative -- {len(not_success_df)*0.24+len(success_df)*.76:.0f}\")\n",
    "        #print(f\"Estimated total success % -- {100*(len(not_success_df)*0.24+len(success_df)*.76)/len(full_df):.0f}%\")\n",
    "    \n",
    "    # cutoffs = {\n",
    "    #     \"residual_cutoff\" : residual_cutoff, \n",
    "    #     \"pa_cutoff\"       : pa_cutoff, \n",
    "    #     \"alen_cutoff\"     : alen_cutoff, \n",
    "    #     \"sign_cutoff\"     : sign_cutoff\n",
    "    # }\n",
    "    return success_df, not_success_df # , cutoffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a24bed-8970-4c51-b8a9-83d51e80bdd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_by_eye_data(\n",
    "    out_dir, \n",
    "    basename, \n",
    "    residual_df, \n",
    "    full_df,\n",
    "    **kwargs\n",
    "):\n",
    "    \n",
    "    sparcfire_processed = kwargs.get(\"sparcfire_processed\", None)\n",
    "    subset              = kwargs.get(\"subset\", None)\n",
    "    verbose             = kwargs.get(\"verbose\", True)\n",
    "    \n",
    "    with open(f\"{pj(out_dir, basename, basename)}_by-eye_success.txt\", \"r\") as f:\n",
    "        raw_by_eye_success_galaxies = [i.split(\"_\")[0].strip() for i in f.readlines()]\n",
    "\n",
    "    with open(f\"{pj(out_dir, basename, basename)}_by-eye_not_success.txt\", \"r\") as f:\n",
    "        raw_by_eye_not_success_galaxies = [i.split(\"_\")[0].strip() for i in f.readlines()]\n",
    "        \n",
    "    by_eye_success_galaxies = [i for i in raw_by_eye_success_galaxies if i in full_df.index]\n",
    "    by_eye_not_success_galaxies = [i for i in raw_by_eye_not_success_galaxies if i in full_df.index]\n",
    "    if sparcfire_processed is not None:\n",
    "        sparcfire_processed = full_df.dropna(subset = [\"min_arm_pa_diff\", \"pa_diff_galaxy\"], how = \"all\")\n",
    "    \n",
    "    if verbose:\n",
    "        total = len(residual_df)\n",
    "        if subset:\n",
    "            total = subset\n",
    "            print(f\"Working on a subset of {total} galaxies\")\n",
    "            \n",
    "        align = len(f\"{len(by_eye_success_galaxies)}/{len(raw_by_eye_success_galaxies)}\")\n",
    "        print(f\"Number of *total* by eye successful galaxies\")\n",
    "        print(f\"{len(raw_by_eye_success_galaxies):<{align}} => {len(raw_by_eye_success_galaxies)/total*100:.2f}%\")\n",
    "        print(f\"Number of by eye successful galaxies that SpArcFiRe *could* process\")\n",
    "        by_eye_processed = [i for i in sparcfire_processed.index if i in raw_by_eye_success_galaxies]\n",
    "        print(f\"{len(by_eye_processed)}/{len(raw_by_eye_success_galaxies)} => {len(by_eye_processed)/len(raw_by_eye_success_galaxies)*100:.2f}%\")\n",
    "        \n",
    "        print()\n",
    "        \n",
    "        align = len(f\"{len(by_eye_not_success_galaxies)}/{len(raw_by_eye_not_success_galaxies)}\")\n",
    "        print(f\"Number of *total* by eye not successful galaxies\")\n",
    "        print(f\"{len(raw_by_eye_not_success_galaxies):<{align}} => {len(raw_by_eye_not_success_galaxies)/total*100:.2f}%\")\n",
    "        \n",
    "        print(f\"Number of by eye not successful galaxies that SpArcFiRe *could* process\")\n",
    "        by_eye_processed = [i for i in sparcfire_processed.index if i in raw_by_eye_not_success_galaxies]\n",
    "        print(f\"{len(by_eye_processed)}/{len(raw_by_eye_not_success_galaxies)} => {len(by_eye_processed)/len(raw_by_eye_not_success_galaxies)*100:.2f}%\")\n",
    "    \n",
    "    return by_eye_success_galaxies, by_eye_not_success_galaxies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49f540e-82da-4e7b-8c61-6779c16075a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_false_positive_negative(\n",
    "    by_eye_success_galaxies, \n",
    "    by_eye_not_success_galaxies, \n",
    "    success_df, \n",
    "    not_success_df, \n",
    "    full_df,\n",
    "    method  = \"nmr_x_1-p\",\n",
    "    verbose = True\n",
    "):\n",
    "    \n",
    "    false_positive = set(by_eye_not_success_galaxies).intersection(set(success_df.index))\n",
    "    false_negative = set(by_eye_success_galaxies).intersection(set(not_success_df.index))\n",
    "\n",
    "    by_eye_success_df     = full_df.loc[by_eye_success_galaxies].sort_values(by = method)\n",
    "    by_eye_not_success_df = full_df.loc[by_eye_not_success_galaxies].sort_values(by = method)\n",
    "\n",
    "    FP_rate = f\"{len(false_positive)}/({len(false_positive)} + {len(by_eye_not_success_df)})\"\n",
    "    FN_rate = f\"{len(false_negative)}/({len(false_negative)} + {len(by_eye_success_df)})\"\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"False positive rate (by eye) -- {FP_rate} = {100*eval(FP_rate):.2f}%\")\n",
    "        print(f\"False negative rate (by eye) -- {FN_rate} = {100*eval(FN_rate):.2f}%\")\n",
    "\n",
    "    #print(f\"Total # of galaxies sorted by eye -- {len(raw_by_eye_success_galaxies) + len(raw_by_eye_not_success_galaxies)}\")\n",
    "    return by_eye_success_df, by_eye_not_success_df, FP_rate, FN_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a481b27c-a6ff-4fc8-86ed-0ae1e24c014c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def vprint(verbosity, *args, **kwargs):\n",
    "    if verbosity:\n",
    "        print(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be746f45-f1ed-4663-b6ab-5c08d86c3efb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_full_df_with_petromags(\n",
    "    full_df,\n",
    "    petromag_df,\n",
    "    color_band\n",
    "):\n",
    "    \n",
    "    petromag_col = f\"petroMag_{color_band}\"\n",
    "        \n",
    "    full_df   = full_df.join(petromag_df[petromag_col])#.dropna(subset = petromag_col)\n",
    "\n",
    "    highest_mag_num = int(sorted([x for x in full_df.columns if x.startswith(\"magnitude_sersic\")])[-1][-1])\n",
    "\n",
    "    for i in range(1, highest_mag_num + 1):\n",
    "        full_df[f\"petromag_{color_band}_diff_{i}\"] = full_df[f\"magnitude_sersic_{i}\"] - full_df[petromag_col]\n",
    "        \n",
    "    return full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6fcd6b-d3b1-4e8a-a675-1d196bbe4d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_analysis(\n",
    "    **kwargs\n",
    "):\n",
    "    \n",
    "    in_dir                = kwargs.get(\"in_dir\", \"sparcfire-in\")\n",
    "    out_dir               = kwargs.get(\"out_dir\", \"sparcfire-out\")\n",
    "    basename              = kwargs.get(\"basename\", \"\") \n",
    "    method                = kwargs.get(\"method\", \"nmr_x_1-p\")\n",
    "    flip_chiral_agreement = kwargs.get(\"flip_chiral_agreement\", False)\n",
    "    pa_cutoff_val         = kwargs.get(\"pa_cutoff_val\", 10)\n",
    "    residual_cutoff_val   = kwargs.get(\"residual_cutoff_val\", 0.5)\n",
    "    alen_cutoff_val       = kwargs.get(\"alen_cutoff_val\", 0.007)\n",
    "    incl_by_eye           = kwargs.get(\"incl_by_eye\", True)\n",
    "    by_eye_subset         = kwargs.get(\"by_eye_subset\", None)\n",
    "    color_band            = kwargs.get(\"color_band\", \"r\")\n",
    "    petromag_df           = kwargs.get(\"petromag_df\", pd.DataFrame())\n",
    "    verbose               = kwargs.get(\"verbose\", False)\n",
    "    \n",
    "    vprint(verbose, \"Load residual.\")\n",
    "    residual_df = load_residual_df(\n",
    "        out_dir, \n",
    "        basename, \n",
    "        method = method, \n",
    "        residual_cutoff_val = residual_cutoff_val\n",
    "    )\n",
    "    \n",
    "    # field_pa   = \"pitch_angle\"\n",
    "    # field_alen = \"arc_length\"\n",
    "    # name_col   = \"gxyName\"\n",
    "\n",
    "    vprint(verbose, \"Load pre galaxy csv.\")\n",
    "    pre_sparc_output_csv        = load_galaxy_csv(out_dir,      basename, pre_post = \"pre\")\n",
    "        \n",
    "    vprint(verbose, \"Load pre galaxy arcs csv.\")\n",
    "    pre_sparc_output_arcs_top2  = load_galaxy_arcs_csv(out_dir, basename, pre_post = \"pre\")\n",
    "\n",
    "    vprint(verbose, \"Load post galaxy csv.\")\n",
    "    post_sparc_output_csv       = load_galaxy_csv(out_dir,      basename, pre_post = \"post\")\n",
    "    \n",
    "    vprint(verbose, \"Load post galaxy arcs csv.\")\n",
    "    post_sparc_output_arcs_top2 = load_galaxy_arcs_csv(out_dir, basename, pre_post = \"post\")\n",
    "\n",
    "# ====================================================================================================================\n",
    "\n",
    "    vprint(verbose, \"Prep pre galaxy arcs df\")\n",
    "    pre_sp_out    = prepare_arcs_output(pre_sparc_output_arcs_top2,  pre_post = \"pre\")\n",
    "    vprint(verbose, \"Prep post galaxy arcs df\")\n",
    "    post_sp_out   = prepare_arcs_output(post_sparc_output_arcs_top2, pre_post = \"post\")\n",
    "\n",
    "    vprint(verbose, \"And combine\")\n",
    "    all_sparc_out = pd.concat([pre_sp_out, post_sp_out], axis = 1)\n",
    "    \n",
    "# ====================================================================================================================\n",
    "\n",
    "    vprint(verbose, \"Compare SpArcFiRe analysis before and after\")\n",
    "    before_after_galfit_df     = before_after_galfit_comparison(\n",
    "        all_sparc_out, \n",
    "        pre_sparc_output_csv, \n",
    "        post_sparc_output_csv\n",
    "    )\n",
    "    \n",
    "    vprint(verbose, \"Bring everything together\")\n",
    "    full_df             = gather_everything(residual_df, before_after_galfit_df, method)\n",
    "    \n",
    "    if not petromag_df.empty:\n",
    "        vprint(verbose, \"Load dataframe with petromag information\")\n",
    "        full_df         = load_full_df_with_petromags(full_df, petromag_df, color_band)\n",
    "    \n",
    "    sparcfire_processed = full_df.dropna(subset = [\"min_arm_pa_diff\", \"pa_diff_galaxy\"], how = \"all\")\n",
    "    \n",
    "    vprint(verbose, \"Determine success\")\n",
    "    success_df, not_success_df = determine_success(\n",
    "        full_df, \n",
    "        in_dir                 = in_dir, \n",
    "        out_dir                = out_dir, \n",
    "        flip_chiral_agreement  = flip_chiral_agreement,\n",
    "        sparcfire_processed    = sparcfire_processed,\n",
    "        pa_cutoff_val          = pa_cutoff_val, \n",
    "        residual_cutoff_val    = residual_cutoff_val,\n",
    "        alen_cutoff_val        = alen_cutoff_val\n",
    "    )\n",
    "    \n",
    "    full_df[\"success\"] = full_df.index.isin(success_df.index)\n",
    "    print()\n",
    "    \n",
    "# ====================================================================================================================\n",
    "    \n",
    "    by_eye_success_df     = pd.DataFrame()\n",
    "    by_eye_not_success_df = pd.DataFrame()\n",
    "    \n",
    "    if incl_by_eye:\n",
    "        vprint(verbose, \"Extract by-eye evaluation\")\n",
    "        by_eye_success_galaxies, by_eye_not_success_galaxies = extract_by_eye_data(\n",
    "            out_dir, \n",
    "            basename, \n",
    "            residual_df, \n",
    "            full_df, \n",
    "            subset = by_eye_subset,\n",
    "            sparcfire_processed = sparcfire_processed\n",
    "        )\n",
    "        print()\n",
    "\n",
    "        # To resolve an occasional processing error...\n",
    "        by_eye_success_limited     = list(set(by_eye_success_galaxies).intersection(full_df.index))\n",
    "        by_eye_not_success_limited = list(set(by_eye_not_success_galaxies).intersection(full_df.index))\n",
    "\n",
    "        vprint(verbose, \"Calculate by-eye statistics\")\n",
    "        by_eye_success_df, by_eye_not_success_df, FP_rate, FN_rate = calculate_false_positive_negative(\n",
    "            by_eye_success_limited, \n",
    "            by_eye_not_success_limited, \n",
    "            success_df, \n",
    "            not_success_df, \n",
    "            full_df,\n",
    "            method = method\n",
    "        )\n",
    "\n",
    "        full_df[\"by_eye_success\"] = full_df.index.isin(by_eye_success_df.index)\n",
    "    \n",
    "    results_nt = all_results_nt(full_df, success_df, not_success_df, by_eye_success_df, by_eye_not_success_df)\n",
    "    for df in results_nt:\n",
    "        df[\"runname\"]  = basename\n",
    "        \n",
    "    return results_nt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86d3aa8-f9c3-4490-9092-cc594f47de05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_multi_run_results(\n",
    "    method, \n",
    "    *args,\n",
    "    **kwargs\n",
    "):\n",
    "    \n",
    "    df_names      = kwargs.get(\"df_names\", [])\n",
    "    incl_by_eye   = kwargs.get(\"incl_by_eye\", True)\n",
    "    by_eye_subset = kwargs.get(\"by_eye_subset\", None)\n",
    "    verbose       = kwargs.get(\"verbose\", True)\n",
    "    \n",
    "    print(f\"Joining {len(args)} attempts...\")\n",
    "    primary_full_df = deepcopy(args[0].full_df)\n",
    "    \n",
    "    num_dfs = len(args)\n",
    "    #alt_full_df     = deepcopy(args[1].full_df)\n",
    "    #alt_full_df.rename(columns = {method : f\"1_{method}\"}, inplace = True)\n",
    "\n",
    "    all_full_dfs = [primary_full_df]\n",
    "    all_methods  = [method]\n",
    "    all_columns  = []\n",
    "    \n",
    "    for i, arg in enumerate(args[1:]):\n",
    "        alt_method = f\"{i}_{method}\"\n",
    "        all_methods.append(alt_method)\n",
    "        \n",
    "        all_full_dfs.append(arg.full_df.rename(columns = {method : alt_method}))\n",
    "        all_columns.append(set(arg.full_df.columns))\n",
    "        \n",
    "    shared_columns = list(set(primary_full_df.columns).intersection(*all_columns)) + [\"gname\"]\n",
    "    #empty_list = [None]*max([len(df) for df in all_full_dfs])\n",
    "    #empty_df = pd.DataFrame({col : None for col in shared_columns}) #.set_index(\"gname\")\n",
    "    \n",
    "    # BY RESIDUAL\n",
    "    #temp_bool_df = pd.concat([primary_full_df[method], alt_full_df[f\"1_{method}\"]], axis = 1)\n",
    "    combined_bool_df = pd.concat([df[method] for df, method in zip(all_full_dfs, all_methods)], axis = 1)\n",
    "\n",
    "    #combined_bool_df.drop(index = list(set(primary_full_df.index).difference(set(alt_full_df.index))), inplace = True)\n",
    "    #temp_bool_df[\"minima\"] = temp_bool_df.idxmin(axis = 1)\n",
    "    combined_bool_df[\"minima\"] = combined_bool_df.idxmin(axis = 1)\n",
    "    \n",
    "    #og_minima  = temp_bool_df.minima == method\n",
    "    #alt_minima = temp_bool_df.minima == f\"1_{method}\"\n",
    "    \n",
    "    #og_success = temp_bool_df.index.isin(args[0].by_eye_success_df.index)\n",
    "    #alt_success = temp_bool_df.index.isin(args[1].by_eye_success_df.index)\n",
    "    #print(sum((og_minima & og_success) | (alt_minima & alt_success)))\n",
    "        \n",
    "    # By everything\n",
    "    eval_str = \" | \".join([f\"all_full_dfs[{i}].success\" for i in range(num_dfs)])\n",
    "    # success_n | success_m\n",
    "    combined_bool_df[\"by_sparcfire_score_success\"] = eval(eval_str) #primary_full_df.success | alt_full_df.success # | combined_bool_df.residual_minima_success\n",
    "    \n",
    "    minima_conditions  = [combined_bool_df.minima == method for method in all_methods]\n",
    "    success_conditions = [df.success for df in all_full_dfs]\n",
    "    all_conditions     = zip(minima_conditions, success_conditions)\n",
    "    \n",
    "    list_o_conditions = [cond_set[0] & cond_set[1] for cond_set in all_conditions]\n",
    "    eval_str = \" | \".join([f\"list_o_conditions[{i}]\" for i in range(num_dfs)])\n",
    "    # minima -> success_minima\n",
    "    combined_bool_df[\"by_sparcfire_and_best_score_success\"] = eval(eval_str)\n",
    "    \n",
    "    combined_bool_df[\"best_fit\"] = combined_bool_df[combined_bool_df.by_sparcfire_score_success].minima.replace(\n",
    "        {alt_method : name for alt_method, name in zip(all_methods, df_names)}\n",
    "    )\n",
    "    \n",
    "    if incl_by_eye:\n",
    "        \n",
    "        # Use by eye success df to account for by eye subsets (and to shorten the array) rather than info in full_df\n",
    "        by_eye_success_conditions = [combined_bool_df.index.isin(df.by_eye_success_df.index) for df in args]\n",
    "        # Flatten\n",
    "        all_by_eye_success_gnames     = list(set([gname for df in args for gname in df.by_eye_success_df.index]))\n",
    "        #all_by_eye_not_success_gnames = list(set([gname for df in args for gname in df.by_eye_not_success_df.index]))\n",
    "        all_by_eye_not_success_gnames = list(set([gname for df in args for gname in df.by_eye_not_success_df.index]))\n",
    "        #by_sparcfire_success_cond = [combined_bool_df.by_sparcfire_success == method for method in all_methods]\n",
    "\n",
    "        combined_bool_df[\"residual_success_by_eye\"] = combined_bool_df.index.isin(all_by_eye_success_gnames) & combined_bool_df.by_sparcfire_score_success \n",
    "        \n",
    "        all_conditions = zip(minima_conditions, by_eye_success_conditions)\n",
    "        list_o_conditions = [cond_set[0] & cond_set[1] for cond_set in all_conditions]\n",
    "        eval_str = \" | \".join([f\"list_o_conditions[{i}]\" for i in range(num_dfs)])\n",
    "\n",
    "        # How well does choosing the smallest residual score across all runs work in picking a successful fit\n",
    "        # when compared with the by eye analysis?\n",
    "        # minima -> (success_minima & by eye)\n",
    "        combined_bool_df[\"residual_minima_success_by_eye\"] = eval(eval_str)\n",
    "        # print(sum((minima_conditions[0] & by_eye_success_conditions[0]) | (minima_conditions[1] & by_eye_success_conditions[1])))\n",
    "        # print(sum(list_o_conditions[0] | list_o_conditions[1]))\n",
    "        \n",
    "        by_sparcfire_success_by_eye = combined_bool_df.index.isin(all_by_eye_success_gnames) & combined_bool_df.by_sparcfire_score_success\n",
    "            \n",
    "        # As with and including residual minima, but now include the sparcfire scoring\n",
    "        # (minima -> [success_minima & by eye]) | ([success_m | success_n] & by eye)\n",
    "        combined_bool_df[\"by_minima_or_sparcfire_success_by_eye\"]  = by_sparcfire_success_by_eye | combined_bool_df.residual_minima_success_by_eye\n",
    "        # Comment out this one because it's filtering both individually by eye rather than doing (minima | score) & by eye\n",
    "        #combined_bool_df[\"by_minima_and_sparcfire_success_by_eye\"] = by_sparcfire_success_by_eye & combined_bool_df.residual_minima_success_by_eye\n",
    "    \n",
    "        # TODO: Show % in both\n",
    "        # by eye success for all labeled by df\n",
    "        best_fit_str_dict = {m : f\"df_{i}\" for i, m in enumerate(all_methods)}\n",
    "        combined_bool_df[\"best_fit_by_eye\"] = None\n",
    "\n",
    "        for gname, row in combined_bool_df.iterrows():\n",
    "            best_method = [\n",
    "                (m, full_df.loc[gname, \"by_eye_success\"]) \n",
    "                for m, full_df in zip(all_methods, all_full_dfs)\n",
    "                if gname in full_df.index and full_df.loc[gname, \"by_eye_success\"]\n",
    "            ]\n",
    "\n",
    "            if len(best_method) > 1:\n",
    "                best_method = [(row.minima, None)]\n",
    "\n",
    "            elif not best_method:\n",
    "                best_method = [(None, None)]\n",
    "\n",
    "            if not combined_bool_df.loc[gname, \"best_fit_by_eye\"]:\n",
    "                combined_bool_df.loc[gname, \"best_fit_by_eye\"] = best_fit_str_dict.get(best_method[0][0], None)\n",
    "\n",
    "        #eval_str = \" | \".join([f\"all_full_dfs[{i}].by_eye_success\" for i, _ in enumerate(all_full_dfs)])\n",
    "        #combined_bool_df[\"by_eye_success\"] = eval(eval_str) #primary_full_df.by_eye_success | alt_full_df.by_eye_success\n",
    "        combined_bool_df[\"by_eye_success\"] = False | combined_bool_df.best_fit_by_eye.str.contains(\"df\")\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Total success by combining SpArcFiRe + score: {sum(combined_bool_df.by_sparcfire_score_success)}/{total_galaxies}\")\n",
    "        print(f\"i.e. success_n | success_m | ...\")\n",
    "        print()\n",
    "        print(f\"Total success by combining SpArcFiRe + best score: {sum(combined_bool_df.by_sparcfire_and_best_score_success)}/{total_galaxies}\")\n",
    "        print(f\"i.e. minima -> success_minima\")\n",
    "        print(mini_sep)\n",
    "        if incl_by_eye:\n",
    "            print(\"Checking against the by eye determination...\")\n",
    "            _total_galaxies = total_galaxies\n",
    "            if df_names:\n",
    "                if len(df_names) != num_dfs: \n",
    "                    print(\"Length of dataframe names supplied should be equal to the number of dataframes supplied.\")\n",
    "                    print(\"Leaving current convention in the dataframe (df_0, df_1, ..., df_n)\")\n",
    "                else:\n",
    "                    combined_bool_df[\"best_fit_by_eye\"]   = combined_bool_df.best_fit_by_eye.replace({f\"df_{i}\" : name for i, name in enumerate(df_names)})\n",
    "            \n",
    "            if by_eye_subset:\n",
    "                _total_galaxies = by_eye_subset\n",
    "                print(\"Using a subset of galaxies for the by eye determination...\")\n",
    "                \n",
    "            print(f\"Total success by eye: {sum(combined_bool_df.by_eye_success)}/{_total_galaxies}\")\n",
    "            total_by_eye = sum(combined_bool_df.by_eye_success)\n",
    "            print()\n",
    "            print(f\"By eye captured by either score: {sum(combined_bool_df.residual_success_by_eye)}/{total_by_eye}\")\n",
    "            print(f\"i.e. (success_m | success_n | ...) & by eye\")\n",
    "            print()\n",
    "            print(f\"By eye captured by best score: {sum(combined_bool_df.residual_minima_success_by_eye)}/{total_by_eye}\")\n",
    "            print(f\"i.e. minima -> (success_minima & by eye)\")\n",
    "            print()\n",
    "            print(f\"By eye captured by SpArcFiRe or choosing best score between the two runs: {sum(combined_bool_df.by_minima_or_sparcfire_success_by_eye)}/{total_by_eye}\")\n",
    "            print(f\"i.e. (minima -> [success_minima & by eye]) | ([success_m | success_n | ...] & by eye)\")\n",
    "            #print(f\"By eye captured by SpArcFiRe and choosing best score between the two runs: {sum(combined_bool_df.by_minima_and_sparcfire_success_by_eye)}/{total_by_eye}\")\n",
    "            print(mini_sep)\n",
    "\n",
    "            bss  = set(combined_bool_df[combined_bool_df.by_sparcfire_score_success].index)\n",
    "            #bss  = set(combined_bool_df[bss.isin(all_by_eye_success_gnames)].index)\n",
    "            TP   = all_by_eye_success_gnames\n",
    "            #TP   = set(combined_bool_df[combined_bool_df[\"by_eye_success\"]].index)\n",
    "            \n",
    "            #bsns  = ~combined_bool_df.by_sparcfire_score_success\n",
    "            bsns = combined_bool_df[~combined_bool_df.by_sparcfire_score_success].index\n",
    "            #bsns = bsns.index\n",
    "            #bsns = set(combined_bool_df[bsns.isin(all_by_eye_not_success_gnames)].index)\n",
    "            \n",
    "            # Exclude the ones found in the success galaxies because some runs may find success where the others didn't\n",
    "            TN =  set(all_by_eye_not_success_gnames).difference(set(all_by_eye_success_gnames))\n",
    "            assert len(TP) + len(TN) == _total_galaxies, f\"True positive and true negative don't add up to {_total_galaxies}!\"\n",
    "            #TN   = combined_bool_df[~combined_bool_df[\"by_eye_success\"]].index\n",
    "            #TN   = set(TN[TN.isin(all_by_eye_not_success_gnames)])\n",
    "\n",
    "            FP   = bss.intersection(TN)\n",
    "            FN   = bsns.intersection(TP)\n",
    "\n",
    "            sparc_positive = bss.intersection(TP)\n",
    "            sparc_negative = bsns.intersection(TN)\n",
    "            fraction = len(sparc_positive)/sum(combined_bool_df.by_eye_success)\n",
    "            \n",
    "            combined_bool_by_eye_not_success = ~combined_bool_df.by_eye_success\n",
    "            denom = combined_bool_by_eye_not_success[combined_bool_by_eye_not_success.index.isin(all_by_eye_not_success_gnames)]\n",
    "            neg_fraction = len(sparc_negative)/sum(denom)\n",
    "            # FPR = FP/(FP + TN)\n",
    "            # FNR = FN/(FN + TP)\n",
    "            # TODO WTF\n",
    "            print(f\"By eye success found by SpArcFiRe + score:  {len(sparc_positive)}/{sum(combined_bool_df.by_eye_success)} = {100*fraction:.2f}%\")\n",
    "            print(f\"By eye not success found by SpArcFiRe + score:  {len(sparc_negative)}/{sum(denom)} = {100*neg_fraction:.2f}%\")\n",
    "            \n",
    "            FP_rate = f\"{len(FP)} / ({len(FP)} + {len(TN)})\"\n",
    "            FN_rate = f\"{len(FN)} / ({len(FN)} + {len(TP)})\"\n",
    "\n",
    "            print()\n",
    "            print(f\"False positive rate (by eye) -- {FP_rate} = {100*eval(FP_rate):.2f}%\")\n",
    "            print(f\"False negative rate (by eye) -- {FN_rate} = {100*eval(FN_rate):.2f}%\")\n",
    "            \n",
    "            # TODO: GENERATE CONFUSION MATRIX\n",
    "            #print()\n",
    "            #print(f\"Confusion matrix\")\n",
    "            #print()\n",
    "            #print()\n",
    "    \n",
    "    \n",
    "    _ = [full_df.rename(columns = {alt_method : method}, inplace = True) for alt_method, full_df in zip(all_methods[1:], all_full_dfs[1:])]\n",
    "    \n",
    "    combined_full_df = pd.concat([full_df for full_df in all_full_dfs])\n",
    "    \n",
    "    combined_success_df = pd.concat(\n",
    "                full_df.loc[combined_bool_df[combined_bool_df.best_fit == name].index, :] \n",
    "                for name, full_df in zip(df_names, all_full_dfs)\n",
    "            )\n",
    "            \n",
    "    combined_by_eye_success_df = None\n",
    "    if incl_by_eye:\n",
    "        # Get index, i.e. galaxy name from choosing the best fit then feed that into the full_dfs in all_full_dfs via loc\n",
    "        # to grab the row\n",
    "        combined_by_eye_success_df = pd.concat(\n",
    "            full_df.loc[combined_bool_df[combined_bool_df.best_fit_by_eye == name].index, :] \n",
    "            for name, full_df in zip(df_names, all_full_dfs)\n",
    "        )\n",
    "    \n",
    "    return combined_results_nt(combined_bool_df, combined_full_df, combined_success_df, combined_by_eye_success_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "693a33b8-825d-40d2-88ec-906322df9ec7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_ecdf(\n",
    "    x,\n",
    "    df, \n",
    "    dict_o_kwargs\n",
    "):\n",
    "\n",
    "    fig = px.ecdf(\n",
    "        df,\n",
    "        x        = x,\n",
    "        markers  = True, \n",
    "        lines    = False, \n",
    "        marginal = dict_o_kwargs.get(\"marginal\"),\n",
    "        ecdfnorm = None,\n",
    "     ) \n",
    "\n",
    "    cutoff_val = dict_o_kwargs.get(\"cutoff_val\")\n",
    "    if dict_o_kwargs.get(\"add_vline\"):\n",
    "        fig.add_vline(x = cutoff_val, \n",
    "                      row = 1,\n",
    "                      line_color = \"cyan\",\n",
    "                      annotation_text= f\"{cutoff_val}\", \n",
    "                      annotation_position=\"bottom\")\n",
    "\n",
    "    if dict_o_kwargs.get(\"add_hline\"):\n",
    "        yval = sum(df.loc[:, x] < cutoff_val)\n",
    "        fig.add_hline(y = yval, \n",
    "                      row = 1,\n",
    "                      col = 1,\n",
    "                      line_color = \"magenta\",\n",
    "                      annotation_text=f\"{yval}\",\n",
    "                      annotation_position=\"bottom left\"\n",
    "                     )\n",
    "        \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "d8fe7455-01b0-477f-beb7-0d72b1af46db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_scatter(\n",
    "    x, \n",
    "    y, \n",
    "    df, \n",
    "    dict_o_kwargs\n",
    "):\n",
    "    \n",
    "    color_continuous_scale    = \"Agsunset\"\n",
    "    #if dict_o_kwargs.get(\"color_continuous_midpoint\"):\n",
    "    #    color_continuous_scale = \"Portland\"\n",
    "    \n",
    "    fig = px.scatter(\n",
    "        df, \n",
    "        x = x, \n",
    "        y = y,\n",
    "        color                     = dict_o_kwargs.get(\"color\"),\n",
    "        color_continuous_scale    = color_continuous_scale,\n",
    "        range_color               = dict_o_kwargs.get(\"range_color\"),\n",
    "        #color_continuous_midpoint = dict_o_kwargs.get(\"color_continuous_midpoint\"),\n",
    "    )\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "fbe217be-635a-4f9a-85d1-bf40d0bb4fcb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_histogram(\n",
    "    x, \n",
    "    df, \n",
    "    dict_o_kwargs, \n",
    "):\n",
    "    \n",
    "    df[x] +=  dict_o_kwargs.get(\"hist_offset\", 0)\n",
    "    fig = px.histogram(\n",
    "        df,\n",
    "        x                       = x,\n",
    "        color                   = dict_o_kwargs.get(\"color\"),\n",
    "        color_discrete_sequence = dict_o_kwargs.get(\"color_discrete_sequence\"),\n",
    "        histnorm                = dict_o_kwargs.get(\"histnorm\"),\n",
    "        facet_col               = dict_o_kwargs.get(\"facet_col\"),\n",
    "        facet_row               = dict_o_kwargs.get(\"facet_row\"),\n",
    "        nbins                   = dict_o_kwargs.get(\"nbins\", 0),\n",
    "        marginal                = dict_o_kwargs.get(\"marginal\"),\n",
    "        #hover_data = {'Galaxy ID': (\":c\", full_df.index)},\n",
    "    )\n",
    "    \n",
    "    if dict_o_kwargs.get(\"facet_col\") or dict_o_kwargs.get(\"facet_row\"):\n",
    "        fig.for_each_annotation(lambda a: a.update(text = a.text.split(\"=\")[-1]))\n",
    "\n",
    "    # if multi:\n",
    "    #     fig.update_layout(barmode = \"overlay\")\n",
    "    #     fig.update_traces(\n",
    "    #         opacity = 0.75,\n",
    "    #         marker_line_width = 1,\n",
    "    #         marker_line_color = \"white\"\n",
    "    #     )\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "8a462a65-144d-4794-83a8-2255ee54d4de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_overlay_histogram(\n",
    "    x,\n",
    "    dfs,\n",
    "    dict_o_kwargs\n",
    "):\n",
    "    \n",
    "    histnorm    = dict_o_kwargs.get(\"histnorm\", \"probability\")\n",
    "    nbinsx      = dict_o_kwargs.get(\"nbins\", 40)\n",
    "    \n",
    "    xmin, xmax  = None, None\n",
    "    xaxis_range = dict_o_kwargs.get(\"xaxis_range\", (xmin, xmax))\n",
    "    \n",
    "    if isinstance(xaxis_range, (tuple, list)) and all(xaxis_range):\n",
    "        xmin, xmax  = xaxis_range\n",
    "        \n",
    "    xbins       = None\n",
    "    \n",
    "    # Because xmin could be 0\n",
    "    if nbinsx and isinstance(xmin, (int, float)) and isinstance(xmax, (int, float)):\n",
    "        #print(xmin, xmax, nbinsx)\n",
    "        xbins = dict(\n",
    "            start = xmin,\n",
    "            end   = xmax,\n",
    "            size  = (xmax - xmin)/nbinsx,\n",
    "        )\n",
    "    \n",
    "    colors = deepcopy(px.colors.qualitative.Plotly)\n",
    "    # Bulge -- Redder\n",
    "    colors[0] = px.colors.qualitative.Plotly[1]\n",
    "    # Disk -- Bluer\n",
    "    colors[1] = px.colors.qualitative.Plotly[0]\n",
    "    \n",
    "    num_rows, num_cols = ceil(len(dfs)/3), len(dfs)\n",
    "    # facet_col = dict_o_kwargs.get(\"facet_col\")\n",
    "    # if facet_col:\n",
    "    #     num_cols  = len(df[facet_col].unique())\n",
    "    #     reversed_cols.pop(facet_col)\n",
    "        \n",
    "    # facet_row = dict_o_kwargs.get(\"facet_row\")\n",
    "    # if facet_row:\n",
    "    #     num_rows  = len(df[facet_row].unique())\n",
    "    #     reversed_cols.pop(facet_row)\n",
    "    \n",
    "    # colors and to_plot is already reversed so they're fine as-is\n",
    "    fig = make_subplots(\n",
    "        num_rows, \n",
    "        num_cols,\n",
    "        subplot_titles = list(dfs.keys()),\n",
    "        shared_yaxes = True,\n",
    "    )\n",
    "    \n",
    "    dfs = list(dfs.values())\n",
    "    showlegend = True\n",
    "    for row in range(num_rows):\n",
    "        for col in range(num_cols):\n",
    "            df = dfs[3*row + col]\n",
    "            \n",
    "            reversed_cols   = list(reversed(deepcopy(df.columns)))\n",
    "            reversed_colors = reversed(colors[:len(df.columns)])\n",
    "    \n",
    "            for col_name, color in zip(reversed_cols, reversed_colors):\n",
    "                name     = col_name.split(\"_\")\n",
    "                name[-1] = str(int(name[-1]) + 1) # since we index at 0\n",
    "                name     = \" \".join(name)\n",
    "                \n",
    "                                    \n",
    "                fig.add_trace(\n",
    "                    go.Histogram(\n",
    "                        x                 = df[col_name] + dict_o_kwargs.get(\"hist_offset\", 0),\n",
    "                        histnorm          = histnorm,\n",
    "                        name              = name,\n",
    "                        marker_color      = color,\n",
    "                        nbinsx            = nbinsx,\n",
    "                        xbins             = xbins,\n",
    "                        showlegend        = showlegend,\n",
    "                        bingroup          = 1\n",
    "                        #marginal          = dict_o_kwargs.get(\"marginal\"),\n",
    "                        #hover_data = {'Galaxy ID': (\":c\", full_df.index)},\n",
    "                    ),\n",
    "                    row = row + 1, col = col + 1\n",
    "                )\n",
    "            # Turning this off after one go-round\n",
    "            showlegend = False\n",
    "        \n",
    "    # if facet_col or facet_row:\n",
    "    #     fig.for_each_annotation(lambda a: a.update(text = a.text.split(\"=\")[-1]))\n",
    "        \n",
    "    # This applies the yaxis title text to just 'one' of the facet cols, i.e. the first\n",
    "    fig.update_layout(\n",
    "        barmode           = \"overlay\",\n",
    "        legend_traceorder = \"reversed\",\n",
    "        yaxis_title_text  = histnorm,\n",
    "    )\n",
    "    \n",
    "    fig.update_traces(\n",
    "        opacity           = 0.75,\n",
    "        marker_line_width = 1,\n",
    "        marker_line_color = \"white\",\n",
    "    )\n",
    "    \n",
    "    # This applies x to *all* facet cols\n",
    "    fig.update_xaxes(\n",
    "        title_text = x\n",
    "    )\n",
    "        \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "8c26146b-9f20-456d-aa64-f0e0b56a6225",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_plot(\n",
    "    x, \n",
    "    runname, \n",
    "    plot_type, \n",
    "    df_or_dfs, \n",
    "    output_image_dir = \"for_paper_images\", \n",
    "    **kwargs\n",
    "):\n",
    "        \n",
    "    dict_o_kwargs = {\n",
    "        \"y\"               : None,\n",
    "        \n",
    "        # Need these for histogram binning\n",
    "        \"xaxis_range\"     : (None, None),\n",
    "        \"log_x\"           : None,\n",
    "        \n",
    "        \"color\"                     : None,\n",
    "        \"color_discrete_sequence\"   : None,\n",
    "        \"range_color\"               : None,\n",
    "        #\"color_continuous_midpoint\" : None,\n",
    "        \n",
    "        \"hist_offset\"     : 0,\n",
    "        \"histnorm\"        : \"\",\n",
    "        \"marginal\"        : None,\n",
    "        \"nbins\"           : 0,\n",
    "        \n",
    "        \"facet_col\"       : None,\n",
    "        \"facet_row\"       : None,\n",
    "        \n",
    "        \"cutoff_val\"      : 0.007,\n",
    "        \"add_vline\"       : True,\n",
    "        \"add_hline\"       : True,\n",
    "    }\n",
    "    \n",
    "    # Updating with kwargs\n",
    "    dict_o_kwargs = {key : kwargs.get(key, default) for key, default in dict_o_kwargs.items()}\n",
    "    \n",
    "    plt.clf()\n",
    "    #pio.templates.default = \"plotly_white\"\n",
    "    \n",
    "    if plot_type == \"ecdf\":\n",
    "        fig = create_ecdf(x, df_or_dfs, dict_o_kwargs)\n",
    "    elif plot_type == \"scatter\":\n",
    "        fig = create_scatter(x, dict_o_kwargs.get(\"y\"), df_or_dfs, dict_o_kwargs)\n",
    "    elif plot_type == \"histogram\":\n",
    "        fig = create_histogram(x, df_or_dfs, dict_o_kwargs)\n",
    "        #kwargs[\"yaxis_title\"] = kwargs.get(\"yaxis_title\", kwargs.get(\"histnorm\", \"probability\"))\n",
    "    elif plot_type == \"overlay_histogram\":\n",
    "        fig = create_overlay_histogram(x, df_or_dfs, dict_o_kwargs)\n",
    "    else:\n",
    "        return\n",
    "    \n",
    "    if kwargs.get(\"title\"):\n",
    "        fig.update_layout(\n",
    "            title_text = kwargs.get(\"title\"), \n",
    "            title_x    = kwargs.get(\"title_x\"), \n",
    "            title_y    = kwargs.get(\"title_y\")\n",
    "        )\n",
    "    \n",
    "    row, col = None, None\n",
    "    if plot_type != \"overlay_histogram\":\n",
    "        row, col = 1, 1\n",
    "        \n",
    "    if kwargs.get(\"xaxis_title\"):\n",
    "        fig.update_xaxes(title_text = kwargs.get(\"xaxis_title\"), row = row, col = col)\n",
    "    if kwargs.get(\"yaxis_title\"):\n",
    "        fig.update_yaxes(title_text = kwargs.get(\"yaxis_title\"), row = row, col = col)\n",
    "        \n",
    "    if kwargs.get(\"log_x\"):\n",
    "        fig.update_xaxes(type = \"log\", row = row, col = col)\n",
    "    if kwargs.get(\"log_y\"):\n",
    "        fig.update_yaxes(type = \"log\", row = row, col = col)\n",
    "       \n",
    "    xaxis_range = kwargs.get(\"xaxis_range\")\n",
    "    yaxis_range = kwargs.get(\"yaxis_range\")\n",
    "    if isinstance(xaxis_range, (tuple, list)):\n",
    "        fig.update_xaxes(range = kwargs.get(\"xaxis_range\"), row = row, col = col)\n",
    "    if isinstance(yaxis_range, (tuple, list)):\n",
    "        fig.update_yaxes(range = kwargs.get(\"yaxis_range\"), row = row, col = col)\n",
    "    \n",
    "    height           = kwargs.get(\"height\", 800)\n",
    "    width_multiplier = kwargs.get(\"width_multiplier\", 1.5) #1200\n",
    "    width            = height*width_multiplier\n",
    "    \n",
    "    if kwargs.get(\"show\"):\n",
    "        # Invert boolean so interactive = True means NOT static plot and vice-versa\n",
    "        fig.show(\n",
    "            config = {\n",
    "                'staticPlot' : not kwargs.get(\"interactive\", False),\n",
    "                'toImageButtonOptions': {\n",
    "                    'height': height,\n",
    "                    'width' : width\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "    \n",
    "    if kwargs.get(\"write\"):\n",
    "        filetype = kwargs.get(\"filetype\", \"png\")\n",
    "        fig.write_image(\n",
    "            f\"{output_image_dir}/{plot_type}_{x}_{runname}.{filetype}\", \n",
    "            height = height, \n",
    "            width = width\n",
    "        )\n",
    "        \n",
    "    fig.data   = []\n",
    "    fig.layout = {}\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "524b8133-afce-4840-9a24-9d145858b41f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_all_plots(\n",
    "    df_container,\n",
    "    method, \n",
    "    basename, \n",
    "    output_image_dir,\n",
    "    **kwargs\n",
    "):\n",
    "    \n",
    "    #color_band   = kwargs.get(\"color_band\", \"r\")\n",
    "    incl_by_eye = kwargs.get(\"incl_by_eye\", True)\n",
    "    show        = kwargs.get(\"show\", False)\n",
    "    interactive = kwargs.get(\"interactive\", False)\n",
    "    write       = kwargs.get(\"write\", False)\n",
    "\n",
    "# ============================================================================================================================================================\n",
    "# FULL ECDF\n",
    "# ============================================================================================================================================================\n",
    "\n",
    "    # Use a cutoff because there tends to be some extremely high values which skew the plot\n",
    "    plot_df = df_container.full_df[df_container.full_df.loc[:, method] < kwargs.get(\"score_ecdf_cutoff\", 0.015)].copy()\n",
    "    \n",
    "    _ = create_plot(\n",
    "        x                = method,\n",
    "        runname          = basename,\n",
    "        plot_type        = \"ecdf\",\n",
    "        df_or_dfs        = plot_df,\n",
    "        output_image_dir = output_image_dir,\n",
    "        xaxis_title      = method, #\"KStest+NMR\",\n",
    "        marginal         = \"histogram\",\n",
    "        # title       = f\"1000 galaxies: ECDF for KStest+NMR on all models\",\n",
    "        # title_y     = 0.92\n",
    "        cutoff_val       = kwargs.get(\"residual_cutoff_val\", 0.007),\n",
    "        show             = show,\n",
    "        interactive      = interactive,\n",
    "        write            = write\n",
    "    )\n",
    "    \n",
    "# ============================================================================================================================================================\n",
    "# ECDF OF BY EYE SCORE\n",
    "# ============================================================================================================================================================\n",
    "    \n",
    "    if incl_by_eye:\n",
    "        _ = create_plot(\n",
    "            x                = method,\n",
    "            runname          = f\"{basename}_by-eye\",\n",
    "            plot_type        = \"ecdf\",\n",
    "            df_or_dfs        = df_container.by_eye_success_df,\n",
    "            output_image_dir = output_image_dir,\n",
    "            xaxis_title      = method, #\"KStest+NMR\",\n",
    "            marginal         = \"histogram\",\n",
    "            #add_hline        = False,\n",
    "            # title       = f\"1000 galaxies: ECDF for KStest+NMR on by-eye successful model fits\",\n",
    "            # title_y     = 0.92\n",
    "            show             = show,\n",
    "            interactive      = interactive,\n",
    "            write            = write\n",
    "        )\n",
    "    \n",
    "# ============================================================================================================================================================\n",
    "# SERSIC INDEX HISTOGRAMS\n",
    "# ============================================================================================================================================================\n",
    "\n",
    "    # x1   = \"sersic_index_sersic_1\"\n",
    "    # x2   = \"sersic_index_sersic_2\"\n",
    "    # x3   = \"sersic_index_sersic_3\"\n",
    "    \n",
    "    x    = \"n\"\n",
    "    \n",
    "    cols_to_use = sorted([x for x in df_container.full_df.columns if x.startswith(\"sersic_index_sersic\")])        \n",
    "    rename      = {col_name : f\"sersic_{i}\" for i, col_name in enumerate(cols_to_use)}\n",
    "    \n",
    "    plot_df_all          = df_container.full_df[cols_to_use].copy().rename(columns = rename)\n",
    "    plot_df_success      = df_container.success_df[cols_to_use].copy().rename(columns = rename)\n",
    "    \n",
    "    to_plot  = {\"all models\" : plot_df_all, \"success\" : plot_df_success}\n",
    "    runname   = f\"{basename}_all-vs-success\"\n",
    "    \n",
    "    if incl_by_eye:\n",
    "        plot_df_by_eye = df_container.by_eye_success_df[cols_to_use].copy().rename(columns = rename)\n",
    "        to_plot[\"by-eye success\"] = plot_df_by_eye\n",
    "        runname   = f\"{basename}_all-vs-success-vs-by-eye\"\n",
    "    \n",
    "    _ = create_plot(\n",
    "        x                       = x,\n",
    "        runname                 = runname,\n",
    "        plot_type               = \"overlay_histogram\",\n",
    "        df_or_dfs               = to_plot,\n",
    "        output_image_dir        = output_image_dir,\n",
    "        histnorm                = \"probability\",\n",
    "        #marginal                = \"rug\",\n",
    "        #color                   = \"component\",\n",
    "        #color_discrete_sequence = colors,\n",
    "        nbins                   = kwargs.get(\"nbins\", 40),\n",
    "        #facet_col               = fcol,\n",
    "        xaxis_range             = kwargs.get(\"xaxis_range_sersic_hist\", None),\n",
    "        yaxis_range             = kwargs.get(\"yaxis_range_sersic_hist\", None),\n",
    "        #reversed_order          = True,\n",
    "        # title       = f\"{runname} galaxies: distribution of magnitudes for by-eye successful models\"\n",
    "        # title_y     = 0.85\n",
    "        show                    = show,\n",
    "        interactive             = interactive,\n",
    "        write                   = write\n",
    "    )\n",
    "    \n",
    "# ============================================================================================================================================================\n",
    "# MAGNITUDE HISTOGRAMS \n",
    "# ============================================================================================================================================================\n",
    "\n",
    "    # x1   = \"magnitude_sersic_1\"\n",
    "    # x2   = \"magnitude_sersic_2\"\n",
    "    # x3   = \"magnitude_sersic_3\"\n",
    "        \n",
    "    x    = \"m\"\n",
    "        \n",
    "    cols_to_use = sorted([x for x in df_container.full_df.columns if x.startswith(\"magnitude_sersic\")])      \n",
    "    rename      = {col_name : f\"sersic_{i}\" for i, col_name in enumerate(cols_to_use)}\n",
    "    \n",
    "    plot_df_all          = df_container.full_df[cols_to_use].copy().rename(columns = rename)\n",
    "    plot_df_success      = df_container.success_df[cols_to_use].copy().rename(columns = rename)\n",
    "    \n",
    "    to_plot  = {\"all models\" : plot_df_all, \"success\" : plot_df_success}\n",
    "    runname  = f\"{basename}_all-vs-success\"\n",
    "    \n",
    "    if incl_by_eye:\n",
    "        plot_df_by_eye            = df_container.by_eye_success_df[cols_to_use].copy().rename(columns = rename)\n",
    "        to_plot[\"by-eye success\"] = plot_df_by_eye\n",
    "        runname                   = f\"{basename}_all-vs-success-vs-by-eye\"\n",
    "    \n",
    "    _ = create_plot(\n",
    "        x                       = x,\n",
    "        runname                 = runname,\n",
    "        plot_type               = \"overlay_histogram\",\n",
    "        df_or_dfs               = to_plot,\n",
    "        output_image_dir        = output_image_dir,\n",
    "        histnorm                = \"probability\",\n",
    "        nbins                   = kwargs.get(\"mag_nbins\"),\n",
    "        hist_offset             = kwargs.get(\"mag_hist_offset\", 3),\n",
    "        xaxis_range             = kwargs.get(\"xaxis_range_mag_hist\", None),\n",
    "        yaxis_range             = kwargs.get(\"yaxis_range_mag_hist\", None),\n",
    "        # title       = f\"{runname} galaxies: distribution of magnitudes for by-eye successful models\"\n",
    "        # title_y     = 0.85\n",
    "        show                    = show,\n",
    "        interactive             = interactive,\n",
    "        write                   = write\n",
    "    )\n",
    "    \n",
    "# ============================================================================================================================================================\n",
    "# PETROMAG DIFFERENCE HISTOGRAM\n",
    "# ============================================================================================================================================================\n",
    "\n",
    "    if \"petromag\" in \" \".join(df_container.full_df.columns):\n",
    "        x    = \"m-petromag\"\n",
    "        fcol = \"domain\"\n",
    "\n",
    "        cols_to_use = sorted([x for x in df_container.full_df.columns if x.startswith(f\"petromag\")])\n",
    "        rename      = {col_name : f\"sersic_{i}\" for i, col_name in enumerate(cols_to_use)}\n",
    "    \n",
    "        plot_df_all          = df_container.full_df[cols_to_use].copy().rename(columns = rename)\n",
    "        plot_df_success      = df_container.success_df[cols_to_use].copy().rename(columns = rename)\n",
    "\n",
    "        to_plot  = {\"all models\" : plot_df_all, \"success\" : plot_df_success}\n",
    "        runname  = f\"{basename}_all-vs-success\"\n",
    "\n",
    "        if incl_by_eye:\n",
    "            plot_df_by_eye            = df_container.by_eye_success_df[cols_to_use].copy().rename(columns = rename)\n",
    "            to_plot[\"by-eye success\"] = plot_df_by_eye\n",
    "            runname                   = f\"{basename}_all-vs-success-vs-by-eye\"\n",
    "\n",
    "        _ = create_plot(\n",
    "            x                       = x,\n",
    "            runname                 = runname,\n",
    "            plot_type               = \"overlay_histogram\",\n",
    "            df_or_dfs               = to_plot,\n",
    "            output_image_dir        = output_image_dir,\n",
    "            histnorm                = \"probability\",\n",
    "            nbins                   = kwargs.get(\"mag_nbins\"),\n",
    "            hist_offset             = kwargs.get(\"mag_hist_offset\", 3),\n",
    "            xaxis_range             = kwargs.get(\"xaxis_range_petromag_hist\", None),\n",
    "            yaxis_range             = kwargs.get(\"yaxis_range_petromag_hist\", None),\n",
    "            # title       = f\"{runname} galaxies: distribution of magnitudes for by-eye successful models\"\n",
    "            # title_y     = 0.85\n",
    "            show                    = show,\n",
    "            interactive             = interactive,\n",
    "            write                   = write\n",
    "        )\n",
    "        \n",
    "# ============================================================================================================================================================\n",
    "# SPIRAL ARM FLUX RATIO HISTOGRAM\n",
    "# ============================================================================================================================================================\n",
    "\n",
    "    x     = \"arm_flux_ratio\"\n",
    "    fcol  = \"domain\"\n",
    "    xmin, xmax = kwargs.get(\"xaxis_range_arm_flux_hist\", (0, 5))\n",
    "\n",
    "    plot_df       = df_container.full_df[df_container.full_df[x] < xmax][x].copy().to_frame()\n",
    "    plot_df[fcol] = \"all models\"\n",
    "\n",
    "    plot_df1       = df_container.success_df[df_container.success_df[x] < xmax][x].copy().to_frame()\n",
    "    plot_df1[fcol] = \"success\"\n",
    "    \n",
    "    to_concat = [plot_df, plot_df1]\n",
    "    runname   = f\"{basename}_all-vs-success\"\n",
    "    \n",
    "    if incl_by_eye:\n",
    "        plot_df2       = df_container.by_eye_success_df[df_container.by_eye_success_df[x] < xmax][x].copy().to_frame()\n",
    "        plot_df2[fcol] = \"by-eye success\"\n",
    "        to_concat.append(plot_df2)\n",
    "        runname   = f\"{basename}_by-eye-vs-success-vs-all\"\n",
    "\n",
    "    plot_df = pd.concat(to_concat, axis = 0)\n",
    "\n",
    "    _ = create_plot(\n",
    "        x                       = x,\n",
    "        runname                 = runname,\n",
    "        plot_type               = \"histogram\",\n",
    "        df_or_dfs               = plot_df,\n",
    "        output_image_dir        = output_image_dir,\n",
    "        histnorm                = \"probability\",\n",
    "        multi                   = False,\n",
    "        facet_col               = fcol,\n",
    "        #nbins                   = 40, #kwargs.get(\"mag_nbins\"),\n",
    "        #hist_offset             = kwargs.get(\"mag_hist_offset\", 3),\n",
    "        #xaxis_range             = kwargs.get(\"xaxis_range_arm_flux_hist\", None),\n",
    "        yaxis_range             = kwargs.get(\"yaxis_range_arm_flux_hist\", None),\n",
    "        # title       = f\"{runname} galaxies: distribution of magnitudes for by-eye successful models\"\n",
    "        # title_y     = 0.85\n",
    "        show                    = show,\n",
    "        interactive             = interactive,\n",
    "        write                   = write\n",
    "    )\n",
    "    \n",
    "# ============================================================================================================================================================\n",
    "# ALEN HISTOGRAM\n",
    "# ============================================================================================================================================================\n",
    "\n",
    "    x    = \"alen_ratio\"\n",
    "    fcol = \"domain\"\n",
    "    \n",
    "    plot_df       = df_container.full_df[x].copy().to_frame()\n",
    "    plot_df[fcol] = \"all models\"\n",
    "\n",
    "    plot_df1       = df_container.success_df[x].copy().to_frame()\n",
    "    plot_df1[fcol] = \"success\"\n",
    "    \n",
    "    to_concat = [plot_df, plot_df1]\n",
    "    runname   = f\"{basename}_all-vs-success\"\n",
    "    \n",
    "    if incl_by_eye:\n",
    "        plot_df2       = df_container.by_eye_success_df[x].copy().to_frame()\n",
    "        plot_df2[fcol] = \"by-eye success\"\n",
    "        to_concat.append(plot_df2)\n",
    "        runname   = f\"{basename}_by-eye-vs-success-vs-all\"\n",
    "\n",
    "    plot_df = pd.concat(to_concat, axis = 0)\n",
    "    \n",
    "    _ = create_plot(\n",
    "        x                       = x,\n",
    "        runname                 = runname,\n",
    "        plot_type               = \"histogram\",\n",
    "        df_or_dfs               = plot_df,\n",
    "        output_image_dir        = output_image_dir,\n",
    "        histnorm                = \"probability\",\n",
    "        multi                   = False,\n",
    "        # color                   = \"component\",\n",
    "        # color_discrete_sequence = colors,\n",
    "        facet_col               = fcol,\n",
    "        xaxis_range             = kwargs.get(\"xaxis_range_alen_hist\"), # [10, 20],\n",
    "        yaxis_range             = kwargs.get(\"yaxis_range_alen_hist\"), # [0, 0.15],\n",
    "        # title       = f\"{runname} galaxies: distribution of magnitudes for by-eye successful models\"\n",
    "        # title_y     = 0.85\n",
    "        show                    = show,\n",
    "        interactive             = interactive,\n",
    "        write                   = write\n",
    "    )\n",
    "    \n",
    "# ============================================================================================================================================================\n",
    "# SCATTER OF PITCH ANGLE DIFFERENCES\n",
    "# ============================================================================================================================================================\n",
    "    \n",
    "    x     = \"observation\"\n",
    "    y     = \"model\"\n",
    "    color = \"difference\"\n",
    "\n",
    "    plot_df        = df_container.full_df.copy()\n",
    "    plot_df[x]     = df_container.full_df.loc[:, \"min_pre\"]\n",
    "    plot_df[y]     = df_container.full_df.loc[:, \"min_post\"]\n",
    "    plot_df[color] = df_container.full_df.loc[:, \"min_arm_pa_diff\"]\n",
    "\n",
    "    _ = create_plot(\n",
    "        x                = x,\n",
    "        y                = y,\n",
    "        runname          = f\"{basename}_pa_diff\",\n",
    "        plot_type        = \"scatter\",\n",
    "        df_or_dfs        = plot_df,\n",
    "        output_image_dir = output_image_dir,\n",
    "        color            = color,\n",
    "        #xaxis_title      = \"\n",
    "        #color_continuous_midpoint = kwargs.get(\"pa_cutoff_val\"),\n",
    "        #range_color      = [0, 90],\n",
    "        width_multiplier = 1,\n",
    "        # title     = \"Pitch angle difference reported by SpArcFiRe, model vs observation\"\n",
    "        # title_y   = 0.85\n",
    "        show             = show,\n",
    "        write            = write\n",
    "    )\n",
    "    \n",
    "# ============================================================================================================================================================\n",
    "# SCATTER OF PITCH ANGLE DIFFERENCES FOR BY EYE SUCCESSFUL\n",
    "# ============================================================================================================================================================\n",
    "    if incl_by_eye:\n",
    "        x     = \"observation\"\n",
    "        y     = \"model\"\n",
    "        color = \"difference\"\n",
    "        \n",
    "        plot_df        = df_container.by_eye_success_df.copy()\n",
    "        plot_df[x]     = df_container.by_eye_success_df.loc[:, \"min_pre\"]\n",
    "        plot_df[y]     = df_container.by_eye_success_df.loc[:, \"min_post\"]\n",
    "        plot_df[color] = df_container.by_eye_success_df.loc[:, \"min_arm_pa_diff\"]\n",
    "\n",
    "        _ = create_plot(\n",
    "            x                = x,\n",
    "            y                = y,\n",
    "            runname          = f\"{basename}_by-eye_pa_diff\",\n",
    "            plot_type        = \"scatter\",\n",
    "            df_or_dfs        = plot_df,\n",
    "            output_image_dir = output_image_dir,\n",
    "            color            = color,\n",
    "            #color_continuous_midpoint = kwargs.get(\"pa_cutoff_val\"),\n",
    "            width_multiplier = 1,\n",
    "            # title     = \"Pitch angle difference reported by SpArcFiRe, model vs observation\"\n",
    "            # title_y   = 0.85\n",
    "            show             = show,\n",
    "            interactive      = interactive,\n",
    "            write            = write\n",
    "        )\n",
    "    \n",
    "# ============================================================================================================================================================\n",
    "# ECDF OF PITCH ANGLE DIFFERENCES\n",
    "# ============================================================================================================================================================\n",
    "\n",
    "    # _ = create_plot(\n",
    "    #     x                = \"min_pa_diff\",\n",
    "    #     runname          = basename,\n",
    "    #     plot_type        = \"ecdf\",\n",
    "    #     df_or_dfs        = df_container.full_df,\n",
    "    #     output_image_dir = output_image_dir,\n",
    "    #     xaxis_title      = \"Pitch Angle Difference (deg)\",\n",
    "    #     cutoff_val       = kwargs.get(\"pa_cutoff_val\", 10),\n",
    "    #     marginal         = \"histogram\",\n",
    "    #     # title       = f\"ECDF of pitch angle difference reported by SpArcFiRe, model vs observation\"\n",
    "    #     # title_y     = 0.85\n",
    "    #     show             = show,\n",
    "    #     interactive      = interactive,\n",
    "    #     write            = write\n",
    "    # )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9968be-1763-40f0-b267-cfbe467d4d31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_quantiles(\n",
    "    out_dir, \n",
    "    df, \n",
    "    method,\n",
    "    **kwargs\n",
    "):\n",
    "    print_latex = kwargs.get(\"print_latex\", True)\n",
    "    copy_png    = kwargs.get(\"copy_png\", False)\n",
    "    \n",
    "    # Just in case\n",
    "    df.sort_values(by = method, inplace = True)\n",
    "\n",
    "    # Expect that if there exists more than one runname,\n",
    "    # then we're working with combined data\n",
    "    runnames = list(set(df.runname))\n",
    "    if len(runnames) > 1:\n",
    "        prefixes = list(set([i.split(\"_\")[0] for i in runnames]))\n",
    "        if len(prefixes) == 1:\n",
    "            runname = f\"{prefixes[0]}_combined\"\n",
    "        else:\n",
    "            runname = \"combined\"\n",
    "    else:\n",
    "        runname = runnames[0]\n",
    "        \n",
    "    success_dir = pj(out_dir, runname, f'{runname}_galfit_png')\n",
    "    print_latex_file = pj(out_dir, runname, f\"{runname}_for_latex.txt\")\n",
    "    \n",
    "    if kwargs.get(\"incl_by_eye\", None):\n",
    "        success_dir = pj(out_dir, runname, f'{runname}_by_eye_galfit_png')\n",
    "        print_latex_file = pj(out_dir, runname, f\"{runname}_by_eye_for_latex.txt\")\n",
    "    \n",
    "    if not exists(success_dir):\n",
    "        os.makedirs(success_dir)\n",
    "    \n",
    "    quantile           = [\"0\", \"20\", \"40\", \"60\", \"80\"]\n",
    "    quantiled_galaxies = []\n",
    "    \n",
    "    print_latex_all = []\n",
    "    if print_latex:\n",
    "        \n",
    "        if exists(print_latex_file):\n",
    "            print(\"Deleting old latex output file...\")\n",
    "            os.remove(print_latex_file)\n",
    "            \n",
    "        print(f\"Writing latex to file {print_latex_file}\")\n",
    "    \n",
    "    for q in quantile:\n",
    "        #vprint(print_latex, f\"{q} &\")\n",
    "        print_latex_all.append(f\"{q} &\")\n",
    "        \n",
    "        if copy_png:\n",
    "            quantile_dir = pj(success_dir, f\"{runname}_all_quantile\", f\"quantile_{q}\")\n",
    "            if exists(quantile_dir):\n",
    "                shutil.rmtree(quantile_dir)\n",
    "            os.makedirs(quantile_dir)\n",
    "\n",
    "        interp_df = df[method][df[method] >= df[method].quantile(0.01*float(q), interpolation='lower')]\n",
    "        for count, (index, value) in enumerate(interp_df.items()):\n",
    "            #if count < 5:\n",
    "            #    continue\n",
    "            if count == 8:\n",
    "                break\n",
    "\n",
    "            gname = index\n",
    "            #print(q, i)\n",
    "            #vprint(print_latex, f\"{initial_str}{gname + '_combined.png'}{end_str}\")\n",
    "            #latex_rname = runname\n",
    "            copy_rname  = df.loc[index, \"runname\"]\n",
    "            \n",
    "            # Use runname here for combined runs\n",
    "            temp_str    = f\"images/{runname}/{runname}_all_quantile/quantile_\"\n",
    "            initial_str = f\"    \\includegraphics[height=0.18\\\\textheight]{{{temp_str}{q}/\"\n",
    "            \n",
    "            end_str = \"} &\"\n",
    "            if count == 7 or count == len(interp_df) - 1:\n",
    "                end_str = \"} \\\\\\\\\"\n",
    "                \n",
    "            print_latex_all.append(f\"{initial_str}{gname + '_combined.png'}{end_str}\")\n",
    "\n",
    "            if copy_png:\n",
    "                png_dir = pj(out_dir, copy_rname, f'{copy_rname}_galfit_png')\n",
    "                shutil.copy(pj(png_dir, f\"{gname}_combined.png\"), quantile_dir)\n",
    "\n",
    "            quantiled_galaxies.append(gname)\n",
    "                \n",
    "            #sp(f\"cp {pj(out_dir, 'by_eye_success', gname + '_combined.png')} {pj(success_dir, 'all_quantile', 'quantile_' + q)}\")\n",
    "            \n",
    "    if print_latex:           \n",
    "        with open(print_latex_file, \"w\") as plf:\n",
    "            plf.write(\"\\n\".join(print_latex_all))\n",
    "            plf.write(\"\\n\")\n",
    "            \n",
    "    if copy_png:\n",
    "        # Tar it all up!\n",
    "        sp(f\"tar -czvf {pj(out_dir, runname, runname)}_all_quantile.tar.gz -C {success_dir} {runname}_all_quantile\")\n",
    "        \n",
    "    return quantiled_galaxies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1214924-ee80-484d-854c-ec76922f1871",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fprint(input_str, fill_char = \"*\", fill_len = 100):\n",
    "    input_str = f\" {input_str} \"\n",
    "    print()\n",
    "    print(f\"{input_str:{fill_char}^{fill_len}}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649d4f1a-e413-4a34-92b5-e8dd762acbbb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_petromags(\n",
    "    gzoo_file,\n",
    "    color_band\n",
    "):\n",
    "    \n",
    "    if not exists(gzoo_file):\n",
    "        return full_df\n",
    "    \n",
    "    petromag_col = f\"petroMag_{color_band}\"\n",
    "    gname_col = \"GZ_dr8objid\"\n",
    "    \n",
    "    gzoo_data = pd.read_csv(\n",
    "        gzoo_file, \n",
    "        sep = \"\\t\", \n",
    "        index_col = gname_col,\n",
    "        usecols  = [gname_col, petromag_col],\n",
    "        dtype = {\n",
    "            gname_col    : str,\n",
    "            petromag_col : np.float32\n",
    "        }\n",
    "    ).fillna(\"None\")\n",
    "    \n",
    "    gzoo_data = gzoo_data[~gzoo_data.index.duplicated(keep='first')]\n",
    "    \n",
    "    return gzoo_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b8ff1f-4954-4488-9979-c5d889d40ae8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def main(\n",
    "    run_path, \n",
    "    *basenames, \n",
    "    **kwargs\n",
    "):\n",
    "    # Set some path variables and things\n",
    "    run_path = run_path\n",
    "    \n",
    "    if in_notebook():\n",
    "        run_path = run_path.replace(\"ics-home\", \"portmanm\")\n",
    "\n",
    "    in_dir  = kwargs.get(\"in_dir\", pj(run_path, \"sparcfire-in\"))\n",
    "    out_dir = kwargs.get(\"tmp_dir\", pj(run_path, \"sparcfire-out\"))\n",
    "    tmp_dir = kwargs.get(\"out_dir\", pj(run_path, \"sparcfire-tmp\"))\n",
    "\n",
    "    output_image_dir = kwargs.get(\"output_image_dir\", pj(run_path, \"for_paper_images\"))\n",
    "    if not exists(output_image_dir):\n",
    "        os.makedirs(output_image_dir)\n",
    "        \n",
    "    method          = kwargs.get(\"method\", \"nmr_x_1-p\")\n",
    "    nmr             = \"norm_masked_residual\"\n",
    "    color_band      = kwargs.get(\"color_band\", \"r\")\n",
    "    \n",
    "    global total_galaxies\n",
    "    total_galaxies = get_total_galaxies(in_dir = in_dir, out_dir = out_dir)\n",
    "    \n",
    "    petromag_df = pd.DataFrame()\n",
    "    # For speed\n",
    "    if not kwargs.get(\"do_not_load_petromags\"):\n",
    "        print(\"Loading petromag info...\")\n",
    "        gzoo_file   = pj(\"/home\", \"portmanm\", \"kelly_stuff\", \"Kelly-29k.tsv\")\n",
    "        gzoo_file   = kwargs.get(\"gzoo_file\", gzoo_file)\n",
    "\n",
    "        petromag_df = load_petromags(gzoo_file, color_band)\n",
    "    \n",
    "    # FUNCTIONS OPTIONS\n",
    "    incl_by_eye   = kwargs.get(\"incl_by_eye\", False)\n",
    "    by_eye_subset = kwargs.get(\"by_eye_subset\", False)\n",
    "    write         = kwargs.get(\"write\", False)\n",
    "    show          = kwargs.get(\"show\", False)\n",
    "    interactive   = kwargs.get(\"interactive\", False)\n",
    "    print_latex   = kwargs.get(\"print_latex\", True)\n",
    "    copy_png      = kwargs.get(\"copy_png\", True)\n",
    "    \n",
    "    # Getting ready\n",
    "    all_results  = {}\n",
    "    plot_options = kwargs.get(\"plot_options\", {bname : {} for bname in basenames})\n",
    "    \n",
    "    # LOOPING THROUGH NAMES GIVEN FOR ANALYSIS\n",
    "    for basename in basenames:\n",
    "        # RESIDUAL ANALYSIS\n",
    "        fprint(f\"PERFORMING RESIDUAL ANALYSIS FOR {basename}\")\n",
    "        analysis_results  = residual_analysis(\n",
    "            in_dir              = in_dir, \n",
    "            out_dir             = out_dir, \n",
    "            basename            = basename,\n",
    "            method              = method,\n",
    "            incl_by_eye         = incl_by_eye,\n",
    "            by_eye_subset       = by_eye_subset,\n",
    "            color_band          = color_band,\n",
    "            petromag_df         = petromag_df,\n",
    "            pa_cutoff_val       = kwargs.get(\"pa_cutoff_val\", 10),\n",
    "            residual_cutoff_val = kwargs.get(\"residual_cutoff_val\", 0.5),\n",
    "            alen_cutoff_val     = kwargs.get(\"alen_cutoff_val\", 0.007)\n",
    "        )\n",
    "        \n",
    "        # Collating\n",
    "        all_results[basename] = analysis_results\n",
    "        \n",
    "        if write or show:\n",
    "            # OUTPUTTING PLOTS\n",
    "            fprint(\"CREATING PLOTS\")\n",
    "            _ = create_all_plots(\n",
    "                analysis_results, \n",
    "                method, \n",
    "                basename, \n",
    "                output_image_dir, \n",
    "                incl_by_eye = incl_by_eye,\n",
    "                write       = write,\n",
    "                show        = show,\n",
    "                interactive = interactive,\n",
    "                pa_cutoff_val       = kwargs.get(\"pa_cutoff_val\", 10),\n",
    "                residual_cutoff_val = kwargs.get(\"residual_cutoff_val\", 0.5),\n",
    "                #alen_cutoff_val     = kwargs.get(\"alen_cutoff_val\", 0.007)\n",
    "                **plot_options[basename]\n",
    "                #xaxis_range_mag_hist = [10, 20],\n",
    "                #yaxis_range_mag_hist = [0, 0.15]\n",
    "            )\n",
    "\n",
    "        if print_latex or copy_png:\n",
    "            fprint(\"QUANTILING IMAGES FROM RESULTS\")\n",
    "            \n",
    "            if incl_by_eye:\n",
    "                print(\"... by eye\")\n",
    "                quantile_df = analysis_results.by_eye_success_df\n",
    "                galaxy_set_q = create_quantiles(\n",
    "                    out_dir, \n",
    "                    #basename, \n",
    "                    quantile_df,\n",
    "                    method,\n",
    "                    **kwargs\n",
    "                    # print_latex = print_latex, \n",
    "                    # copy_png = copy_png\n",
    "                )\n",
    "            else:\n",
    "                quantile_df = analysis_results.success_df\n",
    "\n",
    "            fprint(\"QUANTILING IMAGES FROM RESULTS\")\n",
    "            galaxy_set_q = create_quantiles(\n",
    "                out_dir, \n",
    "                #basename, \n",
    "                quantile_df,\n",
    "                method,\n",
    "                **kwargs\n",
    "                # print_latex = print_latex, \n",
    "                # copy_png = copy_png\n",
    "            )\n",
    "        \n",
    "        # Unfortunately have to do this after and have the user generate the pngs from here\n",
    "        # in order to rerun create_quantiles\n",
    "        if kwargs.get(\"prep_for_quantile\", False):\n",
    "            fprint(\"JUST KIDDING, EXTRACTING QUANTILED MODELS TO BE CONVERTED TO PNG\")\n",
    "            \n",
    "            to_untar = ' '.join([f\"./{gname}_galfit_out.fits\" for gname in galaxy_set_q])\n",
    "            tar_file = f\"{pj(out_dir, basename, basename)}_galfits.tar.gz\"\n",
    "            sp(f\"tar -xzvf {tar_file} --occurrence {to_untar}\")\n",
    "\n",
    "            _ = [shutil.move(f\"{gname}_galfit_out.fits\", f\"{pj(out_dir, basename, basename)}_galfits\")\n",
    "                 for gname in galaxy_set_q\n",
    "                ]\n",
    "            \n",
    "            print(f\"Please generate the pngs corresponding with the fits in the {pj(out_dir, basename, basename)}_galfits directory.\")\n",
    "            print(\"You may then proceed to run the 'create_quantiles' function again with copy_png set to True.\")\n",
    "    \n",
    "    if len(basenames) > 1:\n",
    "        fprint(\"COMBINING RESULTS FROM ALL RUNS FED IN\")\n",
    "        combined = combine_multi_run_results(\n",
    "            method,\n",
    "            *all_results.values(),\n",
    "            df_names      = basenames,\n",
    "            incl_by_eye   = incl_by_eye,\n",
    "            by_eye_subset = by_eye_subset\n",
    "        )\n",
    "        \n",
    "        prefixes = list(set([i.split(\"_\")[0] for i in basenames]))\n",
    "        if len(prefixes) == 1:\n",
    "            new_basename = f\"{prefixes[0]}_combined\"\n",
    "        else:\n",
    "            new_basename = \"combined\"\n",
    "        \n",
    "        all_results[new_basename] = combined\n",
    "        \n",
    "        if write or show:\n",
    "            try:\n",
    "                # OUTPUTTING PLOTS\n",
    "                fprint(\"CREATING PLOTS\")\n",
    "                _ = create_all_plots(\n",
    "                    combined, \n",
    "                    method, \n",
    "                    new_basename, \n",
    "                    output_image_dir, \n",
    "                    incl_by_eye = incl_by_eye,\n",
    "                    write       = write,\n",
    "                    show        = show,\n",
    "                    interactive = interactive,\n",
    "                    pa_cutoff_val       = kwargs.get(\"pa_cutoff_val\", 10),\n",
    "                    residual_cutoff_val = kwargs.get(\"residual_cutoff_val\", 0.007),\n",
    "                    **plot_options[new_basename]\n",
    "                    #xaxis_range_mag_hist = [10, 20],\n",
    "                    #yaxis_range_mag_hist = [0, 0.15]\n",
    "                )\n",
    "            except KeyError as ke:\n",
    "                print(f\"Were plot options specified with the correct combined basename, {new_basename}?\")\n",
    "                print(\"Proceeding without plot options.\")\n",
    "                _ = create_all_plots(\n",
    "                    combined, \n",
    "                    method, \n",
    "                    new_basename, \n",
    "                    output_image_dir, \n",
    "                    incl_by_eye = incl_by_eye,\n",
    "                    write       = write,\n",
    "                    show        = show,\n",
    "                    interactive = interactive,\n",
    "                    pa_cutoff_val       = kwargs.get(\"pa_cutoff_val\", 10),\n",
    "                    residual_cutoff_val = kwargs.get(\"residual_cutoff_val\", 0.007),\n",
    "                    #**plot_options[new_basename]\n",
    "                    #xaxis_range_mag_hist = [10, 20],\n",
    "                    #yaxis_range_mag_hist = [0, 0.15]\n",
    "                )\n",
    "\n",
    "        if print_latex or copy_png:\n",
    "            fprint(\"QUANTILING IMAGES FROM RESULTS\")\n",
    "            if incl_by_eye:\n",
    "                print(\"... by eye\")\n",
    "                # Do it twice to have a by eye sample and a regular sample\n",
    "                quantile_df = combined.by_eye_success_df\n",
    "                galaxy_set_q = create_quantiles(\n",
    "                    out_dir, \n",
    "                    #basename, \n",
    "                    quantile_df,\n",
    "                    method,\n",
    "                    **kwargs\n",
    "                    # print_latex = print_latex, \n",
    "                    # copy_png = copy_png\n",
    "                )\n",
    "                \n",
    "            else:\n",
    "                quantile_df = combined.success_df\n",
    "\n",
    "            \n",
    "            galaxy_set_q = create_quantiles(\n",
    "                out_dir, \n",
    "                #basename, \n",
    "                quantile_df,\n",
    "                method,\n",
    "                **kwargs\n",
    "                # print_latex = print_latex, \n",
    "                # copy_png = copy_png\n",
    "            )\n",
    "        \n",
    "        # Unfortunately have to do this after and have the user generate the pngs from here\n",
    "        # in order to rerun create_quantiles\n",
    "        if kwargs.get(\"prep_for_quantile\", False):\n",
    "            fprint(\"JUST KIDDING, EXTRACTING QUANTILED MODELS TO BE CONVERTED TO PNG\")\n",
    "            \n",
    "            to_untar = ' '.join([f\"./{gname}_galfit_out.fits\" for gname in galaxy_set_q])\n",
    "            tar_file = f\"{pj(out_dir, new_basename, new_basename)}_galfits.tar.gz\"\n",
    "            sp(f\"tar -xzvf {tar_file} --occurrence {to_untar}\")\n",
    "\n",
    "            _ = [shutil.move(f\"{gname}_galfit_out.fits\", f\"{pj(out_dir, new_basename, new_basename)}_galfits\")\n",
    "                 for gname in galaxy_set_q\n",
    "                ]\n",
    "            \n",
    "            print(f\"Please generate the pngs corresponding with the fits in the {pj(out_dir, basename, basename)}_galfits directory.\")\n",
    "            print(\"You may then proceed to run the 'create_quantiles' function again with copy_png set to True.\")\n",
    "        \n",
    "    fprint(\"DONE!!!\")\n",
    "    \n",
    "    # combined_bool_df only if applicable\n",
    "    # {basename : namedtuple (fields below), \"combined_bool_df\" : combined_bool_df}\n",
    "    # full_df, success_df, not_success_df, by_eye_success_df, by_eye_not_success_df\n",
    "    return all_results\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca63ade-456e-41a4-baa5-4e2ae42875ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    #pd.options.mode.chained_assignment = 'raise'\n",
    "    galaxy_set_14_results = main(\n",
    "        \"testing_python_control\", \n",
    "        \"14_NC2\", \n",
    "        #\"14_NC3\",\n",
    "        pa_cutoff_val       = 10,\n",
    "        alen_cutoff_val     = 0.5,\n",
    "        residual_cutoff_val = 0.007,\n",
    "        color_band  = \"r\",\n",
    "        incl_by_eye = True,\n",
    "        show        = True,\n",
    "        write       = False,\n",
    "        copy_png    = False,\n",
    "        print_latex = False,\n",
    "        interactive = False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478469d0-ed46-4dcf-8699-3cc407cf8020",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    plot_options = {\n",
    "        \"1000_NC2\" : {\n",
    "            \"xaxis_range_sersic_hist\" : [0, 8],\n",
    "            \"yaxis_range_sersic_hist\" : [0, 0.18],\n",
    "            \"xaxis_range_mag_hist\"    : [13, 23], #[10, 20], \n",
    "            \"yaxis_range_mag_hist\"    : [0, 0.18],\n",
    "            \"xaxis_range_petromag_hist\"    : [-5, 9], \n",
    "            \"yaxis_range_petromag_hist\"    : [0, 0.34],\n",
    "            \"mag_nbins\"                    : 40,\n",
    "        },\n",
    "        \"1000_NC3\" : {\n",
    "            \"xaxis_range_sersic_hist\" : [0, 8],\n",
    "            \"yaxis_range_sersic_hist\" : [0, 0.26],\n",
    "            \"xaxis_range_mag_hist\"    : [13, 25], #[10, 22], \n",
    "            \"yaxis_range_mag_hist\"    : [0, 0.22],\n",
    "            \"xaxis_range_petromag_hist\"    : [-5, 9], #[-8, 6], \n",
    "            \"yaxis_range_petromag_hist\"    : [0, 0.34],\n",
    "            \"mag_nbins\"                    : 40,\n",
    "        },\n",
    "        \"1000_combined\" : {\n",
    "            \"xaxis_range_sersic_hist\" : [0, 8],\n",
    "            \"yaxis_range_sersic_hist\" : [0, 0.26],\n",
    "            \"xaxis_range_mag_hist\"    : [13, 25], #[10, 22], \n",
    "            \"yaxis_range_mag_hist\"    : [0, 0.24],\n",
    "            \"xaxis_range_petromag_hist\"    : [-5, 9], \n",
    "            \"yaxis_range_petromag_hist\"    : [0, 0.31],\n",
    "            \"mag_nbins\"                    : 40,\n",
    "        },\n",
    "    }\n",
    "    \n",
    "    galaxy_set_no_elps_1000_results = main(\n",
    "        \"run13_for_paper\", \n",
    "        \"1000_NC2\", \n",
    "        #\"1000_NC3\",\n",
    "        pa_cutoff_val       = 7,\n",
    "        alen_cutoff_val     = 0.62,\n",
    "        residual_cutoff_val = 0.007,\n",
    "        incl_by_eye = True,\n",
    "        write       = False,\n",
    "        show        = True,\n",
    "        copy_png    = False,\n",
    "        print_latex = False,\n",
    "        interactive = False,\n",
    "        plot_options = plot_options\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63464946-41bd-4573-ac6a-279c63a14e30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    plot_options = {\n",
    "        \"29k_NC2\" : {\n",
    "            \"xaxis_range_sersic_hist\" : [0, 8],\n",
    "            \"yaxis_range_sersic_hist\" : [0, 0.22],\n",
    "            \"xaxis_range_mag_hist\" : [12, 23], \n",
    "            \"yaxis_range_mag_hist\" : [0, 0.13],\n",
    "            \"xaxis_range_petromag_hist\"    : [-3, 5], \n",
    "            \"yaxis_range_petromag_hist\"    : [0, 0.23],\n",
    "            \"mag_nbins\"                    : 40,\n",
    "        },\n",
    "        \"29k_NC3\" : {\n",
    "            \"xaxis_range_sersic_hist\" : [0, 8],\n",
    "            \"yaxis_range_sersic_hist\" : [0, 0.35],\n",
    "            \"xaxis_range_mag_hist\"    : [12, 23], \n",
    "            \"yaxis_range_mag_hist\"    : [0, 0.15],\n",
    "            \"xaxis_range_petromag_hist\"    : [-3, 5], \n",
    "            \"yaxis_range_petromag_hist\"    : [0, 0.18],\n",
    "            \"mag_nbins\"                    : 40,\n",
    "        },\n",
    "        \"29k_combined\" : {\n",
    "            \"xaxis_range_sersic_hist\" : [0, 8],\n",
    "            \"yaxis_range_sersic_hist\" : [0, 0.31],\n",
    "            \"xaxis_range_mag_hist\"    : [12, 23], \n",
    "            \"yaxis_range_mag_hist\"    : [0, 0.15],\n",
    "            \"xaxis_range_petromag_hist\"    : [-3, 5], \n",
    "            \"yaxis_range_petromag_hist\"    : [0, 0.19],\n",
    "            \"mag_nbins\"                    : 40,\n",
    "        },\n",
    "    }\n",
    "    \n",
    "    galaxy_set_29k_results = main(\n",
    "        \"29k_galaxies\", \n",
    "        \"29k_NC2\", \n",
    "        \"29k_NC3\",\n",
    "        plot_options  = plot_options,\n",
    "        pa_cutoff_val       = 9,\n",
    "        alen_cutoff_val     = 0.45, #0.52,\n",
    "        residual_cutoff_val = 0.009,\n",
    "        write         = True,\n",
    "        show          = False,\n",
    "        incl_by_eye   = True,\n",
    "        by_eye_subset = 1000,\n",
    "        copy_png      = False,\n",
    "        print_latex   = False,\n",
    "        interactive   = False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98498552-b0d1-4461-b28a-6412e2cc2213",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_images_old(input_df, png_dir:str, variable_name:str, custom_range = None):\n",
    "    images_out = []\n",
    "    \n",
    "    if not custom_range:\n",
    "        custom_range = range(0, len(input_df), 50) \n",
    "        \n",
    "    count = 0\n",
    "    for index_num in custom_range:\n",
    "        g_variable = input_df.iloc[index_num]\n",
    "        gname = g_variable.name\n",
    "        variable_value = g_variable[variable_name]#.norm_masked_residual\n",
    "\n",
    "        height = 500\n",
    "        width = 500\n",
    "        size = (height, width)\n",
    "        #out_str = galaxy_info.name.replace(\"galfit_out.fits\", \"combined.png\").strip()\n",
    "        out_str = f\"{gname}_combined.png\"\n",
    "        #print(out_str)\n",
    "        \n",
    "        \n",
    "        images_out.append(Image(filename = pj(png_dir, out_str), width=width, height=height))\n",
    "            \n",
    "        print(f\"{gname}, sorted #: {index_num}\")\n",
    "        print(f\"{variable_name} = {variable_value:.6f}\")\n",
    "        #print(f\"Dim: {galaxy_info['image_size']}x{galaxy_info['image_size']}\")\n",
    "        print()\n",
    "        \n",
    "    return images_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb0dadf-10a4-4c06-bfac-5c5ca8168990",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_to_disp = generate_images_old(full_df, pj(out_dir, \"galfit_png\"), \"diff\") #, range(0,len(full_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c716159c-c1f4-4aa2-89e5-8a99a118d224",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(*images_to_disp)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "70746b6a-4331-43af-9972-17511a378117",
   "metadata": {
    "tags": []
   },
   "source": [
    "for png in glob.glob(pj(out_dir, \"scatter_plots\", \"*.png\")):\n",
    "    gname = os.path.basename(png).rstrip(\".png\")\n",
    "    if gname not in success_df.index and gname in constrained_df.index:\n",
    "        print(constrained_df.loc[gname, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd73b55-2bc5-46a9-9d47-16f472f03d31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_images(input_df, png_dir:str, cutoff_val = 0.01, variable_name = \"norm_masked_residual\", custom_range = None):\n",
    "    images_below_cutoff = []\n",
    "    images_above_cutoff = []\n",
    "    \n",
    "    if not custom_range:\n",
    "        custom_range = range(0, len(input_df), 50) \n",
    "    count = 0\n",
    "    for index_num in custom_range:\n",
    "        g_variable = input_df.iloc[index_num]\n",
    "        gname = g_variable.name\n",
    "        variable_value = g_variable[variable_name]#.norm_masked_residual\n",
    "\n",
    "        # iloc returns a series, name returns the name of the row\n",
    "\n",
    "        \n",
    "        # print(f\"chi^2/nu = {galaxy_info['chi^2_nu']:.2f}\")\n",
    "        # print(f\"chi^2 = {galaxy_info['chi^2']:.2f}\")\n",
    "        #print(f\"Norm GALFIT residual = {norm_galfit_residual:.4f}\")\n",
    "\n",
    "\n",
    "        # galfit_cmap = grayscale_cmap('RdBu')\n",
    "        # residual_plot = plt.imshow(np.flipud(masked_residual[:,:])) #, norm=colors.LogNorm())\n",
    "        # residual_plot.set_cmap('Greys')\n",
    "        # residual_plot.set_cmap(galfit_cmap)\n",
    "        # cbar = plt.colorbar()\n",
    "\n",
    "        #plt.imshow(residual_plot)\n",
    "        #imgplot = plt.imshow(arr[:, :, 0])\n",
    "        height = 500\n",
    "        width = 500\n",
    "        size = (height, width)\n",
    "        #out_str = galaxy_info.name.replace(\"galfit_out.fits\", \"combined.png\").strip()\n",
    "        out_str = f\"{gname}_combined.png\"\n",
    "        #print(out_str)\n",
    "        \n",
    "        if variable_value < cutoff_val:\n",
    "            images_below_cutoff.append(Image(filename = pj(png_dir, out_str), width=width, height=height))\n",
    "            #images_below_cutoff.append(PIL.Image.open(pj(png_dir, out_str)).resize(size))\n",
    "        else:\n",
    "            count += 1\n",
    "            if count == 1:\n",
    "                print(\"=\"*80)\n",
    "            images_above_cutoff.append(Image(filename = pj(png_dir, out_str), width=width, height=height))\n",
    "            #images_above_cutoff.append(PIL.Image.open(pj(png_dir, out_str)).resize(size))\n",
    "\n",
    "            \n",
    "        print(f\"{gname}, sorted #: {index_num}\")\n",
    "        print(f\"{variable_name} = {variable_value:.6f}\")\n",
    "        #print(f\"Dim: {galaxy_info['image_size']}x{galaxy_info['image_size']}\")\n",
    "        print()\n",
    "        \n",
    "    return images_below_cutoff, images_above_cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa61e80e-f4c1-4c8c-b07f-f9ed0a1b56e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "png_dir = os.path.join(run_path, out_dir, \"galfit_png\")\n",
    "#below, above = generate_images(residual_df, png_dir, cutoff_val = 0.013342, variable_name = analysis_var, custom_range = range(700, len(residual_df), 10) )\n",
    "below, above = generate_images(residual_df, png_dir, cutoff_val = cutoff_val, variable_name = analysis_var, custom_range = range(800, len(residual_df), 10) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d88e511-d149-424d-8a7e-6e8f4fe51dc1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display(*below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630341ca-75b3-4dc6-91b6-b9929e4f01a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(*above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9901973e-ac6f-4700-aa25-c14eab1075a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# good_fit = \"1237671262278582530\"\n",
    "# bad_fit = \"1237668366388756890\"\n",
    "\n",
    "# good_fit_obj = OutputFits(pj(out_dir, good_fit, f\"{good_fit}_galfit_out.fits\"))\n",
    "# bad_fit_obj = OutputFits(pj(out_dir, bad_fit, f\"{bad_fit}_galfit_out.fits\"))\n",
    "# good_residual = good_fit_obj.residual.data\n",
    "\n",
    "# scipy.stats.probplot(good_residual.flatten(), plot = plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ee8420-f01d-407b-a78f-7420e0244a93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# bad_residual = bad_fit_obj.residual.data\n",
    "# scipy.stats.probplot(bad_residual.flatten(), plot = plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e075be-9f7e-4901-9c7c-a364497be181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thanks to https://jakevdp.github.io/PythonDataScienceHandbook/04.07-customizing-colorbars.html\n",
    "def grayscale_cmap(cmap):\n",
    "    \"\"\"Return a grayscale version of the given colormap\"\"\"\n",
    "    cmap = plt.cm.get_cmap(cmap)\n",
    "    colors = cmap(np.arange(cmap.N))\n",
    "    \n",
    "    # convert RGBA to perceived grayscale luminance\n",
    "    # cf. http://alienryderflex.com/hsp.html\n",
    "    RGB_weight = [0.299, 0.587, 0.114]\n",
    "    luminance = np.sqrt(np.dot(colors[:, :3] ** 2, RGB_weight))\n",
    "    colors[:, :3] = luminance[:, np.newaxis]\n",
    "        \n",
    "    return LinearSegmentedColormap.from_list(cmap.name + \"_gray\", colors, cmap.N)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
