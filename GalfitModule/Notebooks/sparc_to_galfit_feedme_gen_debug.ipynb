{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Author: Matthew Portman**\n",
    "\n",
    "**Date (Commit date will likely be more accurate): 4/17/23**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# MINI README\n",
    "\n",
    "Please place this script into the directory which contains the folders for your input, temporary, and output files for SpArcFiRe typically denoted: sparcfire-in, sparcfire-tmp, and sparcfire-out. GALFIT will also be run from that same directory if you choose to use the control script included in the repo. I recommend running this alone *once* before running the big script to ensure everything is in its right place (https://www.youtube.com/watch?v=sKZN115n6MI). After you confirm that this works without any errors the first time around, feel free to run the control script from then on. \n",
    "\n",
    "Running from the overarching directory is a temporary measure which will be remedied upon completion of the entire control script and full integration with SpArcFiRe. \n",
    "\n",
    "TO RUN: `python3 sparc_to_galfit_feedme_gen.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import log\n",
    "import glob\n",
    "import csv\n",
    "import subprocess\n",
    "import random\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "\n",
    "from astropy.io import fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# For debugging purposes\n",
    "from IPython import get_ipython\n",
    "def in_notebook():\n",
    "    ip = get_ipython()\n",
    "    \n",
    "    if ip:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from os.path import join as pj\n",
    "from os.path import exists\n",
    "\n",
    "_HOME_DIR = os.path.expanduser(\"~\")\n",
    "if in_notebook():\n",
    "    _SPARCFIRE_DIR = pj(_HOME_DIR, \"sparcfire_matt\") \n",
    "    _MODULE_DIR    = pj(_SPARCFIRE_DIR, \"GalfitModule\")\n",
    "else:\n",
    "    try:\n",
    "        _SPARCFIRE_DIR = os.environ[\"SPARCFIRE_HOME\"]\n",
    "        _MODULE_DIR = pj(_SPARCFIRE_DIR, \"GalfitModule\")\n",
    "    except KeyError:\n",
    "        if __name__ == \"__main__\":\n",
    "            print(\"SPARCFIRE_HOME is not set. Please run 'setup.bash' inside SpArcFiRe directory if not done so already.\")\n",
    "            print(\"Checking the current directory for GalfitModule, otherwise quitting.\")\n",
    "            \n",
    "        _MODULE_DIR = pj(os.getcwd(), \"GalfitModule\")\n",
    "        \n",
    "        if not exists(_MODULE_DIR):\n",
    "            raise Exception(\"Could not find GalfitModule!\")\n",
    "    \n",
    "sys.path.append(_MODULE_DIR)\n",
    "from Classes.Components import *\n",
    "from Classes.Containers import FeedmeContainer\n",
    "from Functions.helper_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To convert autocrop image to fits\n",
    "import subprocess\n",
    "\n",
    "try: \n",
    "    autocrop_img_filename = glob.glob('*_autoCrop.png')[0]\n",
    "    #convert_command = [\"convert \", autocrop_img_filename,\"input.fits\"]\n",
    "    convert_command = \"convert \" + autocrop_img_filename + \" input.fits\"\n",
    "\n",
    "except:\n",
    "    print(\"Cannot find \", autocrop_img_filename, \" to convert to fits.\")\n",
    "    print(\"Check Sparcfire output or directories. Cannot proceed. Quitting.\")\n",
    "    raise SystemExit(\"Quitting.\")\n",
    "    \n",
    "else:\n",
    "    try: \n",
    "        subprocess.run(convert_command, shell=True)\n",
    "    \n",
    "    except:\n",
    "        print(\"Cannot convert to FITS:\", autocrop_img_filename)\n",
    "        print(\"Check Sparcfire output or directories. Cannot proceed.\")\n",
    "        raise SystemExit(\"Quitting.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grabbing filepath from command line\n",
    "def command_line(top_dir = os.getcwd(), **kwargs): # = True):\n",
    "    \n",
    "    in_dir_out  = kwargs.get(\"in_dir\", pj(top_dir, \"sparcfire-in\"))\n",
    "    tmp_dir_out = kwargs.get(\"tmp_dir\", pj(top_dir, \"sparcfire-tmp\"))\n",
    "    out_dir_out = kwargs.get(\"out_dir\", pj(top_dir, \"sparcfire-out\"))\n",
    "        \n",
    "    #if not run_as_script:\n",
    "    #    return in_dir_out, tmp_dir_out, out_dir_out\n",
    "    \n",
    "    try:\n",
    "        if len(sys.argv) != 4: # including name of python script\n",
    "            print(f\"Using: \\n{in_dir_out}\\n{tmp_dir_out}\\n{out_dir_out}\\nto generate feedme.\")\n",
    "\n",
    "        else:\n",
    "            in_dir_out = argv[1]\n",
    "            tmp_dir_out = argv[2]\n",
    "            out_dir_out = argv[3]\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    return absp(in_dir_out), absp(tmp_dir_out), absp(out_dir_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_galaxy_names_list(in_dir, tmp_dir, out_dir, galaxy_names = []):\n",
    "\n",
    "    gnames_out = galaxy_names\n",
    "#     try:\n",
    "#         #filenames_read = find_files(in_dir, \"*.fits\", \"f\")\n",
    "    \n",
    "#     #except:\n",
    "#         # Feel free to hardcode this \n",
    "#         #print(\"Please input the full path to the input directory for the SpArcFiRe run and include the trailing /\")\n",
    "#         #print(\"e.g. /home/usr/sparcfire-in/\")\n",
    "#         #in_dir = input()\n",
    "    \n",
    "#         #try:\n",
    "#             #filenames_in = glob.glob(in_dir + \"*.fits\")\n",
    "\n",
    "#         #except:\n",
    "#             #print(\"See instructions above or check your directory path. Could not glob.\")\n",
    "#             #raise SystemExit(\"Exitting.\")\n",
    "    \n",
    "#     except:\n",
    "#         print(\"Please copy me into the directory which contains the folders for your\")\n",
    "#         print(\"input, temporary, and output files for SpArcFiRe denoted:\")\n",
    "#         print(\"sparcfire-in, sparcfire-tmp, and sparcfire-out.\")\n",
    "#         raise SystemExit(\"Exitting.\")\n",
    "        \n",
    "#     else:\n",
    "    if not gnames_out:\n",
    "        print(\"No galaxy names fed in. Finding them to generate feedmes.\")\n",
    "    #     print(\"Something went wrong! No galaxies fed into feedme generator.\")\n",
    "    #     print(\"Please copy me into the directory which contains the folders for your\")\n",
    "    #     print(\"input, temporary, and output files for SpArcFiRe denoted:\")\n",
    "    #     print(\"sparcfire-in, sparcfire-tmp, and sparcfire-out.\")\n",
    "    #     raise SystemExit(\"Exitting.\")\n",
    "        gnames_out  = [os.path.basename(s).replace(\".fits\", \"\")\n",
    "                       for s in find_files(in_dir, \"*.fits\", \"f\")\n",
    "                       if exists(pj(out_dir, os.path.basename(s).replace(\".fits\", \"\")))\n",
    "                      ]\n",
    "\n",
    "    folders_out = [pj(out_dir, gname) for gname in gnames_out]\n",
    "        \n",
    "    return gnames_out, folders_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_join(path='.', name='', file_ext=''):\n",
    "    \n",
    "    file_path = pj(path, name + file_ext)\n",
    "\n",
    "    # deprecated\n",
    "    # \"./\" + path + '/' + name + file_ext\n",
    "    # print(file_path)\n",
    "    # print(glob.glob(file_path))\n",
    "    # file_name = glob.glob(file_path)[0]\n",
    "    \n",
    "    return file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_var(x, scale = 1):\n",
    "    # Scales\n",
    "    if not x:\n",
    "        return None\n",
    "    \n",
    "    return float(x)*scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def galaxy_information(galaxy_name, galaxy_path):\n",
    "     \n",
    "    kwargs_out = {\n",
    "        \"bulge_rad\" : 2,\n",
    "        \"bulge_axis_ratio\" : 0.5,\n",
    "        \"bulge_rot_angle\" : 30,\n",
    "        \"crop_rad\" : 30, # New!\n",
    "        \"center_pos_x\" : 30,\n",
    "        \"center_pos_y\" : 30,\n",
    "        \"disk_maj_axs_len\" : 30,\n",
    "        \"disk_rot_angle\" : 30,\n",
    "        #\"pos_angle_sersic\" : 1,\n",
    "        \"pos_angle_power\" : 30,\n",
    "        \"disk_axis_ratio\" : 0.5,\n",
    "        \"avg_arc_length\" : 30,\n",
    "        \"max_arc_length\" : 20,\n",
    "        \"alpha\" : 1,\n",
    "        \"est_arcs\" : 2,\n",
    "        \"inclination\" : 30,\n",
    "        \"bar_candidate\" : 'FALSE',\n",
    "        \"bar_len\"  : 5, \n",
    "        # spin_parity handled by if \n",
    "        \"spin_parity\" : '' #random.choice(['','-'])\n",
    "                    }\n",
    "           \n",
    "    # Making this global since I'm now grabbing the necessary info from the csv\n",
    "    # std for standardized image\n",
    "    global scale_fact_std\n",
    "    scale_fact_std = 2*kwargs_out[\"crop_rad\"]/256\n",
    "        \n",
    "    chirality = 0\n",
    "    chirality_2 = 0\n",
    "    chirality_3 = 0\n",
    "    pitch_angle = 20\n",
    "    \n",
    "    failure_modes = [\"input rejected\", \n",
    "                     \"Subscript indices must either be real positive integers or logicals.\",\n",
    "                     \"SIGMA must be a square  symmetric  positive definite matrix.\"\n",
    "                    ]\n",
    "    \n",
    "    try:\n",
    "        # Using this for the *big* runs because *somebody* (Wayne)\n",
    "        # didn't validate and overwrite the original csv's to include CR (crop radius)\n",
    "        csv_CR = path_join(galaxy_path, galaxy_name, '.csv+CR')\n",
    "        csv_filename = path_join(galaxy_path, galaxy_name, '.csv')\n",
    "        if exists(csv_CR):\n",
    "            csv_filename = csv_CR\n",
    "            \n",
    "        csv_file = open(csv_filename, 'r')\n",
    "        \n",
    "    except:\n",
    "        print(\"Can't open to read: \", csv_filename)\n",
    "        print(\"Check Sparcfire output or directories. Proceeding with default values.\")\n",
    "        return kwargs_out\n",
    "\n",
    "    \n",
    "    reader = csv.DictReader(csv_file, skipinitialspace = True)\n",
    "    for row in reader:\n",
    "        # if sparcfire fails\n",
    "        if row.get('fit_state', \"\") in failure_modes:\n",
    "            break\n",
    "        elif row.get('fit_state', \"\") != \"OK\":\n",
    "            print(f\"fit state is: {row.get('fit_state', '')}\")\n",
    "\n",
    "        try:\n",
    "            # Already accounted for, no need to scale\n",
    "            center_pos_x = float(row.get('inputCenterR'))\n",
    "            center_pos_y = float(row.get('inputCenterC'))\n",
    "\n",
    "            crop_rad = float(row.get('cropRad'))\n",
    "\n",
    "        except (ValueError, TypeError) as ve:\n",
    "            print(f\"SpArcFiRe likely failed on this galaxy, {ve}. Proceeding with default values...\")\n",
    "            break\n",
    "\n",
    "        # Anything with converting to float/int should go in here since there are a couple issues besides\n",
    "        # fit state which still result in an empty csv\n",
    "        try:\n",
    "            input_size    = int(row.get('iptSz', \"[256 256]\").strip().split()[0][1:])\n",
    "            global scale_fact_ipt\n",
    "            if input_size:\n",
    "                scale_fact_ipt = 2*crop_rad/input_size\n",
    "            else:\n",
    "                scale_fact_ipt = 2*crop_rad/256\n",
    "\n",
    "            bulge_rad = scale_var(row.get('bulgeMajAxsLen'), scale_fact_ipt)\n",
    "            # TODO: Take bulge axis ratio from SDSS? deVAB_r\n",
    "            bulge_axis_ratio = float(row.get('bulgeAxisRatio'))\n",
    "\n",
    "            # According to the dissertation this is given in terms of the input image not the standardized image\n",
    "            disk_maj_axs_len = scale_var(row.get('diskMajAxsLen'), scale_fact_ipt) \n",
    "\n",
    "            # Angles don't need to scale\n",
    "            # But sparcfire is flipped across the y-axis and uses mathematical convention\n",
    "            # As opposed to astronomical (0 is vertical y axis, 90 is counter clockwise to x)\n",
    "            bulge_rot_angle = 90 - np.degrees(float(row.get('bulgeMajAxsAngle')))\n",
    "            \n",
    "            # Power angle is mathematical convention, disk angle is astronomical\n",
    "            pos_angle_power = np.degrees(float(row.get('diskMajAxsAngleRadians')))\n",
    "            disk_rot_angle  = 90 - pos_angle_power\n",
    "            \n",
    "            disk_axis_ratio = float(row.get('diskAxisRatio'))\n",
    "\n",
    "            # GRABBING ARC STATISTICS\n",
    "            avg_arc_length = scale_var(row.get('avgArcLength'), scale_fact_std)\n",
    "            #med_arc_length = row['medianArcLength'][:6]\n",
    "            max_arc_length = scale_var(row.get('maxArcLength'), scale_fact_std)\n",
    "\n",
    "            # Grabbing PA absolute average from dominant chirality\n",
    "            pitch_angle = abs(float(row.get('pa_alenWtd_avg_domChiralityOnly')))\n",
    "\n",
    "            # For estimating number of real arcs to influence fourier modes\n",
    "            # This seems to be a much better way to do it\n",
    "            est_arcs = int(row.get('rankAt75pct'))\n",
    "\n",
    "        # Happens when row is empty... This is easier than messing with other conditionals for each scale factor/float conversion\n",
    "        except ValueError as ve:\n",
    "            pass\n",
    "\n",
    "        if disk_rot_angle < 0: \n",
    "            inclination = np.degrees(np.arccos(disk_axis_ratio))\n",
    "            #bulge_rot_angle = 90 + bulge_angle #because sparcfire gets confused sometimes\n",
    "\n",
    "            #pos_angle_power = -disk_rot_angle\n",
    "            #pos_angle_sersic = 90 + disk_angle # Because sparcfire is checking negative direction too, \n",
    "                                                                      # assuming symmetry this should align us better\n",
    "        else:\n",
    "            inclination = -np.degrees(np.arccos(disk_axis_ratio)) \n",
    "            #bulge_rot_angle = 90 - bulge_angle       \n",
    "\n",
    "            #pos_angle_power  = 180 - disk_rot_angle\n",
    "            #pos_angle_sersic = 90 - disk_angle \n",
    "\n",
    "        #if disk_axis_ratio >= 0.5:\n",
    "        #    pos_angle_power = pos_angle_power + bulge_angle # Big change, should this also apply to bulge?\n",
    "\n",
    "        #pos_angle_power = scale_var(pos_angle_power)\n",
    "        #pos_angle_sersic = pos_angle_sersic - 40 # 40 to adjust for coord rotation addition (see main gen)\n",
    "        #inclination = inclination\n",
    "\n",
    "        # Grabbing chirality\n",
    "        chirality = row.get('chirality_maj', chirality)\n",
    "        chirality_2 = row.get('chirality_alenWtd', chirality_2)\n",
    "        chirality_3 = row.get('chirality_longestArc', chirality_3)\n",
    "\n",
    "        #est_arcs = min(int(est_arcs[1]),int(est_arcs[-2]))\n",
    "\n",
    "        # bar candidate: r_in = 0 according to Chien\n",
    "        bar_candidate = row.get('bar_candidate_available')\n",
    "        bar_len  = scale_var(row.get(\"bar_half_length_input_img\"), scale_fact_ipt)\n",
    "\n",
    "        #print(pitch_angle)\n",
    "\n",
    "        # Based on linear regression from test set:\n",
    "        #galaxy, alpha, pitch angle\n",
    "        #6698 - 0.9319, 16.8303045\n",
    "        #1248 - 2.0704, 28.10656079\n",
    "        #9688 - 0.544, 12.11462932\n",
    "        #9241 - 0.7194, 19.01479688\n",
    "        #1827 - 1.2037, 21.55850102\n",
    "        #4222 - 0.5625, 8.145239069\n",
    "        #0761 - 1.1330, 19.53474969\n",
    "        # anddd adjusted according to comparison results \n",
    "        alpha = 0.07*pitch_angle - 0.3\n",
    "\n",
    "    csv_file.close()\n",
    " \n",
    "    if chirality == chirality_2 or chirality == chirality_3:\n",
    "        if chirality == 'Z-wise':\n",
    "            spin_parity = '-'\n",
    "        elif chirality == 'S-wise':\n",
    "            spin_parity = ''\n",
    "        else:\n",
    "            print(f\"Couldn't use chirality.\") #Proceeding with coin flip.\")\n",
    "    elif chirality_2 == chirality_3:\n",
    "        if chirality_2 == 'Z-wise':\n",
    "            spin_parity = '-'\n",
    "        elif chirality_2 == 'S-wise':\n",
    "            spin_parity = ''\n",
    "        else:\n",
    "            print(f\"Couldn't use chirality.\") # Proceeding with coin flip.\")\n",
    "    else:\n",
    "        print(\"Something went wrong in choosing a chirality!\") #Coin flip...\")\n",
    "        spin_parity = '' #random.choice(['','-'])\n",
    "        \n",
    "    loc = locals()\n",
    "    kwargs_out.update({i: loc[i] for i in kwargs_out.keys() if loc[i]})\n",
    "    return kwargs_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arc_information(galaxy_name, galaxy_path, num_arms = 2):\n",
    "\n",
    "    kwargs_out = {\n",
    "        \"inner_rad\" : 0,\n",
    "        \"outer_rad\" : 20,\n",
    "        \"cumul_rot\" : 60\n",
    "                 }\n",
    "    \n",
    "    try:\n",
    "        #arcs_filename = glob.glob(galaxy_path + '/' + '*_arcs.csv')\n",
    "        arcs_filename = path_join(galaxy_path, galaxy_name, '_arcs.csv')\n",
    "        arcs_file = open(arcs_filename, 'r')\n",
    "    except:\n",
    "        print(\"Can't open to read: \", arcs_filename)\n",
    "        print(\"Check Sparcfire output or directories. Proceeding with default values.\")\n",
    "\n",
    "    else:\n",
    "        reader = csv.DictReader(arcs_file)\n",
    "        arcs_in = list(reader)\n",
    "        \n",
    "        # Nested dictionaries\n",
    "        theta_sum = 0\n",
    "        inner_rad = 0\n",
    "        outer_rad = 0\n",
    "\n",
    "        i = 0\n",
    "        count = 0\n",
    "        \n",
    "        try:\n",
    "            winding_dir = float(arcs_in[0]['pitch_angle']) > 0\n",
    "        except IndexError as ie:\n",
    "            # For when sparcfire fails\n",
    "            # TODO: figure out where to put a function that checks if sparcfire failed so I only output\n",
    "            # one message per galaxy instead of doing it for arcs and galaxy info\n",
    "            return kwargs_out\n",
    "\n",
    "        while i < num_arms:\n",
    "            try:\n",
    "                _ = arcs_in[i]['pitch_angle']\n",
    "            except IndexError as ie:\n",
    "                return kwargs_out\n",
    "            \n",
    "            if (float(arcs_in[i]['pitch_angle']) > 0) != winding_dir:\n",
    "                i += 1\n",
    "                continue\n",
    "\n",
    "            # Rudimentary weighting scheme\n",
    "            weight = (num_arms - i)/num_arms\n",
    "            \n",
    "            try:\n",
    "                theta_sum += (np.degrees(float(arcs_in[i]['math_initial_theta'])) % 360) * weight\n",
    "                theta_sum += np.degrees(float(arcs_in[i]['relative_theta_end']))*weight #% 360\n",
    "\n",
    "                inner_rad += float(arcs_in[i]['r_start'])*weight\n",
    "                outer_rad += float(arcs_in[i]['r_end'])*weight\n",
    "            except ValueError as ve:\n",
    "                break\n",
    "\n",
    "            i += 1\n",
    "            count += 1\n",
    "        \n",
    "        # How far the arm rotates in theta which approximates the point where sparcfire no longer traces the arm\n",
    "        # and hence where the cumulative rotation out point is. Note, this already takes into account the relative\n",
    "        # starting point of the arms which is the hard part... \n",
    "        \n",
    "        # Averaging, tack on 180 to limit some of the craziness\n",
    "        # Galfit tends to like the outer_rad smaller, hence larger divisor\n",
    "        weight_div = 1/max(1, count + 1) #1/np.math.factorial(count)\n",
    "        cumul_rot = abs(theta_sum)*weight_div # NOT A STRING\n",
    "\n",
    "        inner_rad = inner_rad*weight_div # Averaging the inner distance to both arcs\n",
    "        outer_rad = outer_rad*weight_div # Averaging outer distance\n",
    "        \n",
    "        arcs_file.close()\n",
    "        \n",
    "        try:\n",
    "            inner_rad = scale_var(inner_rad, scale_fact_ipt)\n",
    "            outer_rad = scale_var(outer_rad, scale_fact_ipt)\n",
    "        except ValueError as ve:\n",
    "            pass\n",
    "\n",
    "    loc = locals()\n",
    "    kwargs_out.update({i: loc[i] for i in kwargs_out.keys() if loc[i]})\n",
    "    return kwargs_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def csv_sdss_info(galaxy_names): # to grab petromag and also psf parameter things\n",
    "    \n",
    "#     gname_info = {}\n",
    "    \n",
    "#     # Defaults go here\n",
    "#     run = 0\n",
    "#     rerun = 0\n",
    "#     cam = 0\n",
    "#     field = 0\n",
    "#     row = 0\n",
    "#     col = 0\n",
    "#     pmag = 16\n",
    "    \n",
    "#     try:\n",
    "#         #star_dl_filename = glob_name('star_dl','star_dl','.csv')\n",
    "#         star_dl_filename = path_join('star_dl','star_dl','.csv')\n",
    "#         star_dl_file = open(star_dl_filename, 'r')\n",
    "        \n",
    "#     except:\n",
    "#         print(\"Can't open to read star_dl.csv with star information (for PSF)\")\n",
    "#         print(\"Check Sparcfire output or directories. Proceeding with default values.\")\n",
    "    \n",
    "#         for gname in galaxy_names:\n",
    "#             gname_info[gname] = [run, rerun, cam, field, row, col, pmag]\n",
    "            \n",
    "#         return gname_info\n",
    "\n",
    "#     else:\n",
    "#         star_df = pd.read_csv(star_dl_file, index_col=0)\n",
    "#         #csv_gal_name = star_df.columns[0]\n",
    "        \n",
    "#         for gname in galaxy_names:\n",
    "#             try:\n",
    "#                 temp = star_df.at[gname, 'run']\n",
    "\n",
    "#             except:\n",
    "#                 #print(star_df.loc[:, 'name'])\n",
    "#                 print(\"Can't find the galaxy:\", gname, \"in our repository.\")\n",
    "#                 print(\"Proceeding with default values and no PSF.\")\n",
    "#                 run = 0\n",
    "#                 rerun = 0\n",
    "#                 camcol = 0\n",
    "#                 field = 0\n",
    "#                 rowc = 0\n",
    "#                 colc = 0\n",
    "#                 petromag = 16\n",
    "\n",
    "#             else:\n",
    "#                 galaxy_band = gname[-1]\n",
    "\n",
    "#                 run = ' run: '     + str(star_df.at[gname, 'run'])\n",
    "#                 rerun = ' rerun: ' + str(star_df.at[gname, 'rerun'])\n",
    "#                 cam = ' camcol: '  + str(star_df.at[gname, 'camcol'])\n",
    "#                 field = ' field: ' + str(star_df.at[gname, 'field'])\n",
    "#                 row = ' row: '     + str(star_df.at[gname, 'rowC'])\n",
    "#                 col = ' col: '     + str(star_df.at[gname, 'colC'])\n",
    "#                 pmag = str(star_df.at[gname, 'petroMag_' + galaxy_band])\n",
    "                \n",
    "#             gname_info[gname] = [run, rerun, cam, field, row, col, pmag]\n",
    "        \n",
    "#     return gname_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_starmask_ascii(starmask_filepath):\n",
    "    with fits.open(starmask_filepath) as sm:\n",
    "        mask_data = sm[0].data\n",
    "        mask_indices = np.dstack(np.where(mask_data == 0))\n",
    "        mask_indices = mask_indices.reshape(mask_indices.shape[1], 2).astype(str)\n",
    "\n",
    "    gname = os.path.basename(starmask_filepath).split(\"_star-rm\")[0]\n",
    "    starmask_ascii_name = os.path.join(os.path.split(starmask_filepath)[0], f\"{gname}_starmask.txt\")\n",
    "\n",
    "    # To avoid some file I/O\n",
    "    if not mask_indices.size: return starmask_ascii_name\n",
    "\n",
    "    with open(starmask_ascii_name, \"w\") as sma:\n",
    "        _ = [sma.write(' '.join(i) + \"\\n\") for i in mask_indices]\n",
    "\n",
    "    return starmask_ascii_name"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def write_to_feedme(path, list_in, feedme_name = \"autogen_feedme_galfit.in\"):\n",
    "    \n",
    "    file_path = os.path.join(\".\", path, feedme_name)\n",
    "#    file_path = \"/\".join([\".\", path, \"\"]) + 'autogen_feedme_galfit.in'\n",
    "    with open(file_path, 'w') as g:\n",
    "        #for value in list_in:\n",
    "        _ = [g.write(f\"{value}\\n\") for value in list_in]\n",
    "        \n",
    "    return file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_feedmes(top_dir = \"\", **kwargs): # single_galaxy_name = \"\", **kwargs):\n",
    "    \n",
    "    if top_dir:\n",
    "        in_dir, tmp_dir, out_dir = command_line(top_dir)\n",
    "    else:\n",
    "        in_dir, tmp_dir, out_dir = command_line()\n",
    "        \n",
    "    in_dir = kwargs.get(\"in_dir\", in_dir)\n",
    "    tmp_dir = kwargs.get(\"tmp_dir\", tmp_dir)\n",
    "    out_dir = kwargs.get(\"out_dir\", out_dir)\n",
    "    \n",
    "    galaxy_names, gfolders = get_galaxy_names_list(in_dir, tmp_dir, out_dir, galaxy_names = kwargs.get(\"galaxy_names\", []))\n",
    "    \n",
    "    #psf_info = csv_sdss_info(galaxy_names)\n",
    "    \n",
    "    feedme_info_out = {}\n",
    "    \n",
    "    petromags = kwargs.get(\"petromags\", 16*np.ones(len(gfolders)))\n",
    "    bulge_axis_ratios = kwargs.get(\"bulge_axis_ratios\", [])\n",
    "    \n",
    "    for i, gfolder in enumerate(gfolders):\n",
    "    \n",
    "        # if single_galaxy_name:\n",
    "        #     gname = single_galaxy_name\n",
    "        #     #gfolder = pj(out_dir, gname)\n",
    "        #     # Alternatively\n",
    "        #     # galaxy = folders_out[galaxy_names.index(gname)]\n",
    "        # else:\n",
    "        #     gname = galaxy_names[count]\n",
    "            \n",
    "        gname = os.path.basename(gfolder)\n",
    "        if not exists(gfolder):\n",
    "            print(f\"{gfolder} cannot be found. Continuing...\")\n",
    "            continue\n",
    "            \n",
    "        print(gname)\n",
    "        \n",
    "        if(os.path.basename(gfolder) != gname):\n",
    "            print(\"uh oh naming went wrong in feedme generator.\")\n",
    "            print(f\"basename of {gfolder} != {gname}\")\n",
    "            continue\n",
    "        \n",
    "        # From old implementation - 1/19/21\n",
    "        # ************\n",
    "        # x1crop, x2crop, y1crop, y2crop = autocrop_grab(gname, gfolder)\n",
    "        # scale = (float(x2crop)-float(x1crop))/256 - from old implementation\n",
    "        # ************\n",
    "        \n",
    "        galaxy_dict = galaxy_information(gname, gfolder)\n",
    "        \n",
    "        center_pos_x = float(galaxy_dict[\"center_pos_x\"])\n",
    "        center_pos_y = float(galaxy_dict[\"center_pos_y\"])\n",
    "        crop_rad = float(galaxy_dict[\"crop_rad\"])\n",
    "        \n",
    "        x1crop = round(center_pos_x - crop_rad)\n",
    "        x2crop = round(center_pos_x + crop_rad)        \n",
    "        y1crop = round(center_pos_y - crop_rad)\n",
    "        y2crop = round(center_pos_y + crop_rad)\n",
    "    \n",
    "        arc_dict = arc_information(gname, gfolder, num_arms = galaxy_dict[\"est_arcs\"])\n",
    "    \n",
    "        if galaxy_dict[\"bar_candidate\"].upper() == \"FALSE\": # According to Chien, if no bar, then r_in = 0 since r_in is more a mathematical construct relating to the bar\n",
    "            in_rad = 0 #unsure if I'll keep this...\n",
    "            #pass\n",
    "        elif galaxy_dict[\"bar_candidate\"].upper() == \"TRUE\":\n",
    "            in_rad = min(galaxy_dict[\"bar_len\"], arc_dict[\"inner_rad\"])\n",
    "        else:\n",
    "            print(bar_candidate)\n",
    "            print(\"bar_candidate is neither TRUE nor FALSE in the CSV. Check sparcfire output.\")\n",
    "            print(\"Defaulting the average inner distance to the arms.\")\n",
    "        \n",
    "        tmp_dir_basename = os.path.basename(tmp_dir)\n",
    "        header = GalfitHeader(input_menu_file = gname,\n",
    "                              #extra_header_info = f\"{run}{camcol}{field}; HDU: z{psf_row}{psf_col}\",\n",
    "                              galaxy_name = gname,\n",
    "                              input_image = pj(in_dir, f\"{gname}.fits\"),\n",
    "                              output_image = pj(tmp_dir, \"galfits\", f\"{gname}_galfit_out.fits\"),\n",
    "                              # Unfortunately have to use a relative path here since GALFIT\n",
    "                              # breaks when the filename is too long\n",
    "                              #psf = pj(\"..\", \"..\", tmp_dir_basename, \"psf_files\", f\"{gname}_psf.fits\"),\n",
    "                              psf = f\"{gname}_psf.fits\",\n",
    "                              pixel_mask = pj(tmp_dir, \"galfit_masks\", f\"{gname}_star-rm.fits\"),\n",
    "                              region_to_fit = (x1crop, x2crop, y1crop, y2crop),\n",
    "                              optimize = 0\n",
    "                             )\n",
    "        \n",
    "        # Take mag from SDSS\n",
    "        # Using the default I've been using (for now)\n",
    "        petromag = float(petromags[i])\n",
    "        \n",
    "        # Take bulge axis ratio from SDSS\n",
    "        if bulge_axis_ratios:\n",
    "            bulge_axis_ratio = float(bulge_axis_ratios[i])\n",
    "        else:\n",
    "            bulge_axis_ratio = galaxy_dict[\"bulge_axis_ratio\"]\n",
    "        \n",
    "        bulge = Sersic(component_number = 1, \n",
    "                       position = (center_pos_x, center_pos_y),\n",
    "                       magnitude = float(petromag),\n",
    "                       effective_radius = galaxy_dict[\"bulge_rad\"],\n",
    "                       # According to other paper GALFIT usually doesn't have a problem with the index\n",
    "                       sersic_index = 1, #4\n",
    "                       axis_ratio = bulge_axis_ratio,\n",
    "                       position_angle = galaxy_dict[\"bulge_rot_angle\"]\n",
    "                      )\n",
    "        \n",
    "        disk  = Sersic(component_number = 2, \n",
    "                       position = (center_pos_x, center_pos_y),\n",
    "                       magnitude = float(petromag) - 3,\n",
    "                       effective_radius = galaxy_dict[\"disk_maj_axs_len\"],\n",
    "                       # According to comparison tests, this usually ends up much higher than classical probably due to the spiral.\n",
    "                       sersic_index = 4,\n",
    "                       axis_ratio = galaxy_dict[\"disk_axis_ratio\"],\n",
    "                       position_angle = galaxy_dict[\"disk_rot_angle\"]\n",
    "                      )\n",
    "            \n",
    "        arms  = Power(component_number = 2,\n",
    "                      inner_rad = in_rad, # Chosen based on where *detection* of arms usually start\n",
    "                      outer_rad = arc_dict[\"outer_rad\"],\n",
    "                      cumul_rot = float(f\"{galaxy_dict['spin_parity']}{arc_dict['cumul_rot']}\"),\n",
    "                      powerlaw = galaxy_dict[\"alpha\"],\n",
    "                      inclination = galaxy_dict[\"inclination\"],\n",
    "                      sky_position_angle = (galaxy_dict[\"pos_angle_power\"] - galaxy_dict[\"disk_rot_angle\"]) % 180 #90 \n",
    "                     )\n",
    "        \n",
    "        # Take 90 pixels (in the 256x256 image) to be the cutoff for an arm\n",
    "        # Use a simple cut off for now\n",
    "        # Looking at the first two arms may be too unreliable\n",
    "        #print(\"Max arc length in 256 img\", scale_var(max_arc, 0.5*256/crop_rad))\n",
    "        if scale_var(galaxy_dict[\"max_arc_length\"], 1/scale_fact_std) < 75:\n",
    "            print(\"Skipping Arms, max arc len is\", max_arc*1/scale_fact_std)\n",
    "            arms.add_skip(skip_val = 1)\n",
    "        else:\n",
    "            # Fixing this to 0.6 to give the arms the best chance to form\n",
    "            disk.axis_ratio = 0.6\n",
    "            disk.param_values[\"axis_ratio\"] = 0.6\n",
    "\n",
    "        fourier = Fourier(component_number = 2)\n",
    "            \n",
    "        sky   = Sky(component_number = 3)\n",
    "        \n",
    "        # Previously used for Fourier modes\n",
    "        \n",
    "#         f1 = 0.05\n",
    "#         f3 = 0.02\n",
    "#         f4 = 0.005\n",
    "#         f5 = 0.001\n",
    "#         if est_arcs <= 2:\n",
    "#             f3 -= 0.015\n",
    "#             f5 = 0\n",
    "#             f4 = 0\n",
    "#         elif est_arcs == 3:\n",
    "#             f3 += 0.03\n",
    "#             f4 += 0.005\n",
    "#             f5 = 0\n",
    "#         elif est_arcs >= 4:\n",
    "#             f3 += 0.03\n",
    "#             f4 += 0.015\n",
    "#             f5 += 0.014\n",
    "#         else:\n",
    "#             print(\"Something went wrong with the estimation of arcs! Check chirality_votes_maj in csv. Proceeding\")\n",
    "        \n",
    "        \n",
    "        # count += 1\n",
    "        \n",
    "        container = FeedmeContainer(path_to_feedme = pj(gfolder, f\"{gname}.in\"),\n",
    "                                    header         = header,\n",
    "                                    bulge          = bulge, \n",
    "                                    disk           = disk,\n",
    "                                    arms           = arms,\n",
    "                                    fourier        = fourier,\n",
    "                                    sky            = sky)\n",
    "        \n",
    "        if arms.param_values.get(\"skip\", False):\n",
    "            # By default includes the header\n",
    "            container.to_file(bulge, disk, sky)\n",
    "        else:\n",
    "            container.to_file()\n",
    "        \n",
    "        feedme_info_out[gname] = container\n",
    "        \n",
    "    return feedme_info_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # FOR NOW (aka TODO) force >python 3.7 for f string and subprocess compatibility\n",
    "    # out_str = \"\"\"\\t Python3.7 or greater required! Exitting without generating feedmes... \n",
    "    #             if feedmes have already been generated, galfit will run with those.\\n\"\"\"\n",
    "    # assert sys.version_info >= (3, 7), out_str\n",
    "    \n",
    "    \n",
    "    # if in_notebook():\n",
    "    #     cwd = cwd.replace(\"ics-home\", username)\n",
    "    cwd = os.getcwd()    \n",
    "    write_to_feedmes(top_dir = cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting sparc_to_galfit_feedme_gen_debug.ipynb\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # in_notebook() is checked in the export function\n",
    "    export_to_py(\"sparc_to_galfit_feedme_gen_debug\", output_filename = pj(_MODULE_DIR, \"sparc_to_galfit_feedme_gen\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
